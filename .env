# Text2Mem Environment Configuration / 环境配置
# Provider: openai

# Database Settings
TEXT2MEM_DB_PATH=./text2mem.db
TEXT2MEM_DB_WAL=true
TEXT2MEM_DB_TIMEOUT=30

# Embedding Model Settings
TEXT2MEM_EMBEDDING_PROVIDER=openai
TEXT2MEM_EMBEDDING_MODEL=text-embedding-3-small

# Generation Model Settings
TEXT2MEM_GENERATION_PROVIDER=openai
TEXT2MEM_GENERATION_MODEL=gpt-4o
TEXT2MEM_TEMPERATURE=0.7
TEXT2MEM_MAX_TOKENS=512
TEXT2MEM_TOP_P=0.9

# OpenAI Settings
OPENAI_API_KEY=sk-REPLACE_THIS_WITH_NEW_KEY
OPENAI_API_BASE=https://yinli.one/v1
OPENAI_ORGANIZATION=

# Ollama Settings
OLLAMA_BASE_URL=http://localhost:11434

# Request Settings
TEXT2MEM_REQUEST_TIMEOUT=60
TEXT2MEM_MAX_RETRIES=3
TEXT2MEM_BATCH_SIZE=10

# Hybrid Search Settings
TEXT2MEM_SEARCH_ALPHA=0.7
TEXT2MEM_SEARCH_BETA=0.3
TEXT2MEM_SEARCH_PHRASE_BONUS=0.2
TEXT2MEM_SEARCH_DEFAULT_LIMIT=10
TEXT2MEM_SEARCH_MAX_LIMIT=100
TEXT2MEM_SEARCH_DEFAULT_K=5

# Bench Test Settings
TEXT2MEM_BENCH_TIMEOUT=90
TEXT2MEM_BENCH_SPLIT=basic
TEXT2MEM_BENCH_MODE=auto
TEXT2MEM_BENCH_VERBOSE=false

# Bench Generation Settings
TEXT2MEM_BENCH_GEN_PROVIDER=openai
TEXT2MEM_BENCH_GEN_MODEL=gpt-4o-mini
TEXT2MEM_BENCH_GEN_TEMPERATURE=0.7
TEXT2MEM_BENCH_GEN_MAX_TOKENS=4000
TEXT2MEM_BENCH_GEN_TIMEOUT=120

# Async Bench Generation Settings
TEXT2MEM_BENCH_GEN_USE_ASYNC=true
TEXT2MEM_BENCH_GEN_MAX_CONCURRENT=5
TEXT2MEM_BENCH_GEN_RETRY_MAX=3
TEXT2MEM_BENCH_GEN_RETRY_DELAY=2
TEXT2MEM_BENCH_GEN_CHECKPOINT_BATCH=10

# Logging
TEXT2MEM_LOG_LEVEL=INFO
TEXT2MEM_LANG=en

# Compatibility Settings
MODEL_SERVICE=openai
TEXT2MEM_PROVIDER=openai
TEXT2MEM_MODELS={"openai":{"embedding":"text-embedding-3-small","generation":"gpt-4o"},"ollama":{"embedding":"nomic-embed-text","generation":"qwen2:0.5b","base_url":"http://localhost:11434"}}
