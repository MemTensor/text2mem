# Text2Mem é…ç½®æŒ‡å—

å®Œæ•´çš„ç¯å¢ƒé…ç½®ã€æ¨¡å‹é€‰æ‹©å’Œå‚æ•°è®¾ç½®è¯´æ˜ã€‚

---

## ç›®å½•

- [é…ç½®æ¶æ„](#é…ç½®æ¶æ„)
- [å¿«é€Ÿé…ç½®](#å¿«é€Ÿé…ç½®)
- [ç¯å¢ƒå˜é‡](#ç¯å¢ƒå˜é‡)
- [æ¨¡å‹é€‰æ‹©](#æ¨¡å‹é€‰æ‹©)
- [é…ç½®éªŒè¯](#é…ç½®éªŒè¯)

---

## é…ç½®æ¶æ„

Text2Mem é‡‡ç”¨ **Provider ä¸ Service åˆ†ç¦»** çš„æ¶æ„ï¼š

- **Provider**ï¼šæä¾›æ¨¡å‹æ¥å£ï¼ˆEmbeddingModel / GenerationModelï¼‰
  - Mock: æ¨¡æ‹Ÿæ¨¡å‹ï¼Œç”¨äºæµ‹è¯•
  - Ollama: æœ¬åœ°è¿è¡Œçš„å¼€æºæ¨¡å‹
  - OpenAI: äº‘ç«¯ API æœåŠ¡

- **Service**ï¼šå°è£…é«˜é˜¶èƒ½åŠ›
  - encode (æ–‡æœ¬ç¼–ç )
  - semantic_search (è¯­ä¹‰æœç´¢)
  - summarize (ç”Ÿæˆæ‘˜è¦)
  - label (æ ‡ç­¾å»ºè®®)
  - split (æ–‡æœ¬æ‹†åˆ†)

---

## å¿«é€Ÿé…ç½®

### æ–¹å¼ 1: ä½¿ç”¨ manage.py (æ¨è)

```bash
# Mock æ¨¡å¼ (æµ‹è¯•/å¼€å‘)
python manage.py config --provider mock

# Ollama æ¨¡å¼ (æœ¬åœ°è¿è¡Œ)
python manage.py config --provider ollama \
  --embed-model nomic-embed-text \
  --gen-model qwen2.5:0.5b

# OpenAI æ¨¡å¼ (äº‘ç«¯API)
python manage.py config --provider openai \
  --openai-key sk-xxx \
  --embed-model text-embedding-3-small \
  --gen-model gpt-4o-mini
```

### æ–¹å¼ 2: ç¼–ç¨‹æ–¹å¼

```python
from text2mem.services.service_factory import create_models_service

# è‡ªåŠ¨æ ¹æ®ç¯å¢ƒé€‰æ‹©
service = create_models_service(mode="auto")

# æˆ–å¼ºåˆ¶æŒ‡å®š provider
service = create_models_service(mode="openai")  # "mock" / "ollama" / "openai"
```

### æ–¹å¼ 3: æ‰‹åŠ¨ç¼–è¾‘ .env

```bash
# å¤åˆ¶æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘é…ç½®
nano .env
```

---

## ç¯å¢ƒå˜é‡

### é€šç”¨é…ç½®

é€‚ç”¨äºæ‰€æœ‰ Providerï¼š

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | é»˜è®¤å€¼ |
|---------|------|--------|
| `TEXT2MEM_DB_PATH` | æ•°æ®åº“æ–‡ä»¶è·¯å¾„ | `./text2mem.db` |
| `TEXT2MEM_DB_WAL` | æ˜¯å¦å¯ç”¨ WAL æ¨¡å¼ | `true` |
| `TEXT2MEM_DB_TIMEOUT` | æ•°æ®åº“è¶…æ—¶(ç§’) | `30` |
| `TEXT2MEM_LOG_LEVEL` | æ—¥å¿—çº§åˆ« | `INFO` |
| `TEXT2MEM_TEMPERATURE` | ç”Ÿæˆæ¨¡å‹æ¸©åº¦ | `0.7` |
| `TEXT2MEM_MAX_TOKENS` | ç”Ÿæˆæœ€å¤§ token æ•° | `512` |
| `TEXT2MEM_TOP_P` | ç”Ÿæˆé‡‡æ · top-p | `0.9` |

### OpenAI é…ç½®

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | é»˜è®¤å€¼ |
|---------|------|--------|
| `OPENAI_API_KEY` | OpenAI API å¯†é’¥ | **å¿…é¡»è®¾ç½®** |
| `OPENAI_API_BASE` | è‡ªå®šä¹‰ API ç«¯ç‚¹ | `https://api.openai.com/v1` |
| `OPENAI_ORGANIZATION` | ç»„ç»‡ ID | æ—  |
| `TEXT2MEM_EMBEDDING_PROVIDER` | å›ºå®šä¸º "openai" | `openai` |
| `TEXT2MEM_EMBEDDING_MODEL` | åµŒå…¥æ¨¡å‹åç§° | `text-embedding-3-small` |
| `TEXT2MEM_GENERATION_PROVIDER` | å›ºå®šä¸º "openai" | `openai` |
| `TEXT2MEM_GENERATION_MODEL` | ç”Ÿæˆæ¨¡å‹åç§° | `gpt-4o-mini` |

### Ollama é…ç½®

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | é»˜è®¤å€¼ |
|---------|------|--------|
| `TEXT2MEM_EMBEDDING_PROVIDER` | å›ºå®šä¸º "ollama" | `ollama` |
| `TEXT2MEM_EMBEDDING_MODEL` | åµŒå…¥æ¨¡å‹åç§° | `nomic-embed-text` |
| `TEXT2MEM_OLLAMA_BASE_URL` | Ollama æœåŠ¡ URL | `http://localhost:11434` |
| `TEXT2MEM_GENERATION_PROVIDER` | å›ºå®šä¸º "ollama" | `ollama` |
| `TEXT2MEM_GENERATION_MODEL` | ç”Ÿæˆæ¨¡å‹åç§° | `qwen2.5:0.5b` |

### Mock é…ç½®

Mock æ¨¡å¼æ— éœ€é¢å¤–é…ç½®ï¼Œè‡ªåŠ¨ä½¿ç”¨è™šæ‹Ÿæ¨¡å‹ã€‚

---

## æ¨¡å‹é€‰æ‹©

### OpenAI æ¨èæ¨¡å‹

#### åµŒå…¥æ¨¡å‹

| æ¨¡å‹ | ç»´åº¦ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|-----|------|------|---------|
| `text-embedding-3-small` | 1536 | **æ¨è**ï¼Œæ€§èƒ½å¥½ï¼Œæˆæœ¬ä½ | é€šç”¨åœºæ™¯ |
| `text-embedding-3-large` | 3072 | æ›´é«˜ç²¾åº¦ï¼Œæˆæœ¬è¾ƒé«˜ | é«˜ç²¾åº¦éœ€æ±‚ |
| `text-embedding-ada-002` | 1536 | æ—§ç‰ˆæ¨¡å‹ | å…¼å®¹æ€§ |

#### ç”Ÿæˆæ¨¡å‹

| æ¨¡å‹ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|-----|------|---------|
| `gpt-4o-mini` | **æ¨è**ï¼Œå¿«é€Ÿä¸”æˆæœ¬ä½ | é€šç”¨åœºæ™¯ |
| `gpt-4o` | æœ€æ–°æ¨¡å‹ï¼Œé«˜è´¨é‡è¾“å‡º | é«˜è´¨é‡éœ€æ±‚ |
| `gpt-4-turbo` | è¾ƒæ–°æ¨¡å‹ï¼Œè´¨é‡ä¸æˆæœ¬é€‚ä¸­ | å¹³è¡¡åœºæ™¯ |
| `gpt-3.5-turbo` | å¿«é€Ÿå“åº”ï¼Œæˆæœ¬æœ€ä½ | ç®€å•ä»»åŠ¡ |

### Ollama æ¨èæ¨¡å‹

#### åµŒå…¥æ¨¡å‹

| æ¨¡å‹ | ç»´åº¦ | ç‰¹ç‚¹ |
|-----|------|------|
| `nomic-embed-text` | 768 | **æ¨è**ï¼Œæ€§èƒ½å¥½ |
| `mxbai-embed-large` | 1024 | å¯é€‰é«˜æ€§èƒ½æ¨¡å‹ |

#### ç”Ÿæˆæ¨¡å‹

| æ¨¡å‹ | å‚æ•°é‡ | ç‰¹ç‚¹ |
|-----|-------|------|
| `qwen2.5:0.5b` | 0.5B | **æ¨è**ï¼Œè½»é‡çº§ |
| `llama3:8b` | 8B | é«˜è´¨é‡ï¼Œéœ€æ›´å¤šèµ„æº |
| `mistral:7b` | 7B | æ›¿ä»£é€‰é¡¹ |

---

## é…ç½®éªŒè¯

### æ£€æŸ¥ç¯å¢ƒçŠ¶æ€

```bash
python manage.py status
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
ğŸ“Š Text2Mem ç¯å¢ƒçŠ¶æ€
============================================================

[ç¯å¢ƒæ–‡ä»¶]
  âœ… .env å·²é…ç½® -> /path/to/.env

[æ¨¡å‹é…ç½®]
  Provider: openai
  åµŒå…¥æ¨¡å‹: openai:text-embedding-3-small
  ç”Ÿæˆæ¨¡å‹: openai:gpt-4o-mini
  OpenAI API Key: âœ… å·²è®¾ç½®

[æ•°æ®åº“]
  è·¯å¾„: ./text2mem.db
  çŠ¶æ€: âœ… å­˜åœ¨

[ä¾èµ–å·¥å…·]
  ollama: âœ… å¯ç”¨
  pytest: âœ… å¯ç”¨
```

### æŸ¥çœ‹æ¨¡å‹è¯¦æƒ…

```bash
python manage.py models-info
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
ğŸ¤– æ¨¡å‹é…ç½®è¯¦æƒ…
============================================================

[æ€»ä½“é…ç½®]
  Provider: openai

[åµŒå…¥æ¨¡å‹]
  Provider: openai
  Model: text-embedding-3-small

[ç”Ÿæˆæ¨¡å‹]
  Provider: openai
  Model: gpt-4o-mini

[OpenAI é…ç½®]
  API Key: âœ… å·²è®¾ç½® (sk-pYqTN...)
  API Base: https://api.openai.com/v1
```

### è¿è¡Œå†’çƒŸæµ‹è¯•

```bash
# æµ‹è¯•å½“å‰é…ç½®
python manage.py models-smoke

# æµ‹è¯•ç‰¹å®š provider
python manage.py models-smoke openai
python manage.py models-smoke ollama
python manage.py models-smoke mock
```

---

## åˆ‡æ¢é…ç½®

### åœ¨ä¸åŒ Provider ä¹‹é—´åˆ‡æ¢

```bash
# åˆ‡æ¢åˆ° Ollama
python manage.py config --provider ollama

# åˆ‡æ¢åˆ° OpenAI
python manage.py config --provider openai --openai-key sk-xxx

# åˆ‡æ¢åˆ° Mock
python manage.py config --provider mock
```

### æ›´æ–°å•ä¸ªç¯å¢ƒå˜é‡

```bash
# æ›´æ–°ç”Ÿæˆæ¨¡å‹
python manage.py set-env TEXT2MEM_GENERATION_MODEL gpt-4o

# æ›´æ–°åµŒå…¥æ¨¡å‹
python manage.py set-env TEXT2MEM_EMBEDDING_MODEL text-embedding-3-large

# æ›´æ–°æ•°æ®åº“è·¯å¾„
python manage.py set-env TEXT2MEM_DB_PATH /path/to/custom.db
```

---

## è¯­è¨€ä¸å›½é™…åŒ– (i18n)

### é»˜è®¤è¯­è¨€

- é»˜è®¤è¾“å‡ºè¯­è¨€ï¼šè‹±è¯­ (en)
- å¯é€šè¿‡ç¯å¢ƒå˜é‡å…¨å±€è®¾ç½®

### é…ç½®æ–¹å¼

```bash
# è®¾ç½®ä¸ºä¸­æ–‡
export TEXT2MEM_LANG=zh

# è®¾ç½®ä¸ºè‹±æ–‡
export TEXT2MEM_LANG=en
```

### è¯­è¨€è§£æé¡ºåº

1. æ˜¾å¼ä¼ å…¥çš„ `meta.lang` æˆ–è°ƒç”¨å‚æ•° `lang`
2. ç¯å¢ƒå˜é‡ `TEXT2MEM_LANG`
3. è‡ªåŠ¨æ£€æµ‹è¾“å…¥æ˜¯å¦åŒ…å«ä¸­æ–‡
4. å›è½åˆ°è‹±æ–‡ (en)

### ä½¿ç”¨ç¤ºä¾‹

```python
# å…¨å±€è®¾ç½®ä¸­æ–‡
import os
os.environ['TEXT2MEM_LANG'] = 'zh'

# å•æ¬¡è°ƒç”¨ä½¿ç”¨è‹±æ–‡
result = engine.execute({
    "stage": "RET",
    "op": "Retrieve",
    "meta": {"lang": "en"}
})
```

---

## Ollama ç‰¹æ®Šè¯´æ˜

### å®‰è£… Ollama

```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows
# ä¸‹è½½å®‰è£…åŒ…: https://ollama.com/download
```

### å¯åŠ¨ Ollama æœåŠ¡

```bash
ollama serve
```

### æ‹‰å–æ¨¡å‹

```bash
# ä½¿ç”¨ manage.py (æ¨è)
python manage.py setup-ollama

# æˆ–æ‰‹åŠ¨æ‹‰å–
ollama pull nomic-embed-text
ollama pull qwen2.5:0.5b
```

### éªŒè¯ Ollama

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:11434/api/version

# åˆ—å‡ºå·²å®‰è£…æ¨¡å‹
ollama list
```

---

## æ•…éšœæ’é™¤

### OpenAI API é”™è¯¯

**é—®é¢˜**: 401 Unauthorized

**è§£å†³**:
```bash
# æ£€æŸ¥ API Key
echo $OPENAI_API_KEY

# é‡æ–°è®¾ç½®
python manage.py config --provider openai --openai-key sk-xxx
```

### Ollama è¿æ¥å¤±è´¥

**é—®é¢˜**: Connection refused

**è§£å†³**:
```bash
# å¯åŠ¨ Ollama æœåŠ¡
ollama serve

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:11434/api/version
```

### æ¨¡å‹æœªæ‰¾åˆ°

**é—®é¢˜**: Model 'xxx' not found

**è§£å†³**:
```bash
# Ollama: æ‹‰å–æ¨¡å‹
python manage.py setup-ollama

# OpenAI: æ£€æŸ¥æ¨¡å‹åç§°
python manage.py models-info
```

---

## ç›¸å…³æ–‡æ¡£

- [README.md](../README.md) - é¡¹ç›®ä¸»æ–‡æ¡£
- [CHANGELOG.md](CHANGELOG.md) - å˜æ›´æ—¥å¿—
- [Environment Configuration Guide](ENVIRONMENT_CONFIGURATION.md) - è¯¦ç»†ç¯å¢ƒé…ç½®

---

## å¸®åŠ©å‘½ä»¤

```bash
# æŸ¥çœ‹æ‰€æœ‰é…ç½®å‘½ä»¤
python manage.py help config
python manage.py help set-env
python manage.py help setup-ollama
python manage.py help setup-openai
```
