<div align="center">

# Text2Mem Configuration Guide | Text2Mem é…ç½®æŒ‡å—

**Complete environment configuration, model selection, and parameter settings**  
**å®Œæ•´çš„ç¯å¢ƒé…ç½®ã€æ¨¡å‹é€‰æ‹©å’Œå‚æ•°è®¾ç½®è¯´æ˜**

</div>

---

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

---

# English

## Table of Contents

- [Configuration Architecture](#configuration-architecture)
- [Quick Setup](#quick-setup)
- [Environment Variables](#environment-variables)
- [Model Selection](#model-selection)
- [Configuration Validation](#configuration-validation)
- [Troubleshooting](#troubleshooting)

---

## Configuration Architecture

Text2Mem uses a **Provider and Service separation** architecture:

- **Provider**: Provides model interfaces (EmbeddingModel / GenerationModel)
  - Mock: Simulated models for testing
  - Ollama: Locally running open-source models
  - OpenAI: Cloud API service

- **Service**: Encapsulates high-level capabilities
  - encode (text encoding)
  - semantic_search (semantic search)
  - summarize (generate summary)
  - label (label suggestion)
  - split (text splitting)

---

## Quick Setup

### Method 1: Using manage.py (Recommended)

```bash
# Mock mode (testing/development)
python manage.py config --provider mock

# Ollama mode (local running)
python manage.py config --provider ollama \
  --embed-model nomic-embed-text \
  --gen-model qwen2.5:0.5b

# OpenAI mode (cloud API)
python manage.py config --provider openai \
  --openai-key sk-xxx \
  --embed-model text-embedding-3-small \
  --gen-model gpt-4o-mini
```

### Method 2: Programmatic

```python
from text2mem.services.service_factory import create_models_service

# Automatically select based on environment
service = create_models_service(mode="auto")

# Or force specify provider
service = create_models_service(mode="openai")  # "mock" / "ollama" / "openai"
```

### Method 3: Manual .env Edit

```bash
# Copy template
cp .env.example .env

# Edit configuration
nano .env
```

---

## Environment Variables

### Common Configuration

Applicable to all Providers:

| Variable | Description | Default |
|---------|------|--------|
| `TEXT2MEM_DB_PATH` | Database file path | `./text2mem.db` |
| `TEXT2MEM_DB_WAL` | Enable WAL mode | `true` |
| `TEXT2MEM_DB_TIMEOUT` | Database timeout(s) | `30` |
| `TEXT2MEM_LOG_LEVEL` | Log level | `INFO` |
| `TEXT2MEM_TEMPERATURE` | Generation temperature | `0.7` |
| `TEXT2MEM_MAX_TOKENS` | Max generation tokens | `512` |
| `TEXT2MEM_TOP_P` | Generation top-p sampling | `0.9` |

### OpenAI Configuration

| Variable | Description | Default |
|---------|------|--------|
| `OPENAI_API_KEY` | OpenAI API key | **Must set** |
| `OPENAI_API_BASE` | Custom API endpoint | `https://api.openai.com/v1` |
| `OPENAI_ORGANIZATION` | Organization ID | None |
| `TEXT2MEM_EMBEDDING_PROVIDER` | Fixed to "openai" | `openai` |
| `TEXT2MEM_EMBEDDING_MODEL` | Embedding model name | `text-embedding-3-small` |
| `TEXT2MEM_GENERATION_PROVIDER` | Fixed to "openai" | `openai` |
| `TEXT2MEM_GENERATION_MODEL` | Generation model name | `gpt-4o-mini` |

### Ollama Configuration

| Variable | Description | Default |
|---------|------|--------|
| `TEXT2MEM_EMBEDDING_PROVIDER` | Fixed to "ollama" | `ollama` |
| `TEXT2MEM_EMBEDDING_MODEL` | Embedding model name | `nomic-embed-text` |
| `TEXT2MEM_OLLAMA_BASE_URL` | Ollama service URL | `http://localhost:11434` |
| `TEXT2MEM_GENERATION_PROVIDER` | Fixed to "ollama" | `ollama` |
| `TEXT2MEM_GENERATION_MODEL` | Generation model name | `qwen2.5:0.5b` |

### Mock Configuration

Mock mode requires no additional configuration, automatically uses virtual models.

---

## Model Selection

### OpenAI Recommended Models

#### Embedding Models

| Model | Dimensions | Features | Use Case |
|-----|------|------|---------|
| `text-embedding-3-small` | 1536 | **Recommended**, good performance, low cost | General |
| `text-embedding-3-large` | 3072 | Higher precision, higher cost | High precision needs |
| `text-embedding-ada-002` | 1536 | Legacy model | Compatibility |

#### Generation Models

| Model | Features | Use Case |
|-----|------|---------|
| `gpt-4o-mini` | **Recommended**, fast and low cost | General |
| `gpt-4o` | Latest model, high quality output | High quality needs |
| `gpt-4-turbo` | Newer model, balanced quality and cost | Balanced scenarios |
| `gpt-3.5-turbo` | Fast response, lowest cost | Simple tasks |

### Ollama Recommended Models

#### Embedding Models

| Model | Dimensions | Features |
|-----|------|------|
| `nomic-embed-text` | 768 | **Recommended**, good performance |
| `mxbai-embed-large` | 1024 | Optional high-performance model |

#### Generation Models

| Model | Parameters | Features |
|-----|-------|------|
| `qwen2.5:0.5b` | 0.5B | **Recommended**, lightweight |
| `llama3:8b` | 8B | High quality, needs more resources |
| `mistral:7b` | 7B | Alternative option |

---

## Configuration Validation

### Check Environment Status

```bash
python manage.py status
```

Output example:
```
============================================================
ğŸ“Š Text2Mem Environment Status
============================================================

[Environment File]
  âœ… .env configured -> /path/to/.env

[Model Configuration]
  Provider: openai
  Embedding model: openai:text-embedding-3-small
  Generation model: openai:gpt-4o-mini
  OpenAI API Key: âœ… Set

[Database]
  Path: ./text2mem.db
  Status: âœ… Exists

[Dependencies]
  ollama: âœ… Available
  pytest: âœ… Available
```

### View Model Details

```bash
python manage.py models-info
```

Output example:
```
============================================================
ğŸ¤– Model Configuration Details
============================================================

[General Configuration]
  Provider: openai

[Embedding Model]
  Provider: openai
  Model: text-embedding-3-small

[Generation Model]
  Provider: openai
  Model: gpt-4o-mini

[OpenAI Configuration]
  API Key: âœ… Set (sk-pYqTN...)
  API Base: https://api.openai.com/v1
```

### Run Smoke Tests

```bash
# Test current configuration
python manage.py models-smoke

# Test specific provider
python manage.py models-smoke openai
python manage.py models-smoke ollama
python manage.py models-smoke mock
```

---

## Troubleshooting

### OpenAI API Errors

**Problem**: 401 Unauthorized

**Solution**:
```bash
# Check API Key
echo $OPENAI_API_KEY

# Reset
python manage.py config --provider openai --openai-key sk-xxx
```

### Ollama Connection Failed

**Problem**: Connection refused

**Solution**:
```bash
# Start Ollama service
ollama serve

# Check service status
curl http://localhost:11434/api/version
```

### Model Not Found

**Problem**: Model 'xxx' not found

**Solution**:
```bash
# Ollama: Pull model
python manage.py setup-ollama

# OpenAI: Check model name
python manage.py models-info
```

---

# ä¸­æ–‡

## ç›®å½•

- [é…ç½®æ¶æ„](#é…ç½®æ¶æ„-1)
- [å¿«é€Ÿé…ç½®](#å¿«é€Ÿé…ç½®-1)
- [ç¯å¢ƒå˜é‡](#ç¯å¢ƒå˜é‡-1)
- [æ¨¡å‹é€‰æ‹©](#æ¨¡å‹é€‰æ‹©-1)
- [é…ç½®éªŒè¯](#é…ç½®éªŒè¯-1)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤-1)

---

## é…ç½®æ¶æ„

Text2Mem é‡‡ç”¨ **Provider ä¸ Service åˆ†ç¦»** çš„æ¶æ„ï¼š

- **Provider**ï¼šæä¾›æ¨¡å‹æ¥å£ï¼ˆEmbeddingModel / GenerationModelï¼‰
  - Mock: æ¨¡æ‹Ÿæ¨¡å‹ï¼Œç”¨äºæµ‹è¯•
  - Ollama: æœ¬åœ°è¿è¡Œçš„å¼€æºæ¨¡å‹
  - OpenAI: äº‘ç«¯ API æœåŠ¡

- **Service**ï¼šå°è£…é«˜é˜¶èƒ½åŠ›
  - encode (æ–‡æœ¬ç¼–ç )
  - semantic_search (è¯­ä¹‰æœç´¢)
  - summarize (ç”Ÿæˆæ‘˜è¦)
  - label (æ ‡ç­¾å»ºè®®)
  - split (æ–‡æœ¬æ‹†åˆ†)

---

## å¿«é€Ÿé…ç½®

### æ–¹å¼ 1: ä½¿ç”¨ manage.py (æ¨è)

```bash
# Mock æ¨¡å¼ (æµ‹è¯•/å¼€å‘)
python manage.py config --provider mock

# Ollama æ¨¡å¼ (æœ¬åœ°è¿è¡Œ)
python manage.py config --provider ollama \
  --embed-model nomic-embed-text \
  --gen-model qwen2.5:0.5b

# OpenAI æ¨¡å¼ (äº‘ç«¯API)
python manage.py config --provider openai \
  --openai-key sk-xxx \
  --embed-model text-embedding-3-small \
  --gen-model gpt-4o-mini
```

### æ–¹å¼ 2: ç¼–ç¨‹æ–¹å¼

```python
from text2mem.services.service_factory import create_models_service

# è‡ªåŠ¨æ ¹æ®ç¯å¢ƒé€‰æ‹©
service = create_models_service(mode="auto")

# æˆ–å¼ºåˆ¶æŒ‡å®š provider
service = create_models_service(mode="openai")  # "mock" / "ollama" / "openai"
```

### æ–¹å¼ 3: æ‰‹åŠ¨ç¼–è¾‘ .env

```bash
# å¤åˆ¶æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘é…ç½®
nano .env
```

---

## ç¯å¢ƒå˜é‡

### é€šç”¨é…ç½®

é€‚ç”¨äºæ‰€æœ‰ Providerï¼š

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | é»˜è®¤å€¼ |
|---------|------|--------|
| `TEXT2MEM_DB_PATH` | æ•°æ®åº“æ–‡ä»¶è·¯å¾„ | `./text2mem.db` |
| `TEXT2MEM_DB_WAL` | æ˜¯å¦å¯ç”¨ WAL æ¨¡å¼ | `true` |
| `TEXT2MEM_DB_TIMEOUT` | æ•°æ®åº“è¶…æ—¶(ç§’) | `30` |
| `TEXT2MEM_LOG_LEVEL` | æ—¥å¿—çº§åˆ« | `INFO` |
| `TEXT2MEM_TEMPERATURE` | ç”Ÿæˆæ¨¡å‹æ¸©åº¦ | `0.7` |
| `TEXT2MEM_MAX_TOKENS` | ç”Ÿæˆæœ€å¤§ token æ•° | `512` |
| `TEXT2MEM_TOP_P` | ç”Ÿæˆé‡‡æ · top-p | `0.9` |

### OpenAI é…ç½®

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | é»˜è®¤å€¼ |
|---------|------|--------|
| `OPENAI_API_KEY` | OpenAI API å¯†é’¥ | **å¿…é¡»è®¾ç½®** |
| `OPENAI_API_BASE` | è‡ªå®šä¹‰ API ç«¯ç‚¹ | `https://api.openai.com/v1` |
| `OPENAI_ORGANIZATION` | ç»„ç»‡ ID | æ—  |
| `TEXT2MEM_EMBEDDING_PROVIDER` | å›ºå®šä¸º "openai" | `openai` |
| `TEXT2MEM_EMBEDDING_MODEL` | åµŒå…¥æ¨¡å‹åç§° | `text-embedding-3-small` |
| `TEXT2MEM_GENERATION_PROVIDER` | å›ºå®šä¸º "openai" | `openai` |
| `TEXT2MEM_GENERATION_MODEL` | ç”Ÿæˆæ¨¡å‹åç§° | `gpt-4o-mini` |

### Ollama é…ç½®

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | é»˜è®¤å€¼ |
|---------|------|--------|
| `TEXT2MEM_EMBEDDING_PROVIDER` | å›ºå®šä¸º "ollama" | `ollama` |
| `TEXT2MEM_EMBEDDING_MODEL` | åµŒå…¥æ¨¡å‹åç§° | `nomic-embed-text` |
| `TEXT2MEM_OLLAMA_BASE_URL` | Ollama æœåŠ¡ URL | `http://localhost:11434` |
| `TEXT2MEM_GENERATION_PROVIDER` | å›ºå®šä¸º "ollama" | `ollama` |
| `TEXT2MEM_GENERATION_MODEL` | ç”Ÿæˆæ¨¡å‹åç§° | `qwen2.5:0.5b` |

### Mock é…ç½®

Mock æ¨¡å¼æ— éœ€é¢å¤–é…ç½®ï¼Œè‡ªåŠ¨ä½¿ç”¨è™šæ‹Ÿæ¨¡å‹ã€‚

---

## æ¨¡å‹é€‰æ‹©

### OpenAI æ¨èæ¨¡å‹

#### åµŒå…¥æ¨¡å‹

| æ¨¡å‹ | ç»´åº¦ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|-----|------|------|---------|
| `text-embedding-3-small` | 1536 | **æ¨è**ï¼Œæ€§èƒ½å¥½ï¼Œæˆæœ¬ä½ | é€šç”¨åœºæ™¯ |
| `text-embedding-3-large` | 3072 | æ›´é«˜ç²¾åº¦ï¼Œæˆæœ¬è¾ƒé«˜ | é«˜ç²¾åº¦éœ€æ±‚ |
| `text-embedding-ada-002` | 1536 | æ—§ç‰ˆæ¨¡å‹ | å…¼å®¹æ€§ |

#### ç”Ÿæˆæ¨¡å‹

| æ¨¡å‹ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|-----|------|---------|
| `gpt-4o-mini` | **æ¨è**ï¼Œå¿«é€Ÿä¸”æˆæœ¬ä½ | é€šç”¨åœºæ™¯ |
| `gpt-4o` | æœ€æ–°æ¨¡å‹ï¼Œé«˜è´¨é‡è¾“å‡º | é«˜è´¨é‡éœ€æ±‚ |
| `gpt-4-turbo` | è¾ƒæ–°æ¨¡å‹ï¼Œè´¨é‡ä¸æˆæœ¬é€‚ä¸­ | å¹³è¡¡åœºæ™¯ |
| `gpt-3.5-turbo` | å¿«é€Ÿå“åº”ï¼Œæˆæœ¬æœ€ä½ | ç®€å•ä»»åŠ¡ |

### Ollama æ¨èæ¨¡å‹

#### åµŒå…¥æ¨¡å‹

| æ¨¡å‹ | ç»´åº¦ | ç‰¹ç‚¹ |
|-----|------|------|
| `nomic-embed-text` | 768 | **æ¨è**ï¼Œæ€§èƒ½å¥½ |
| `mxbai-embed-large` | 1024 | å¯é€‰é«˜æ€§èƒ½æ¨¡å‹ |

#### ç”Ÿæˆæ¨¡å‹

| æ¨¡å‹ | å‚æ•°é‡ | ç‰¹ç‚¹ |
|-----|-------|------|
| `qwen2.5:0.5b` | 0.5B | **æ¨è**ï¼Œè½»é‡çº§ |
| `llama3:8b` | 8B | é«˜è´¨é‡ï¼Œéœ€æ›´å¤šèµ„æº |
| `mistral:7b` | 7B | æ›¿ä»£é€‰é¡¹ |

---

## é…ç½®éªŒè¯

### æ£€æŸ¥ç¯å¢ƒçŠ¶æ€

```bash
python manage.py status
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
ğŸ“Š Text2Mem ç¯å¢ƒçŠ¶æ€
============================================================

[ç¯å¢ƒæ–‡ä»¶]
  âœ… .env å·²é…ç½® -> /path/to/.env

[æ¨¡å‹é…ç½®]
  Provider: openai
  åµŒå…¥æ¨¡å‹: openai:text-embedding-3-small
  ç”Ÿæˆæ¨¡å‹: openai:gpt-4o-mini
  OpenAI API Key: âœ… å·²è®¾ç½®

[æ•°æ®åº“]
  è·¯å¾„: ./text2mem.db
  çŠ¶æ€: âœ… å­˜åœ¨

[ä¾èµ–å·¥å…·]
  ollama: âœ… å¯ç”¨
  pytest: âœ… å¯ç”¨
```

### æŸ¥çœ‹æ¨¡å‹è¯¦æƒ…

```bash
python manage.py models-info
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
ğŸ¤– æ¨¡å‹é…ç½®è¯¦æƒ…
============================================================

[æ€»ä½“é…ç½®]
  Provider: openai

[åµŒå…¥æ¨¡å‹]
  Provider: openai
  Model: text-embedding-3-small

[ç”Ÿæˆæ¨¡å‹]
  Provider: openai
  Model: gpt-4o-mini

[OpenAI é…ç½®]
  API Key: âœ… å·²è®¾ç½® (sk-pYqTN...)
  API Base: https://api.openai.com/v1
```

### è¿è¡Œå†’çƒŸæµ‹è¯•

```bash
# æµ‹è¯•å½“å‰é…ç½®
python manage.py models-smoke

# æµ‹è¯•ç‰¹å®š provider
python manage.py models-smoke openai
python manage.py models-smoke ollama
python manage.py models-smoke mock
```

---

## æ•…éšœæ’é™¤

### OpenAI API é”™è¯¯

**é—®é¢˜**: 401 Unauthorized

**è§£å†³**:
```bash
# æ£€æŸ¥ API Key
echo $OPENAI_API_KEY

# é‡æ–°è®¾ç½®
python manage.py config --provider openai --openai-key sk-xxx
```

### Ollama è¿æ¥å¤±è´¥

**é—®é¢˜**: Connection refused

**è§£å†³**:
```bash
# å¯åŠ¨ Ollama æœåŠ¡
ollama serve

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:11434/api/version
```

### æ¨¡å‹æœªæ‰¾åˆ°

**é—®é¢˜**: Model 'xxx' not found

**è§£å†³**:
```bash
# Ollama: æ‹‰å–æ¨¡å‹
python manage.py setup-ollama

# OpenAI: æ£€æŸ¥æ¨¡å‹åç§°
python manage.py models-info
```

---

<div align="center">

**Last Updated | æœ€åæ›´æ–°**: 2025-11-10

[â¬† Back to top | è¿”å›é¡¶éƒ¨](#text2mem-configuration-guide--text2mem-é…ç½®æŒ‡å—)

</div>
