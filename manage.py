#!/usr/bin/env python3
"""
Text2Mem é¡¹ç›®ç®¡ç†å·¥å…·

æä¾›ç»Ÿä¸€çš„ç¯å¢ƒé…ç½®ã€æ¼”ç¤ºã€æµ‹è¯•å’Œäº¤äº’åŠŸèƒ½å…¥å£ã€‚

å¿«é€Ÿå¼€å§‹:
  python manage.py status              # æŸ¥çœ‹ç¯å¢ƒçŠ¶æ€
  python manage.py config --provider ollama  # é…ç½®ç¯å¢ƒ
  python manage.py demo                # è¿è¡Œæ¼”ç¤º
  python manage.py session             # è¿›å…¥äº¤äº’æ¨¡å¼

è¯¦ç»†å¸®åŠ©:
  python manage.py help [command]      # æŸ¥çœ‹å‘½ä»¤å¸®åŠ©
"""
import os
import sys
import subprocess
import json
import argparse
import textwrap
from dataclasses import dataclass
from typing import Any, Callable, Dict, Optional, Tuple, List
from pathlib import Path

# å¯¼å…¥æ ¸å¿ƒå·¥å…·
from scripts.cli_core import (
    echo, load_env_file, ENV_PATH as CORE_ENV_PATH,
    build_models_service_from_env as _build_models_service_from_env,
    build_engine_and_adapter as _build_engine_and_adapter,
)
from scripts.config_helpers import generate_grouped_env
from scripts.env_utils import which

ROOT = Path(__file__).parent
ENV_PATH = CORE_ENV_PATH

# åœ¨å¯åŠ¨æ—¶åŠ è½½ç¯å¢ƒå˜é‡
ENV_VARS = load_env_file(ENV_PATH) if ENV_PATH.exists() else {}


@dataclass(frozen=True)
class CommandInfo:
    name: str
    handler: Callable[[], Optional[int]]
    summary: str
    group: str
    aliases: Tuple[str, ...] = ()
    description: Optional[str] = None

    def matches(self, candidate: str) -> bool:
        return candidate == self.name or candidate in self.aliases


COMMAND_GROUPS: Tuple[Tuple[str, str], ...] = (
    ("core", "ğŸ”§ æ ¸å¿ƒé…ç½®"),
    ("demos", "ğŸ¯ åŠŸèƒ½æ¼”ç¤º"),
    ("workflows", "ğŸ“‹ å·¥ä½œæµæ‰§è¡Œ"),
    ("interaction", "ğŸ’¬ äº¤äº’æ¨¡å¼"),
    ("models", "ğŸ¤– æ¨¡å‹ç®¡ç†"),
    ("ops", "âš™ï¸  è¿ç»´å·¥å…·"),
)


# ============================================================================
# ç¯å¢ƒé…ç½®å‘½ä»¤
# ============================================================================


# ============================================================================
# ç¯å¢ƒé…ç½®å‘½ä»¤
# ============================================================================

def cmd_status():
    """æ˜¾ç¤ºç¯å¢ƒä¸ä¾èµ–çŠ¶æ€"""
    from text2mem.core.config import ModelConfig
    
    env_exists = ENV_PATH.exists()
    cfg = ModelConfig.from_env()
    db_path = os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db'
    
    echo("=" * 60)
    echo("ğŸ“Š Text2Mem ç¯å¢ƒçŠ¶æ€")
    echo("=" * 60)
    
    echo("\n[ç¯å¢ƒæ–‡ä»¶]")
    if env_exists:
        echo(f"  âœ… .env å·²é…ç½® -> {ENV_PATH}")
    else:
        echo(f"  âš ï¸  .env æœªæ‰¾åˆ° -> {ENV_PATH}")
        echo(f"  ğŸ’¡ è¿è¡Œ: python manage.py config --provider ollama")
    
    echo("\n[æ¨¡å‹é…ç½®]")
    echo(f"  Provider: {cfg.provider}")
    echo(f"  åµŒå…¥æ¨¡å‹: {cfg.embedding_provider}:{cfg.embedding_model}")
    echo(f"  ç”Ÿæˆæ¨¡å‹: {cfg.generation_provider}:{cfg.generation_model}")
    
    if cfg.embedding_provider == 'ollama' or cfg.generation_provider == 'ollama':
        ollama_url = os.environ.get('TEXT2MEM_OLLAMA_BASE_URL') or \
                     os.environ.get('OLLAMA_BASE_URL') or \
                     cfg.ollama_base_url
        echo(f"  Ollama URL: {ollama_url}")
    
    if 'openai' in (cfg.provider, cfg.embedding_provider, cfg.generation_provider):
        api_key_set = bool(os.environ.get('OPENAI_API_KEY'))
        echo(f"  OpenAI API Key: {'âœ… å·²è®¾ç½®' if api_key_set else 'âŒ æœªè®¾ç½®'}")
    
    echo("\n[æ•°æ®åº“]")
    db_exists = Path(db_path).exists()
    echo(f"  è·¯å¾„: {db_path}")
    echo(f"  çŠ¶æ€: {'âœ… å­˜åœ¨' if db_exists else 'âš ï¸  æœªåˆ›å»ºï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨åˆ›å»ºï¼‰'}")
    
    echo("\n[ä¾èµ–å·¥å…·]")
    echo(f"  ollama: {'âœ… å¯ç”¨' if which('ollama') else 'âŒ æœªå®‰è£…'}")
    echo(f"  pytest: {'âœ… å¯ç”¨' if which('pytest') else 'âš ï¸  æœªå®‰è£…'}")
    
    echo("")
    return 0

def cmd_config():
	"""ç”Ÿæˆ/æ›´æ–° .env æ–‡ä»¶ã€‚"""
	parser = argparse.ArgumentParser(prog='manage.py config', add_help=False)
	parser.add_argument('--provider', choices=['mock','ollama','openai'], required=True)
	parser.add_argument('--openai-key', default=None)
	parser.add_argument('--ollama-base-url', default='http://localhost:11434')
	parser.add_argument('--embed-model', default=None)
	parser.add_argument('--gen-model', default=None)
	parser.add_argument('--db-path', default='./text2mem.db', help='æ•°æ®åº“è·¯å¾„')
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo('ç”¨æ³•: manage.py config --provider [mock|ollama|openai] [--openai-key ...] [--db-path ...]')
		return 2

	existing = dict(ENV_VARS)
	provider = args.provider
	existing['MODEL_SERVICE'] = provider
	existing['TEXT2MEM_PROVIDER'] = provider
	existing['TEXT2MEM_EMBEDDING_PROVIDER'] = 'openai' if provider=='openai' else ('ollama' if provider=='ollama' else provider)
	existing['TEXT2MEM_GENERATION_PROVIDER'] = existing['TEXT2MEM_EMBEDDING_PROVIDER']
	existing['TEXT2MEM_DB_PATH'] = args.db_path

	if provider == 'mock':
		existing.setdefault('TEXT2MEM_EMBEDDING_MODEL', 'dummy-embedding')
		existing.setdefault('TEXT2MEM_GENERATION_MODEL', 'dummy-llm')
	elif provider == 'ollama':
		existing['TEXT2MEM_OLLAMA_BASE_URL'] = args.ollama_base_url
		existing['OLLAMA_BASE_URL'] = args.ollama_base_url
		existing['TEXT2MEM_EMBEDDING_MODEL'] = args.embed_model or 'nomic-embed-text'
		existing['TEXT2MEM_GENERATION_MODEL'] = args.gen_model or 'qwen2.5:0.5b'
	else:  # openai
		if args.openai_key:
			existing['OPENAI_API_KEY'] = args.openai_key
		existing['TEXT2MEM_EMBEDDING_MODEL'] = args.embed_model or 'text-embedding-3-small'
		existing['TEXT2MEM_GENERATION_MODEL'] = args.gen_model or 'gpt-4o-mini'

	content = generate_grouped_env(existing, provider)
	ENV_PATH.write_text(content, encoding='utf-8')
	echo(f"âœ… å·²å†™å…¥ .env -> {ENV_PATH}")
	echo(f"ğŸ’¡ æç¤º: è¿è¡Œ 'python manage.py status' éªŒè¯é…ç½®")
	return 0

def cmd_setup_ollama():
	"""æ‹‰å–å¸¸ç”¨ Ollama æ¨¡å‹ã€‚"""
	exe = which('ollama')
	if not exe:
		echo('âŒ æœªæ‰¾åˆ° ollama å¯æ‰§è¡Œæ–‡ä»¶ï¼Œè¯·å…ˆå®‰è£… https://ollama.ai')
		echo('ğŸ’¡ å®‰è£…æŒ‡å—: https://github.com/ollama/ollama#readme')
		return 1
	
	from text2mem.core.config import ModelConfig
	cfg = ModelConfig.for_ollama()
	emb = os.environ.get('TEXT2MEM_EMBEDDING_MODEL') or cfg.embedding_model
	gen = os.environ.get('TEXT2MEM_GENERATION_MODEL') or cfg.generation_model
	
	echo("ğŸš€ å¼€å§‹æ‹‰å– Ollama æ¨¡å‹...")
	echo(f"â¬‡ï¸  åµŒå…¥æ¨¡å‹: {emb}")
	try:
		subprocess.run([exe, 'pull', emb], check=True)
		echo(f"âœ… {emb} ä¸‹è½½å®Œæˆ")
	except Exception as e:
		echo(f"âŒ æ‹‰å– {emb} å¤±è´¥: {e}")
		return 1
	
	echo(f"â¬‡ï¸  ç”Ÿæˆæ¨¡å‹: {gen}")
	try:
		subprocess.run([exe, 'pull', gen], check=True)
		echo(f"âœ… {gen} ä¸‹è½½å®Œæˆ")
	except Exception as e:
		echo(f"âŒ æ‹‰å– {gen} å¤±è´¥: {e}")
		return 1
	
	echo('ğŸ‰ æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼')
	echo('ğŸ’¡ è¿è¡Œ python manage.py models-smoke æµ‹è¯•æ¨¡å‹')
	return 0

def cmd_setup_openai():
	"""åˆå§‹åŒ– OpenAI é…ç½®åˆ° .envã€‚"""
	parser = argparse.ArgumentParser(prog='manage.py setup-openai', add_help=False)
	parser.add_argument('--api-key', dest='api_key', default=None)
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo('ç”¨æ³•: manage.py setup-openai [--api-key sk-...]'); return 2
	existing = dict(ENV_VARS)
	existing['MODEL_SERVICE'] = 'openai'
	existing['TEXT2MEM_PROVIDER'] = 'openai'
	existing['TEXT2MEM_EMBEDDING_PROVIDER'] = 'openai'
	existing['TEXT2MEM_GENERATION_PROVIDER'] = 'openai'
	if args.api_key:
		existing['OPENAI_API_KEY'] = args.api_key
	existing.setdefault('TEXT2MEM_EMBEDDING_MODEL', 'text-embedding-3-small')
	existing.setdefault('TEXT2MEM_GENERATION_MODEL', 'gpt-3.5-turbo')
	content = generate_grouped_env(existing, 'openai')
	ENV_PATH.write_text(content, encoding='utf-8')
	echo(f"âœ… å·²æ›´æ–° .env -> {ENV_PATH}")
	return 0

def cmd_test():
	"""è¿è¡Œæµ‹è¯•ï¼ˆä¼˜å…ˆ pytestï¼Œå¦åˆ™åšæœ€å°å†’çƒŸï¼‰ã€‚"""
	parser = argparse.ArgumentParser(prog='manage.py test', add_help=False)
	parser.add_argument('-v', '--verbose', action='store_true', help='è¯¦ç»†è¾“å‡º')
	parser.add_argument('-k', '--keyword', default=None, help='ä»…è¿è¡ŒåŒ¹é…çš„æµ‹è¯•')
	parser.add_argument('--smoke', action='store_true', help='ä»…è¿è¡Œå†’çƒŸæµ‹è¯•')
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		args = argparse.Namespace(verbose=False, keyword=None, smoke=False)
	
	if args.smoke:
		echo('ğŸ§ª è¿è¡Œæœ€å°å†’çƒŸæµ‹è¯•...')
		try:
			service = _build_models_service_from_env(None)
			emb = service.encode_memory('hello embeddings')
			echo(f"âœ… Embedding ok, dim={emb.dimension}, model={emb.model}")
			gen = service.generation_model.generate('ä¸€å¥è¯æ€»ç»“ï¼šText2Mem æ˜¯ä»€ä¹ˆï¼Ÿ')
			echo(f"âœ… Generation ok, model={gen.model}")
			echo(f"ğŸ“ è¾“å‡º: {gen.text[:100]}...")
			return 0
		except Exception as e:
			echo(f"âŒ å†’çƒŸå¤±è´¥: {e}")
			return 1
	
	try:
		cmd = [sys.executable, '-m', 'pytest']
		if args.verbose:
			cmd.append('-v')
		else:
			cmd.append('-q')
		if args.keyword:
			cmd.extend(['-k', args.keyword])
		
		echo(f"ğŸ§ª è¿è¡Œæµ‹è¯•: {' '.join(cmd)}")
		r = subprocess.run(cmd, cwd=str(ROOT))
		return r.returncode
	except Exception as e:
		echo(f'âš ï¸ æ— æ³•è¿è¡Œ pytest: {e}')
		echo('ğŸ’¡ å®‰è£… pytest: pip install pytest')
		return 1

def cmd_models_info():
	"""æ˜¾ç¤ºå½“å‰æ¨¡å‹è§£æé…ç½®ã€‚"""
	from text2mem.core.config import ModelConfig
	cfg = ModelConfig.from_env()
	
	echo("=" * 60)
	echo("ğŸ¤– æ¨¡å‹é…ç½®è¯¦æƒ…")
	echo("=" * 60)
	echo(f"\n[æ€»ä½“é…ç½®]")
	echo(f"  Provider: {cfg.provider}")
	
	echo(f"\n[åµŒå…¥æ¨¡å‹]")
	echo(f"  Provider: {cfg.embedding_provider}")
	echo(f"  Model: {cfg.embedding_model}")
	
	echo(f"\n[ç”Ÿæˆæ¨¡å‹]")
	echo(f"  Provider: {cfg.generation_provider}")
	echo(f"  Model: {cfg.generation_model}")
	
	if cfg.embedding_provider == 'ollama' or cfg.generation_provider == 'ollama':
		echo(f"\n[Ollama é…ç½®]")
		echo(f"  Base URL: {cfg.ollama_base_url}")
	
	if cfg.embedding_provider == 'openai' or cfg.generation_provider == 'openai':
		echo(f"\n[OpenAI é…ç½®]")
		api_key = os.environ.get('OPENAI_API_KEY', '')
		echo(f"  API Key: {'âœ… å·²è®¾ç½® (' + api_key[:8] + '...)' if api_key else 'âŒ æœªè®¾ç½®'}")
		if os.environ.get('OPENAI_API_BASE'):
			echo(f"  API Base: {os.environ.get('OPENAI_API_BASE')}")
	
	echo("")
	return 0



def cmd_ir():
	"""æ‰§è¡Œå•æ¡ IR JSONã€‚"""
	parser = argparse.ArgumentParser(prog='manage.py ir', add_help=False)
	parser.add_argument('--mode', choices=['mock','ollama','openai','auto'], default=None)
	group = parser.add_mutually_exclusive_group(required=True)
	group.add_argument('--file', dest='file_path')
	group.add_argument('--inline', dest='inline_json')
	parser.add_argument('--db', dest='db_path', default=None)
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo("ç”¨æ³•: manage.py ir [--mode mock|ollama|openai|auto] (--file path.json | --inline '{...}') [--db path]"); return 2

	service, engine = _build_engine_and_adapter(args.mode, args.db_path)
	if args.file_path:
		ir = json.loads(Path(args.file_path).read_text(encoding='utf-8'))
	else:
		ir = json.loads(args.inline_json)
	res = engine.execute(ir)
	if not getattr(res, 'success', False):
		echo(f"âŒ æ‰§è¡Œå¤±è´¥: {res.error}"); return 1
	data = res.data or {}
	try:
		preview = json.dumps(data, ensure_ascii=False)[:400]
	except Exception:
		preview = str(data)[:400]
	echo(f"âœ… æ‰§è¡ŒæˆåŠŸ | {preview}{'â€¦' if len(preview)>=400 else ''}")
	return 0


def cmd_run_demo():
	"""è¿è¡Œæ¼”ç¤ºï¼šæ‰¹é‡æ‰§è¡Œé¢„ç½®æµç¨‹æˆ–å•æ¡ IR ç¤ºä¾‹ã€‚
	ç”¨æ³•: python manage.py demo [--mode mock|ollama|openai|auto] [--db path] [--set workflows|individual|scenarios]
	- workflows: ä¾æ¬¡è¿è¡Œ examples/op_workflows ä¸‹çš„å¤šæ­¥éª¤æ“ä½œå·¥ä½œæµ
	- individual: é€ä¸ªæ‰§è¡Œ examples/ir_operations ä¸‹çš„å•æ¡ IR ç¤ºä¾‹
	- scenarios: ä¾æ¬¡è¿è¡Œ examples/real_world_scenarios ä¸‹çš„ç°å®æƒ…å¢ƒå·¥ä½œæµ
	"""
	parser = argparse.ArgumentParser(prog='manage.py demo', add_help=False)
	parser.add_argument('--mode', choices=['mock','ollama','openai','auto'], default=None)
	parser.add_argument('--db', dest='db_path', default=None)
	parser.add_argument('--set', choices=['workflows','individual','scenarios'], default='workflows')
	parser.add_argument('--verbose', action='store_true', help='è¯¦ç»†è¾“å‡º')
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo('ç”¨æ³•: python manage.py demo [--mode mock|ollama|openai|auto] [--db path] [--set workflows|individual|scenarios] [--verbose]')
		return 2

	service, engine = _build_engine_and_adapter(args.mode, args.db_path)
	db_path_display = args.db_path or os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db'
	
	echo("=" * 60)
	echo("ğŸ¯ Text2Mem æ¼”ç¤ºæ¨¡å¼")
	echo("=" * 60)
	echo(f"ğŸ§  æ¨¡å‹æœåŠ¡: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")
	echo(f"ğŸ—„ï¸  æ•°æ®åº“: {db_path_display}")
	echo(f"ğŸ“¦ æ¼”ç¤ºé›†: {args.set}")
	echo("=" * 60)
	echo("")

	from text2mem.core.engine import Text2MemEngine
	from text2mem.adapters.sqlite_adapter import SQLiteAdapter
	adapter = SQLiteAdapter(args.db_path or os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db', models_service=service)
	engine = Text2MemEngine(adapter=adapter, models_service=service)

	import json as _json

	def _echo_ir_result(ir_obj, out, verbose=False):
		op = ir_obj.get('op') if isinstance(ir_obj, dict) else None
		if verbose:
			try:
				echo(f"   ğŸ“„ å®Œæ•´è¾“å‡º: {_json.dumps(out, ensure_ascii=False)[:300]}...")
			except Exception:
				pass
		
		if op == 'Encode':
			rid = None
			if isinstance(out, dict):
				rid = out.get('inserted_id') or out.get('id')
			echo(f"   âœ… Encode | id={rid} dim={out.get('embedding_dim') if isinstance(out, dict) else 'n/a'}")
		elif op == 'Retrieve':
			if isinstance(out, list):
				rows = out
			elif isinstance(out, dict):
				rows = out.get('rows') or out.get('matches') or []
			else:
				rows = []
			echo(f"   âœ… Retrieve | æ£€ç´¢åˆ° {len(rows)} æ¡è®°å½•")
			if verbose and rows:
				for idx, row in enumerate(rows[:2], 1):
					echo(f"      [{idx}] {str(row)[:80]}...")
		elif op == 'Summarize':
			summary = ''
			if isinstance(out, dict):
				summary = str(out.get('summary',''))
			echo(f"   âœ… Summarize | {summary[:100]}{'â€¦' if len(summary)>100 else ''}")
		else:
			affected = None
			if isinstance(out, dict):
				affected = out.get('affected_rows') or out.get('updated_rows') or out.get('success_count')
			if affected is not None:
				echo(f"   âœ… {op} | å—å½±å“è¡Œæ•°: {affected}")
			else:
				echo(f"   âœ… {op} | å®Œæˆ")

	ran = 0
	failed = 0
	
	if args.set == 'individual':
		ir_dir = ROOT / 'examples' / 'ir_operations'
		if not ir_dir.exists():
			echo(f'â„¹ï¸  ç›®å½•ä¸å­˜åœ¨: {ir_dir}')
			return 0
		files = sorted(ir_dir.glob('*.json'))
		if not files:
			echo('â„¹ï¸  æœªæ‰¾åˆ° examples/ir_operations ä¸‹çš„ç¤ºä¾‹ã€‚')
			return 0
		for path in files:
			ir = _json.loads(path.read_text(encoding='utf-8'))
			echo(f"ğŸš€ æ‰§è¡Œ {path.name} -> {ir.get('op')} ({ir.get('stage')})")
			try:
				res = engine.execute(ir)
			except Exception as e:
				echo(f"âŒ æ‰§è¡Œå¼‚å¸¸: {e}")
				failed += 1
				continue
			if not getattr(res, 'success', False):
				echo(f"âŒ å¤±è´¥: {res.error}")
				failed += 1
				continue
			out = res.data or {}
			_echo_ir_result(ir, out, args.verbose)
			ran += 1
		echo(f"\n{'='*60}")
		echo(f"ğŸ‰ Demo å®Œæˆ | æˆåŠŸ: {ran} | å¤±è´¥: {failed}")
		return 0 if failed == 0 else 1

	if args.set == 'scenarios':
		wf_dir = ROOT / 'examples' / 'real_world_scenarios'
		if not wf_dir.exists():
			echo(f'â„¹ï¸  ç›®å½•ä¸å­˜åœ¨: {wf_dir}')
			return 0
		files = sorted(wf_dir.glob('*.json'))
		if not files:
			echo('â„¹ï¸  æœªæ‰¾åˆ° examples/real_world_scenarios ä¸‹çš„å·¥ä½œæµã€‚')
			return 0
		for path in files:
			data = _json.loads(path.read_text(encoding='utf-8'))
			steps = data.get('steps', [])
			echo(f"ğŸš€ è¿è¡Œåœºæ™¯: {path.name} | {len(steps)} æ­¥éª¤")
			for i, step in enumerate(steps, start=1):
				ir = step.get('ir') or step
				title = step.get('name') or step.get('description') or f'step {i}'
				echo(f"â¡ï¸  [{i}/{len(steps)}] {title} -> {ir.get('op')}")
				try:
					res = engine.execute(ir)
				except Exception as e:
					echo(f"âŒ æ‰§è¡Œå¼‚å¸¸: {e}")
					failed += 1
					continue
				if not getattr(res, 'success', False):
					echo(f"âŒ å¤±è´¥: {res.error}")
					failed += 1
					continue
				out = res.data or {}
				_echo_ir_result(ir, out, args.verbose)
				ran += 1
		echo(f"\n{'='*60}")
		echo(f"ğŸ‰ Demo å®Œæˆ | æˆåŠŸ: {ran} | å¤±è´¥: {failed}")
		return 0 if failed == 0 else 1

	# workflows: run curated op workflows
	wf_dir = ROOT / 'examples' / 'op_workflows'
	if not wf_dir.exists():
		echo(f'â„¹ï¸  ç›®å½•ä¸å­˜åœ¨: {wf_dir}')
		return 0
	
	files = [
		'op_encode.json',
		'op_label.json',
		'op_label_search.json',
		'op_label_via_search.json',
		'op_promote.json',
		'op_promote_search.json',
		'op_promote_remind.json',
		'op_demote.json',
		'op_update.json',
		'op_delete_search.json',
		'op_update_via_search.json',
		'op_delete.json',
		'op_lock.json',
		'op_expire.json',
		'op_split.json',
		'op_split_custom.json',
		'op_merge.json',
		'op_retrieve.json',
		'op_summarize.json',
	]
	for name in files:
		path = wf_dir / name
		if not path.exists():
			continue
		data = _json.loads(path.read_text(encoding='utf-8'))
		steps = data.get('steps', [])
		echo(f"ğŸš€ è¿è¡Œå·¥ä½œæµ: {name} | {len(steps)} æ­¥éª¤")
		for i, step in enumerate(steps, start=1):
			ir = step.get('ir') or step
			title = step.get('name') or f'step {i}'
			echo(f"â¡ï¸  [{i}/{len(steps)}] {title} -> {ir.get('op')}")
			try:
				res = engine.execute(ir)
			except Exception as e:
				echo(f"âŒ æ‰§è¡Œå¼‚å¸¸: {e}")
				failed += 1
				continue
			if not getattr(res, 'success', False):
				echo(f"âŒ å¤±è´¥: {res.error}")
				failed += 1
				continue
			out = res.data or {}
			_echo_ir_result(ir, out, args.verbose)
			ran += 1
	echo(f"\n{'='*60}")
	echo(f"ğŸ‰ Demo å®Œæˆ | æˆåŠŸ: {ran} | å¤±è´¥: {failed}")
	return 0 if failed == 0 else 1


def cmd_list_workflows():
	"""åˆ—å‡ºå†…ç½®å·¥ä½œæµæ–‡ä»¶ã€‚"""
	candidates = [ROOT/"examples"/"real_world_scenarios", ROOT/"examples"/"op_workflows", ROOT/"text2mem"/"examples"]
	files = []
	for d in candidates:
		if d.exists():
			files += [p for p in d.glob("*.json")]
	if not files:
		echo("â„¹ï¸ æœªæ‰¾åˆ°ä»»ä½•å·¥ä½œæµæ–‡ä»¶"); return 0
	echo("ğŸ“š å·¥ä½œæµæ–‡ä»¶ï¼š")
	for p in sorted(files):
		echo(f"  - {p.relative_to(ROOT)}")
	return 0





def cmd_session():
	"""æŒä¹…åŒ–ä¼šè¯æ¨¡å¼ï¼šå¯æŒ‡å®šæ•°æ®åº“/æ¨¡å¼ï¼ŒåŠ è½½è„šæœ¬å¹¶é€æ¡æ‰§è¡Œæˆ–äº¤äº’è¾“å…¥ã€‚
	ç”¨æ³•: python manage.py session [--mode mock|ollama|openai|auto] [--db path] [--script file]

	å¯ç”¨æŒ‡ä»¤:
	  help                æ˜¾ç¤ºå¸®åŠ©
	  list                åˆ—å‡ºè„šæœ¬è¡Œ
	  next / n            æ‰§è¡Œä¸‹ä¸€è¡Œè„šæœ¬
	  run <idx>           æ‰§è¡Œè„šæœ¬ç¬¬ idx è¡Œ (ä» 1 å¼€å§‹)
	  
	  # 12ç§IRæ“ä½œçš„å¿«æ·æ–¹å¼:
	  encode <text>       ç¼–ç /åˆ›å»ºè®°å¿† (Encode)
	  retrieve <query>    æ£€ç´¢è®°å¿† (Retrieve)
	  label <id> <tags>   ç»™è®°å½•æ‰“æ ‡ç­¾ (Label)
	  update <id> <text>  æ›´æ–°è®°å½•å†…å®¹ (Update)
	  delete <id>         åˆ é™¤è®°å½• (Delete)
	  promote <id>        æå‡è®°å½•ä¼˜å…ˆçº§ (Promote)
	  demote <id>         é™ä½è®°å½•ä¼˜å…ˆçº§ (Demote)
	  lock <id>           é”å®šè®°å½• (Lock)
	  merge <ids>         åˆå¹¶å¤šä¸ªè®°å½•ï¼Œæ ¼å¼: merge 2,3 into 1 (Merge)
	  split <id>          æ‹†åˆ†è®°å½• (Split)
	  expire <id> <ttl>   è®¾ç½®è®°å½•è¿‡æœŸæ—¶é—´ (Expire)
	  summarize <ids>     ç”Ÿæˆå¤šæ¡è®°å½•çš„æ‘˜è¦ (Summarize)
	  
	  ir <json>           æ‰§è¡Œå•æ¡ IR JSON
	  switch-db <path>    åˆ‡æ¢æ•°æ®åº“ (é‡å»ºå¼•æ“)
	  db                  æ˜¾ç¤ºå½“å‰æ•°æ®åº“
	  history             æ˜¾ç¤ºå·²æ‰§è¡ŒæŒ‡ä»¤å†å²
	  save <path>         ä¿å­˜å†å²åˆ°æ–‡ä»¶
	  output brief|full   åˆ‡æ¢è¾“å‡ºæ¨¡å¼
	  quit/exit           é€€å‡º
	  
	é¢å¤–æ”¯æŒï¼š
	  â€¢ ç›´æ¥ç²˜è´´å•æ¡ IR JSONã€IR åˆ—è¡¨æˆ–åŒ…å« steps çš„å·¥ä½œæµ JSON
	  â€¢ è„šæœ¬æ–‡ä»¶ä¸­çš„ JSON è¡Œä¼šè¢«è‡ªåŠ¨è¯†åˆ«å¹¶æ‰§è¡Œ
	"""
	parser = argparse.ArgumentParser(prog='manage.py session', add_help=False)
	parser.add_argument('--mode', choices=['mock','ollama','openai','auto'], default=None)
	parser.add_argument('--db', dest='db_path', default=None)
	parser.add_argument('--script', dest='script_path', default=None)
	parser.add_argument('--output', choices=['brief','full'], default='brief', help='è¾“å‡ºæ¨¡å¼ (brief|full)')
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo('ç”¨æ³•: python manage.py session [--mode mock|ollama|openai|auto] [--db path] [--script file]'); sys.exit(2)

	service, engine = _build_engine_and_adapter(args.mode, args.db_path)
	db_path = args.db_path or os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db'
	echo(f"ğŸ§  æ¨¡å‹æœåŠ¡: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")
	echo(f"ğŸ—„ï¸  æ•°æ®åº“: {db_path}")
	output_mode = args.output  # 'brief' or 'full'

	script_lines: list[str] = []
	if args.script_path:
		sp = Path(args.script_path)
		if not sp.exists():
			echo(f"âš ï¸ è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {sp}")
		else:
			script_lines = [ln.rstrip('\n') for ln in sp.read_text(encoding='utf-8').splitlines()]
			echo(f"ğŸ“„ å·²åŠ è½½è„šæœ¬ {sp} å…± {len(script_lines)} è¡Œ")
	script_ptr = 0  # next line index
	history: list[str] = []

	def rebuild_engine(new_db: str):
		nonlocal service, engine, db_path
		db_path = new_db
		service, engine = _build_engine_and_adapter(args.mode, db_path)
		echo(f"ğŸ” å·²åˆ‡æ¢æ•°æ®åº“å¹¶é‡å»ºå¼•æ“ -> {db_path}")

	def exec_ir(ir: dict):
		try:
			res = engine.execute(ir)
		except Exception as e:
			echo(f"âŒ IR æ‰§è¡Œå¼‚å¸¸: {e}")
			return
		if not getattr(res, 'success', False):
			echo(f"âŒ å¤±è´¥: {res.error}")
			if output_mode == 'full':
				try:
					echo(json.dumps({'error': getattr(res,'error',None)}, ensure_ascii=False))
				except Exception:
					pass
			return
		data = res.data or {}
		op = ir.get('op')
		if output_mode == 'full':
			# å®Œæ•´ JSON è¾“å‡º
			try:
				echo(json.dumps({'op': op, 'success': True, 'data': data}, ensure_ascii=False))
			except Exception:
				echo(str(data))
			return
		# brief æ¨¡å¼
		if op == 'Encode':
			rid = data.get('inserted_id') or data.get('id')
			echo(f"âœ… Encode id={rid} dim={data.get('embedding_dim')}")
			return
		if op == 'Retrieve':
			rows = data.get('rows') if isinstance(data, dict) else (data if isinstance(data, list) else [])
			echo(f"âœ… Retrieve rows={len(rows)}")
			for idx, row in enumerate(rows[:3], 1):  # æ˜¾ç¤ºå‰3æ¡
				text_preview = (row.get('text') or '')[:60]
				echo(f"   [{idx}] id={row.get('id')} {text_preview}{'...' if len(text_preview)>=60 else ''}")
			return
		if op == 'Summarize':
			summary = str(data.get('summary',''))
			echo(f"âœ… Summarize -> {summary[:160]}{'â€¦' if len(summary)>160 else ''}")
			return
		affected = data.get('affected_rows') or data.get('updated_rows') or data.get('success_count')
		if affected is not None:
			echo(f"âœ… {op} affected={affected}")
		else:
			echo(f"âœ… {op} å®Œæˆ")

	def run_inline_workflow(payload: dict) -> bool:
		steps = payload.get('steps')
		if not isinstance(steps, list):
			return False
		name = payload.get('name') or payload.get('title') or 'workflow'
		echo(f"ğŸ§¾ æ‰§è¡Œå†…è”å·¥ä½œæµ: {name} | æ­¥éª¤æ•° {len(steps)}")
		executed = False
		for idx, step in enumerate(steps, start=1):
			if not isinstance(step, dict):
				echo(f"âš ï¸ è·³è¿‡æ— æ•ˆæ­¥éª¤ {idx}: ç±»å‹ {type(step).__name__}")
				continue
			ir = step.get('ir') or step
			if not isinstance(ir, dict) or not ir.get('op'):
				echo(f"âš ï¸ è·³è¿‡æ­¥éª¤ {idx}: æœªæ‰¾åˆ°åˆæ³•çš„ IR")
				continue
			title = step.get('name') or ir.get('name') or f'step {idx}'
			echo(f"â¡ï¸  [{idx}/{len(steps)}] {title} -> {ir.get('op')}")
			exec_ir(ir)
			executed = True
		return executed

	def execute_json_payload(obj: Any) -> bool:
		if isinstance(obj, dict):
			if obj.get('op'):
				exec_ir(obj)
				return True
			if run_inline_workflow(obj):
				return True
			echo('âš ï¸ JSON å¯¹è±¡ç¼ºå°‘å¯æ‰§è¡Œå†…å®¹ (éœ€è¦ op æˆ– steps)')
			return False
		if isinstance(obj, list):
			executed_any = False
			for idx, item in enumerate(obj, start=1):
				echo(f"ğŸ“¦ å¤„ç†åˆ—è¡¨å…ƒç´  {idx}/{len(obj)}")
				executed_any |= execute_json_payload(item)
			return executed_any
		echo('âš ï¸ ä¸æ”¯æŒçš„ JSON ç±»å‹ï¼Œé¢„æœŸå¯¹è±¡æˆ–æ•°ç»„')
		return False

	def run_script_line(idx: int):
		nonlocal script_ptr
		if idx < 1 or idx > len(script_lines):
			echo("âš ï¸ è¡Œå·è¶…å‡ºèŒƒå›´")
			return
		line = script_lines[idx-1].strip()
		script_ptr = idx  # set pointer to this
		if not line or line.startswith('#'):
			echo(f"(è·³è¿‡ç©º/æ³¨é‡Šè¡Œ {idx})")
			return
		echo(f"â–¶ï¸ [è„šæœ¬è¡Œ{idx}] {line}")
		process_command(line)

	def process_command(line: str):
		nonlocal script_ptr, output_mode
		line = line.strip()
		if not line:
			return
		# è‹¥æ•´è¡Œæ˜¯ JSONï¼ˆIRï¼‰ç›´æ¥å°è¯•æ‰§è¡Œ
		if line[0] in '{[':
			try:
				obj = json.loads(line)
			except Exception as e:
				echo(f"JSON è§£æå¤±è´¥: {e}")
				return
			history.append(line)
			if execute_json_payload(obj):
				return
			else:
				return
		history.append(line)
		parts = line.split(' ', 1)
		cmd = parts[0]
		arg = parts[1] if len(parts) > 1 else ''
		
		if cmd in ('quit','exit'):
			raise SystemExit(0)
		if cmd == 'help':
			echo("""å‘½ä»¤:
  åŸºç¡€: help|list|next|n|run <i>|db|history|save <p>|output (brief|full)|quit
  12ç§æ“ä½œå¿«æ·æ–¹å¼:
    encode <text>           - ç¼–ç /åˆ›å»ºè®°å¿† (Encode)
    retrieve <query>        - æ£€ç´¢è®°å¿† (Retrieve)
    label <id> <tags>       - æ‰“æ ‡ç­¾ï¼Œå¤šä¸ªæ ‡ç­¾ç”¨é€—å·åˆ†éš” (Label)
    update <id> <text>      - æ›´æ–°è®°å½•å†…å®¹ (Update)
    delete <id>             - åˆ é™¤è®°å½• (Delete)
    promote <id>            - æå‡ä¼˜å…ˆçº§ (Promote)
    demote <id>             - é™ä½ä¼˜å…ˆçº§ (Demote)
    lock <id>               - é”å®šè®°å½• (Lock)
    merge <ids>             - åˆå¹¶è®°å½•ï¼Œæ ¼å¼: merge 2,3 into 1 (Merge)
    split <id>              - æ‹†åˆ†è®°å½• (Split)
    expire <id> <ttl>       - è®¾ç½®è¿‡æœŸï¼Œå¦‚: P7D=7å¤© (Expire)
    summarize <ids>         - ç”Ÿæˆå¤šæ¡è®°å½•çš„æ‘˜è¦ï¼Œæ ¼å¼: summarize 1,2,3 (Summarize)
  é«˜çº§: ir <json>|switch-db <p>|<ç²˜è´´IR/å·¥ä½œæµJSON>""")
		elif cmd == 'list':
			if not script_lines:
				echo('â„¹ï¸ æœªåŠ è½½è„šæœ¬'); return
			for i,l in enumerate(script_lines, start=1):
				marker = '>>' if (i == script_ptr+1) else '  '
				echo(f"{marker} {i:03d}: {l}")
		elif cmd in ('next','n'):
			if not script_lines:
				echo('â„¹ï¸ æ²¡æœ‰è„šæœ¬'); return
			if script_ptr >= len(script_lines):
				echo('âš ï¸ å·²åˆ°è„šæœ¬æœ«å°¾'); return
			run_script_line(script_ptr+1)
		elif cmd == 'run':
			if not arg.isdigit():
				echo('ç”¨æ³•: run <è¡Œå·>'); return
			run_script_line(int(arg))
		
		# 12ç§æ“ä½œçš„å¿«æ·æ–¹å¼
		elif cmd == 'encode':
			if not arg:
				echo('ç”¨æ³•: encode <text>'); return
			ir = {"stage":"ENC","op":"Encode","args":{"payload":{"text":arg}}}
			exec_ir(ir)
		elif cmd == 'retrieve':
			if not arg:
				echo('ç”¨æ³•: retrieve <query>'); return
			ir = {"stage":"RET","op":"Retrieve","target":{"search":{"intent":{"query":arg},"overrides":{"k":5}}},"args":{}}
			exec_ir(ir)
		elif cmd == 'label':
			parts = arg.split(' ', 1)
			if len(parts) < 2:
				echo('ç”¨æ³•: label <id> <tags> (å¤šä¸ªæ ‡ç­¾ç”¨é€—å·åˆ†éš”)'); return
			record_id, tags_str = parts
			tags = [t.strip() for t in tags_str.split(',')]
			ir = {"stage":"STO","op":"Label","target":{"ids":[record_id]},"args":{"tags":tags,"mode":"add"}}
			exec_ir(ir)
		elif cmd == 'update':
			parts = arg.split(' ', 1)
			if len(parts) < 2:
				echo('ç”¨æ³•: update <id> <new_text>'); return
			record_id, new_text = parts
			ir = {"stage":"STO","op":"Update","target":{"ids":[record_id]},"args":{"set":{"text":new_text}}}
			exec_ir(ir)
		elif cmd == 'delete':
			if not arg:
				echo('ç”¨æ³•: delete <id>'); return
			ir = {"stage":"STO","op":"Delete","target":{"ids":[arg]},"args":{"soft":True}}
			exec_ir(ir)
		elif cmd == 'promote':
			if not arg:
				echo('ç”¨æ³•: promote <id>'); return
			ir = {"stage":"STO","op":"Promote","target":{"ids":[arg]},"args":{"weight_delta":0.2}}
			exec_ir(ir)
		elif cmd == 'demote':
			if not arg:
				echo('ç”¨æ³•: demote <id>'); return
			ir = {"stage":"STO","op":"Demote","target":{"ids":[arg]},"args":{"archive":True}}
			exec_ir(ir)
		elif cmd == 'lock':
			if not arg:
				echo('ç”¨æ³•: lock <id>'); return
			ir = {"stage":"STO","op":"Lock","target":{"ids":[arg]},"args":{"mode":"read_only"}}
			exec_ir(ir)
		elif cmd == 'merge':
			# æ ¼å¼: merge 2,3 into 1 (å°†2,3åˆå¹¶åˆ°1)
			# æˆ–: merge 2,3,4 (å°†2,3åˆå¹¶åˆ°ç¬¬ä¸€ä¸ªï¼Œå³2æ˜¯ä¸»è®°å½•)
			if not arg:
				echo('ç”¨æ³•: merge <child_ids> into <primary_id> æˆ– merge <primary_id>,<child_ids>'); return
			# è§£ææ ¼å¼
			if ' into ' in arg:
				parts = arg.split(' into ')
				child_ids_str = parts[0].strip()
				primary_id = parts[1].strip()
				child_ids = [i.strip() for i in child_ids_str.split(',')]
			else:
				ids_str = arg.split(',')
				if len(ids_str) < 2:
					echo('âš ï¸ è‡³å°‘éœ€è¦2ä¸ªIDè¿›è¡Œåˆå¹¶'); return
				primary_id = ids_str[0].strip()
				child_ids = [i.strip() for i in ids_str[1:]]
			ir = {"stage":"STO","op":"Merge","target":{"ids":child_ids},"args":{"strategy":"merge_into_primary","primary_id":primary_id}}
			exec_ir(ir)
		elif cmd == 'split':
			if not arg:
				echo('ç”¨æ³•: split <id>'); return
			ir = {"stage":"STO","op":"Split","target":{"ids":[arg]},"args":{"strategy":"by_sentences","params":{"by_sentences":{"lang":"zh","max_sentences":3}}}}
			exec_ir(ir)
		elif cmd == 'expire':
			parts = arg.split(' ', 1)
			if len(parts) < 2:
				echo('ç”¨æ³•: expire <id> <ttl> (å¦‚: expire 123 P7D è¡¨ç¤º7å¤©åè¿‡æœŸ)'); return
			record_id, ttl = parts
			ir = {"stage":"STO","op":"Expire","target":{"ids":[record_id]},"args":{"ttl":ttl,"on_expire":"soft_delete"}}
			exec_ir(ir)
		elif cmd == 'summarize':
			# æ ¼å¼: summarize 1,2,3 [focus]
			if not arg:
				echo('ç”¨æ³•: summarize <ids> [focus] (å¤šä¸ªidç”¨é€—å·åˆ†éš”) æˆ– summarize all [focus]'); return
			parts = arg.split(' ', 1)
			ids_or_all = parts[0]
			focus = parts[1] if len(parts) > 1 else "æ€»ä½“æ¦‚è¿°"
			
			if ids_or_all.lower() == 'all':
				# æ€»ç»“æ‰€æœ‰è®°å½•
				ir = {"stage":"RET","op":"Summarize","target":{"all":True},"args":{"focus":focus,"max_tokens":256},"meta":{"confirmation":True}}
			else:
				# æ€»ç»“æŒ‡å®šè®°å½•
				ids = [i.strip() for i in ids_or_all.split(',')]
				ir = {"stage":"RET","op":"Summarize","target":{"ids":ids},"args":{"focus":focus,"max_tokens":256}}
			exec_ir(ir)
		
		# å…¶ä»–å‘½ä»¤
		elif cmd == 'ir':
			try:
				ir = json.loads(arg)
			except Exception as e:
				echo(f"JSON è§£æå¤±è´¥: {e}"); return
			exec_ir(ir)
		elif cmd == 'switch-db':
			if not arg:
				echo('ç”¨æ³•: switch-db <è·¯å¾„>'); return
			rebuild_engine(arg)
		elif cmd == 'db':
			echo(f"å½“å‰æ•°æ®åº“: {db_path}")
		elif cmd == 'history':
			for i,h in enumerate(history, start=1):
				echo(f"{i:03d}: {h}")
		elif cmd == 'save':
			if not arg:
				echo('ç”¨æ³•: save <è·¯å¾„>'); return
			try:
				Path(arg).write_text('\n'.join(history), encoding='utf-8')
				echo(f"âœ… å·²ä¿å­˜å†å² -> {arg}")
			except Exception as e:
				echo(f"âŒ ä¿å­˜å¤±è´¥: {e}")
		elif cmd == 'output':
			if arg not in ('brief','full'):
				echo('ç”¨æ³•: output brief|full'); return
			output_mode = arg
			echo(f"ğŸ”§ è¾“å‡ºæ¨¡å¼å·²åˆ‡æ¢ä¸º: {output_mode}")
		else:
			echo('æœªçŸ¥å‘½ä»¤ï¼Œè¾“å…¥ help è·å–å¸®åŠ©')

	echo("è¿›å…¥ä¼šè¯æ¨¡å¼ï¼Œè¾“å…¥ help æŸ¥çœ‹å‘½ä»¤ï¼ŒCtrl+C é€€å‡ºã€‚")
	while True:
		try:
			line = input('session> ')
		except (EOFError, KeyboardInterrupt):
			echo('')
			break
		try:
			process_command(line)
		except SystemExit:
			break
		except Exception as e:
			echo(f"âŒ å¤„ç†å‘½ä»¤æ—¶é”™è¯¯: {e}")
	echo('ğŸ‘‹ é€€å‡º session')
	return 0


## removed duplicate full demo implementation (deprecated)


def cmd_models_smoke():
	"""æœ€å°åŒ–æ¨¡å‹è°ƒç”¨æµ‹è¯•ï¼šåšä¸€æ¬¡ embed + ä¸€æ¬¡ generateã€‚
	ç”¨æ³•:
	  python manage.py models-smoke            # ä¾æ® .env / MODEL_SERVICE
	  python manage.py models-smoke openai     # å¼ºåˆ¶OpenAI
	  python manage.py models-smoke ollama     # å¼ºåˆ¶Ollama
	  python manage.py models-smoke mock       # æ¨¡æ‹Ÿ
	"""
	mode = None
	if len(sys.argv) >= 3:
		mode = sys.argv[2].lower()

	echo("=" * 60)
	echo("ğŸ§ª æ¨¡å‹å†’çƒŸæµ‹è¯•")
	echo("=" * 60)
	
	try:
		service = _build_models_service_from_env(mode)
		from text2mem.services.models_service import GenerationResult
		echo(f"ğŸ”§ ä½¿ç”¨æ¨¡å‹:")
		echo(f"   Embedding: {service.embedding_model.__class__.__name__}")
		echo(f"   Generation: {service.generation_model.__class__.__name__}")
		echo("")

		# 1) æµ‹è¯•åµŒå…¥
		echo("ğŸ“ æµ‹è¯• 1/2: åµŒå…¥æ¨¡å‹...")
		text = "ç”¨äºåµŒå…¥çš„æµ‹è¯•æ–‡æœ¬ã€‚Hello embeddings!"
		emb = service.encode_memory(text)
		echo(f"âœ… Embedding æˆåŠŸ")
		echo(f"   ç»´åº¦: {emb.dimension}")
		echo(f"   æ¨¡å‹: {emb.model}")
		echo("")

		# 2) æµ‹è¯•ç”Ÿæˆ
		echo("ğŸ“ æµ‹è¯• 2/2: ç”Ÿæˆæ¨¡å‹...")
		prompt = "è¯·ç”¨ä¸€å¥è¯æ€»ç»“ï¼šText2Mem æ˜¯ä¸€ä¸ªæ–‡æœ¬è®°å¿†å¤„ç†ç³»ç»Ÿã€‚"
		gen = service.generation_model.generate(prompt, temperature=0.2, max_tokens=60)
		echo(f"âœ… Generation æˆåŠŸ")
		echo(f"   æ¨¡å‹: {gen.model}")
		echo(f"   è¾“å‡º: {gen.text[:150]}{'...' if len(gen.text) > 150 else ''}")
		echo("")
		
		echo("=" * 60)
		echo("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
		echo("=" * 60)
	except Exception as e:
		echo("")
		echo("=" * 60)
		echo(f"âŒ æ¨¡å‹å†’çƒŸæµ‹è¯•å¤±è´¥")
		echo("=" * 60)
		echo(f"é”™è¯¯: {e}")
		echo("")
		echo("ğŸ’¡ æ•…éšœæ’æŸ¥:")
		echo("   1. æ£€æŸ¥ .env é…ç½®: python manage.py status")
		echo("   2. éªŒè¯æ¨¡å‹é…ç½®: python manage.py models-info")
		echo("   3. Ollama ç”¨æˆ·: ç¡®ä¿æœåŠ¡è¿è¡Œ (ollama serve)")
		echo("   4. OpenAI ç”¨æˆ·: æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®")
		sys.exit(1)
	sys.exit(0)

def cmd_run_workflow():
	"""è¿è¡Œä¸€ä¸ªå·¥ä½œæµJSONæ–‡ä»¶ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªIRæ­¥éª¤ã€‚
	ç”¨æ³•:
	  python manage.py workflow <path-to-workflow.json> [--mode mock|ollama|openai|auto] [--db <db_path>] [--verbose]
	"""
	import argparse, json
	from text2mem.core.engine import Text2MemEngine
	from text2mem.adapters.sqlite_adapter import SQLiteAdapter

	parser = argparse.ArgumentParser(prog="manage.py workflow", add_help=False)
	parser.add_argument("workflow", help="å·¥ä½œæµJSONæ–‡ä»¶è·¯å¾„")
	parser.add_argument("--mode", choices=["mock","ollama","openai","auto"], default=None)
	parser.add_argument("--db", dest="db_path", default=None, help="æ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤è¯»å– TEXT2MEM_DB_PATH æˆ– ./text2mem.dbï¼‰")
	parser.add_argument("--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo("ç”¨æ³•: python manage.py workflow <workflow.json> [--mode mock|ollama|openai|auto] [--db path] [--verbose]")
		sys.exit(2)

	wf_path = Path(args.workflow)
	if not wf_path.exists():
		echo(f"âŒ å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨: {wf_path}")
		sys.exit(2)

	db_path = args.db_path or os.environ.get("TEXT2MEM_DB_PATH") or "./text2mem.db"
	service = _build_models_service_from_env(args.mode)
	adapter = SQLiteAdapter(db_path, models_service=service)
	engine = Text2MemEngine(adapter=adapter, models_service=service)

	data = json.loads(wf_path.read_text(encoding="utf-8"))
	workflow_name = data.get("name") or data.get("title") or wf_path.name
	steps = data.get("steps", [])
	
	echo("=" * 60)
	echo(f"ğŸš€ è¿è¡Œå·¥ä½œæµ: {workflow_name}")
	echo("=" * 60)
	echo(f"ğŸ“„ æ–‡ä»¶: {wf_path}")
	echo(f"ğŸ“¦ æ­¥éª¤æ•°: {len(steps)}")
	echo(f"ğŸ§  æ¨¡å‹: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")
	echo(f"ğŸ—„ï¸  æ•°æ®åº“: {db_path}")
	echo("=" * 60)
	echo("")

	success_count = 0
	failed_count = 0
	
	for idx, step in enumerate(steps, start=1):
		title = step.get("name") or step.get("description") or f"Step {step.get('step', idx)}"
		ir = step.get("ir") or step
		if not isinstance(ir, dict) or not ir.get("op"):
			echo(f"âš ï¸  [{idx}/{len(steps)}] è·³è¿‡æ— æ•ˆæ­¥éª¤: {title}")
			continue
		
		echo(f"â¡ï¸  [{idx}/{len(steps)}] {title}")
		echo(f"    æ“ä½œ: {ir.get('op')} | é˜¶æ®µ: {ir.get('stage', 'N/A')}")
		
		try:
			result = engine.execute(ir)
		except Exception as e:
			echo(f"âŒ æ‰§è¡Œå¼‚å¸¸: {e}")
			if args.verbose:
				import traceback
				traceback.print_exc()
			failed_count += 1
			continue

		if not getattr(result, "success", False):
			echo(f"âŒ æ­¥éª¤å¤±è´¥: {result.error}")
			failed_count += 1
			continue

		data_out = result.data or {}
		op = ir.get("op")
		
		if op == "Encode":
			rid = data_out.get("inserted_id") or data_out.get("id")
			emb_dim = data_out.get("embedding_dim")
			echo(f"    âœ… å·²ç¼–ç  | ID={rid}, dim={emb_dim}")
		elif op == "Retrieve":
			rows = []
			if isinstance(data_out, list):
				rows = data_out
			elif isinstance(data_out, dict):
				rows = data_out.get("rows", []) or []
			echo(f"    âœ… æ£€ç´¢æˆåŠŸ | è¿”å› {len(rows)} æ¡è®°å½•")
			if args.verbose and rows:
				echo(f"       ç¤ºä¾‹: {str(rows[0])[:120]}...")
		elif op == "Summarize":
			summary = str(data_out.get("summary", ""))
			echo(f"    âœ… æ‘˜è¦ç”Ÿæˆ | {summary[:120]}{'...' if len(summary) > 120 else ''}")
		else:
			affected = data_out.get("affected_rows") or data_out.get("updated_rows")
			if affected is not None:
				echo(f"    âœ… å®Œæˆ | å—å½±å“è¡Œ: {affected}")
			else:
				echo(f"    âœ… å®Œæˆ")
		
		success_count += 1
		echo("")

	echo("=" * 60)
	echo(f"ğŸ‰ å·¥ä½œæµå®Œæˆ")
	echo("=" * 60)
	echo(f"âœ… æˆåŠŸ: {success_count}/{len(steps)}")
	if failed_count > 0:
		echo(f"âŒ å¤±è´¥: {failed_count}/{len(steps)}")
	echo("=" * 60)
	
	sys.exit(0 if failed_count == 0 else 1)

def cmd_set_env():
	"""è®¾ç½®ç¯å¢ƒå˜é‡"""
	if len(sys.argv) < 4:
		echo("ç”¨æ³•: manage.py set-env KEY VALUE")
		echo("ä¾‹å¦‚: manage.py set-env TEXT2MEM_LOG_LEVEL DEBUG")
		return 1
	
	key = sys.argv[2]
	value = sys.argv[3]
	
	env_path = ROOT / ".env"
	
	# è¯»å–ç°æœ‰çš„ç¯å¢ƒå˜é‡
	existing_vars = {}
	if env_path.exists():
		existing_vars = load_env_file(env_path)
	
	# æ›´æ–°æˆ–æ·»åŠ ç¯å¢ƒå˜é‡
	existing_vars[key] = value
	
	# é‡æ–°æ„å»º.envæ–‡ä»¶
	env_content = "# Text2Mem ç¯å¢ƒé…ç½®\n"
	provider = existing_vars.get("MODEL_SERVICE", "æœªæŒ‡å®š")
	env_content += f"# æä¾›å•†: {provider}\n\n"
	
	# æ·»åŠ é…ç½®åˆ†ç»„
	sections = {
		"æ•°æ®åº“è®¾ç½®": ["DATABASE_PATH", "TEXT2MEM_DB_PATH", "TEXT2MEM_DB_WAL", "TEXT2MEM_DB_TIMEOUT"],
		"åµŒå…¥æ¨¡å‹è®¾ç½®": ["TEXT2MEM_EMBEDDING_PROVIDER", "TEXT2MEM_EMBEDDING_MODEL", "TEXT2MEM_EMBEDDING_BASE_URL"],
		"ç”Ÿæˆæ¨¡å‹è®¾ç½®": ["TEXT2MEM_GENERATION_PROVIDER", "TEXT2MEM_GENERATION_MODEL", "TEXT2MEM_GENERATION_BASE_URL",
					"TEXT2MEM_TEMPERATURE", "TEXT2MEM_MAX_TOKENS", "TEXT2MEM_TOP_P"],
		"OpenAIè®¾ç½®": ["OPENAI_API_KEY", "OPENAI_MODEL", "OPENAI_API_BASE", "OPENAI_ORGANIZATION"],
		"Ollamaè®¾ç½®": ["OLLAMA_BASE_URL", "OLLAMA_MODEL"],
		"å…¶ä»–è®¾ç½®": ["MODEL_SERVICE", "TEXT2MEM_LOG_LEVEL"]
	}
	
	# æ‰¾åˆ°é”®æ‰€å±çš„éƒ¨åˆ†
	key_section = "å…¶ä»–è®¾ç½®"
	for section, keys in sections.items():
		if key in keys:
			key_section = section
			break
	
	# æŒ‰åˆ†ç»„å†™å…¥é…ç½®
	processed_keys = set()
	for section, keys in sections.items():
		# æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å±äºæ­¤éƒ¨åˆ†çš„é…ç½®
		section_keys = [k for k in keys if k in existing_vars]
		if section_keys:
			env_content += f"\n# {section}\n"
			for k in section_keys:
				env_content += f"{k}={existing_vars[k]}\n"
				processed_keys.add(k)
	
	# æ·»åŠ ä»»ä½•æœªåˆ†ç±»çš„é”®
	unprocessed_keys = [k for k in existing_vars if k not in processed_keys]
	if unprocessed_keys:
		env_content += "\n# å…¶ä»–è‡ªå®šä¹‰è®¾ç½®\n"
		for k in unprocessed_keys:
			env_content += f"{k}={existing_vars[k]}\n"
	
	# å†™å…¥æ–‡ä»¶
	env_path.write_text(env_content, encoding="utf-8")
	
	echo(f"âœ… å·²è®¾ç½®ç¯å¢ƒå˜é‡: {key}={value}")
	return 0


def _normalize_docstring(text: Optional[str]) -> str:
	if not text:
		return ""
	return textwrap.dedent(text.expandtabs()).strip()


COMMAND_DEFINITIONS: Tuple[CommandInfo, ...] = (
	CommandInfo("status", cmd_status, "ç¯å¢ƒçŠ¶æ€ (ä¾èµ– / .env / æœåŠ¡æ¢æµ‹)", "core"),
	CommandInfo("config", cmd_config, ".env ç”Ÿæˆ/æ›´æ–° (--provider ...)", "core"),
	CommandInfo("set-env", cmd_set_env, "å¿«é€Ÿå†™å…¥å•ä¸ªç¯å¢ƒå˜é‡", "core", aliases=("set_env",)),
	CommandInfo("models-info", cmd_models_info, "æ˜¾ç¤ºè§£æåçš„æ¨¡å‹é…ç½®", "core"),
	CommandInfo("demo", cmd_run_demo, "æ‰¹é‡æ‰§è¡Œé¢„ç½® IR / å·¥ä½œæµç¤ºä¾‹", "demos"),
	CommandInfo("ir", cmd_ir, "æ‰§è¡Œå•æ¡ IR JSON (--file|--inline)", "demos"),
	CommandInfo("workflow", cmd_run_workflow, "æŒ‰ steps é¡ºåºè¿è¡Œå·¥ä½œæµæ–‡ä»¶", "workflows"),
	CommandInfo("list-workflows", cmd_list_workflows, "åˆ—å‡ºç¤ºä¾‹å·¥ä½œæµ JSON", "workflows", aliases=("list_workflows",)),
	CommandInfo("session", cmd_session, "å¢å¼ºå‹æŒä¹…ä¼šè¯ (æ”¯æŒ12ç§æ“ä½œå¿«æ·æ–¹å¼)", "interaction"),
	CommandInfo("models-smoke", cmd_models_smoke, "æœ€å°æ¨¡å‹å†’çƒŸ (embed + generate)", "models", aliases=("models_smoke",)),
	CommandInfo("setup-ollama", cmd_setup_ollama, "æ‹‰å–é»˜è®¤ Ollama æ¨¡å‹", "ops"),
	CommandInfo("setup-openai", cmd_setup_openai, "ç”Ÿæˆ OpenAI ä½¿ç”¨çš„ .env", "ops"),
	CommandInfo("test", cmd_test, "è¿è¡Œ pytest æˆ–æœ€å°å†’çƒŸ", "ops"),
)


COMMAND_LOOKUP: Dict[str, CommandInfo] = {}
for info in COMMAND_DEFINITIONS:
	COMMAND_LOOKUP[info.name] = info
	for alias in info.aliases:
		COMMAND_LOOKUP[alias] = info


def _command_names(info: CommandInfo) -> str:
	names = [info.name, *info.aliases]
	return ", ".join(names)


def print_usage() -> None:
	echo("Usage: python manage.py <command> [options]")
	echo("")
	for key, label in COMMAND_GROUPS:
		group_items = [info for info in COMMAND_DEFINITIONS if info.group == key]
		if not group_items:
			continue
		echo(f"[{label}]")
		for info in group_items:
			names = _command_names(info)
			echo(f"  {names:<28} {info.summary}")
		echo("")
	echo("ä½¿ç”¨ python manage.py help <command> æŸ¥çœ‹è¯¦ç»†è¯´æ˜ã€‚")
	echo("")
	echo("ç¤ºä¾‹:")
	echo("  python manage.py demo --mode mock")
	echo("  python manage.py ir --mode mock --inline '{\"stage\":\"RET\",\"op\":...")
	echo("  python manage.py session --mode mock --output full")


def print_command_help(name: str) -> int:
	info = COMMAND_LOOKUP.get(name)
	if not info:
		echo(f"æœªçŸ¥å‘½ä»¤: {name}")
		echo("ä½¿ç”¨ python manage.py help æŸ¥çœ‹å¯ç”¨å‘½ä»¤ã€‚")
		return 1
	label = next((lbl for key, lbl in COMMAND_GROUPS if key == info.group), info.group)
	echo(f"å‘½ä»¤: {_command_names(info)}")
	echo(f"åˆ†ç»„: {label}")
	echo(f"æ¦‚è¦: {info.summary}")
	details = _normalize_docstring(info.description or info.handler.__doc__)
	if details:
		echo("")
		for line in details.splitlines():
			echo(line)
	return 0

def main():
	if len(sys.argv) < 2:
		print_usage()
		return 1
	cmd = sys.argv[1]
	if cmd in ('help', '-h', '--help'):
		target = sys.argv[2] if len(sys.argv) > 2 else None
		if not target:
			print_usage()
			return 0
		return print_command_help(target)
	info = COMMAND_LOOKUP.get(cmd)
	if not info:
		echo(f"Unknown command: {cmd}")
		echo("ä½¿ç”¨ python manage.py help æŸ¥çœ‹å‘½ä»¤åˆ—è¡¨ã€‚")
		return 2
	result = info.handler()
	return result if isinstance(result, int) else 0


if __name__ == "__main__":
	sys.exit(main())

