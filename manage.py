#!/usr/bin/env python3
"""
Project manager for Text2Mem

Commands:
  - status: quick environment status
  - config: write a .env file (--provider [ollama|openai])
  - setup-ollama: pull default models via ollama (if installed)
	- setup-openai: create/update .env for OpenAI usage
	- workflow: run a workflow JSON (examples/workflows/*.json)
  - test: run tests (pytest), or smoke integration if pytest absent
	- models-info: show resolved provider/models from current env
	- models-smoke [mode]: minimal embed+generate smoke (mock|ollama|openai|auto)
	- features [--mode ...] [--db ...]: run encode/retrieve/summarize flow
	- ir [--mode ...] (--file path.json | --inline '{...}') [--db ...]: execute a single IR
	- list-workflows: list bundled workflow files
	- repl [--mode ...] [--db ...]: interactive shell to run commands (embed/gen/ir/...)
"""
import os, sys, subprocess, re, json, argparse, time
from pathlib import Path
from scripts.cli_core import (
	echo, load_env_file, ENV_PATH as CORE_ENV_PATH,
	build_models_service_from_env as _build_models_service_from_env,
	build_engine_and_adapter as _build_engine_and_adapter,
)
from scripts.cli_helpers import run_basic_demo, run_full_demo
from scripts.config_helpers import generate_grouped_env
from scripts.env_utils import which

ROOT = Path(__file__).parent
ENV_PATH = CORE_ENV_PATH

# Load env values (and inject into process) once at startup
ENV_VARS = load_env_file(ENV_PATH) if ENV_PATH.exists() else {}


def cmd_status():
	echo("ğŸ“Š Text2Mem status")
	echo(f"  Python: {sys.version.split()[0]}")
	def has(pkg: str):
		try:
			__import__(pkg); return True
		except Exception:
			return False
	echo(f"  httpx: {'âœ…' if has('httpx') else 'âŒ'}")
	echo(f"  sqlalchemy: {'âœ…' if has('sqlalchemy') else 'âŒ'}")
	echo(f"  pytest: {'âœ…' if has('pytest') else 'âŒ'}")
	echo(f"  openai: {'âœ…' if has('openai') else 'âŒ'}")
	try:
		import httpx
		r = httpx.get("http://localhost:11434/api/tags", timeout=3.0)
		ok = r.status_code == 200
	except Exception:
		ok = False
	echo(f"  ollama service: {'âœ…' if ok else 'âŒ'} (http://localhost:11434)")
	echo(f"  OpenAI API key: {'âœ…' if bool(os.environ.get('OPENAI_API_KEY')) else 'âŒ'}")
	env_path = ROOT / '.env'
	echo(f"  .env: {'âœ…' if env_path.exists() else 'âŒ'} ({env_path})")


def cmd_run_demo():
	"""Run demo (basic or full) using shared helpers with optional JSON/perf output."""
	parser = argparse.ArgumentParser(prog='manage.py demo', add_help=False)
	parser.add_argument('--mode', choices=['mock','ollama','openai','auto'], default=None)
	parser.add_argument('--db', dest='db_path', default=None)
	parser.add_argument('--full', action='store_true', help='æ‰§è¡Œæ‰€æœ‰ 12 ç§æ“ä½œ')
	parser.add_argument('--json', action='store_true', help='è¾“å‡º JSON æ€»ç»“')
	parser.add_argument('--perf', action='store_true', help='è¿½åŠ æ€§èƒ½æ‘˜è¦')
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo('ç”¨æ³•: python manage.py demo [--mode mock|ollama|openai|auto] [--db path] [--full] [--json] [--perf]'); sys.exit(2)
	service, engine = _build_engine_and_adapter(args.mode, args.db_path)
	echo(f"ğŸ§  æ¨¡å‹æœåŠ¡: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")
	echo(f"ğŸ—„ï¸  æ•°æ®åº“: {args.db_path or os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db'}")
	start_all = time.time()
	summary = run_full_demo(echo, engine) if args.full else run_basic_demo(echo, engine)
	summary['elapsed_ms'] = round((time.time() - start_all)*1000, 2)
	if args.perf:
		echo(f"â±ï¸ æ€»è€—æ—¶: {summary['elapsed_ms']} ms | æ“ä½œæ•°: {len(summary.get('operations', []))}")
	if args.json:
		try:
			echo(json.dumps(summary, ensure_ascii=False))
		except Exception as e:
			echo(f"âš ï¸ JSON åºåˆ—åŒ–å¤±è´¥: {e}")
	return 0


def cmd_test():
	"""Run tests. Prefer pytest; fallback to integration script."""
	if which("pytest"):
		code = subprocess.call([sys.executable, "-m", "pytest", "-q"])  # quiet
		sys.exit(code)
	code = subprocess.call([sys.executable, str(ROOT / "tests" / "test_complete_integration.py")])
	sys.exit(code)


# --- configuration helpers (re-introduced minimal versions) ---
def cmd_config():
	echo("âš ï¸ cmd_config å·²æš‚æ—¶ç²¾ç®€æˆ–å°šæœªé‡æ–°å®ç°")
	return 0

def cmd_setup_ollama():
	echo("âš ï¸ cmd_setup_ollama æœªåœ¨å½“å‰ç²¾ç®€ç‰ˆæœ¬ä¸­å®ç°")
	return 0

def cmd_setup_openai():
	echo("âš ï¸ cmd_setup_openai å·²è¢«ç²¾ç®€ï¼›ä½¿ç”¨ config_helpers.generate_grouped_env ç”Ÿæˆ .env")
	return 0


# å…¼å®¹æ—§å¼•ç”¨åç§°ï¼ˆå‘åå…¼å®¹å…¶å®ƒè„šæœ¬ï¼‰
_build_models_service_from_env  # noqa: F401
_build_engine_and_adapter  # noqa: F401


def cmd_models_info():
	"""æ‰“å°å½“å‰è§£æåçš„æ¨¡å‹é…ç½®ï¼ˆproviderã€æ¨¡å‹åã€ç«¯ç‚¹ç­‰ï¼‰ã€‚"""
	from text2mem.core.config import ModelConfig
	cfg = ModelConfig.from_env()
	echo("ğŸ§© Models config")
	echo(f"  provider: {cfg.provider}")
	echo(f"  embedding: provider={cfg.embedding_provider} model={cfg.embedding_model} base_url={cfg.embedding_base_url or '-'}")
	echo(f"  generation: provider={cfg.generation_provider} model={cfg.generation_model} base_url={cfg.generation_base_url or '-'}")
	api = cfg.openai_api_base or ''
	echo(f"  openai: key={'set' if bool(cfg.openai_api_key) else 'unset'} api_base={api if api else '-'}")


def cmd_features():
	"""è¿è¡Œä¸€ç»„å…¸å‹åŠŸèƒ½ï¼šEncode -> Retrieve -> Summarizeã€‚
	ç”¨æ³•: python manage.py features [--mode mock|ollama|openai|auto] [--db path]
	"""
	import argparse
	parser = argparse.ArgumentParser(prog="manage.py features", add_help=False)
	parser.add_argument("--mode", choices=["mock","ollama","openai","auto"], default=None)
	parser.add_argument("--db", dest="db_path", default=None)
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo("ç”¨æ³•: python manage.py features [--mode mock|ollama|openai|auto] [--db path]")
		sys.exit(2)

	service, engine = _build_engine_and_adapter(args.mode, args.db_path)
	echo(f"ğŸ§  æ¨¡å‹æœåŠ¡: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")

	# Encode
	ir_enc = {"stage":"ENC","op":"Encode","args":{"payload":{"text":"Text2Mem features test sentence."},"tags":["features"],"use_embedding":True}}
	res = engine.execute(ir_enc)
	if not getattr(res, "success", False):
		echo(f"âŒ Encodeå¤±è´¥: {res.error}"); sys.exit(1)
	row_id = (res.data or {}).get("inserted_id") or (res.data or {}).get("id")
	echo(f"âœ… Encode ok | id={row_id}")

	# Retrieve
	ir_ret = {"stage":"RET","op":"Retrieve","args":{"query":"features","k":3}}
	res = engine.execute(ir_ret)
	if not getattr(res, "success", False):
		echo(f"âŒ Retrieveå¤±è´¥: {res.error}"); sys.exit(1)
	rows = []
	if isinstance(res.data, list): rows = res.data
	elif isinstance(res.data, dict): rows = res.data.get("rows", []) or []
	echo(f"âœ… Retrieve ok | count={len(rows)}")

	# Summarize
	ir_sum = {"stage":"RET","op":"Summarize","args":{"focus":"features","max_tokens":80}}
	res = engine.execute(ir_sum)
	if not getattr(res, "success", False):
		echo(f"âŒ Summarizeå¤±è´¥: {res.error}"); sys.exit(1)
	summary = str((res.data or {}).get("summary",""))
	echo(f"âœ… Summarize ok | {summary[:160]}{'â€¦' if len(summary)>160 else ''}")
	sys.exit(0)


def cmd_ir():
	"""æ‰§è¡Œå•æ¡ IRã€‚
	ç”¨æ³•: python manage.py ir [--mode mock|ollama|openai|auto] (--file path.json | --inline '{...}') [--db path]
	"""
	parser = argparse.ArgumentParser(prog="manage.py ir", add_help=False)
	parser.add_argument("--mode", choices=["mock","ollama","openai","auto"], default=None)
	group = parser.add_mutually_exclusive_group(required=True)
	group.add_argument("--file", dest="file_path", default=None)
	group.add_argument("--inline", dest="inline", default=None)
	parser.add_argument("--db", dest="db_path", default=None)
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo("ç”¨æ³•: python manage.py ir [--mode mock|ollama|openai|auto] (--file path.json | --inline '{...}') [--db path]")
		sys.exit(2)

	if not args.inline and args.file_path and not Path(args.file_path).exists():
		echo(f"âŒ IRæ–‡ä»¶ä¸å­˜åœ¨: {args.file_path}"); sys.exit(2)

	service, engine = _build_engine_and_adapter(args.mode, args.db_path)
	if args.inline:
		try:
			ir = json.loads(args.inline)
		except Exception as e:
			echo(f"âŒ è§£æ inline JSON å¤±è´¥: {e}"); sys.exit(2)
	else:
		ir = json.loads(Path(args.file_path).read_text(encoding="utf-8"))

	res = engine.execute(ir)
	if not getattr(res, "success", False):
		echo(f"âŒ æ‰§è¡Œå¤±è´¥: {res.error}"); sys.exit(1)
	# å‹å¥½è¾“å‡º
	data = res.data or {}
	try:
		preview = json.dumps(data, ensure_ascii=False)[:400]
	except Exception:
		preview = str(data)[:400]
	echo(f"âœ… æ‰§è¡ŒæˆåŠŸ | {preview}{'â€¦' if len(preview)>=400 else ''}")
	sys.exit(0)


def cmd_list_workflows():
	"""åˆ—å‡ºå†…ç½®å·¥ä½œæµæ–‡ä»¶ã€‚"""
	candidates = [ROOT/"examples"/"workflows", ROOT/"text2mem"/"examples"]
	files = []
	for d in candidates:
		if d.exists():
			files += [p for p in d.glob("*.json")]
	if not files:
		echo("â„¹ï¸ æœªæ‰¾åˆ°ä»»ä½•å·¥ä½œæµæ–‡ä»¶"); return 0
	echo("ğŸ“š å·¥ä½œæµæ–‡ä»¶ï¼š")
	for p in sorted(files):
		echo(f"  - {p.relative_to(ROOT)}")
	return 0


def cmd_repl():
	"""äº¤äº’æ¨¡å¼ï¼šæ¥å—å‘½ä»¤è¡Œè¾“å…¥æ‰§è¡Œå¸¸è§æ“ä½œã€‚
	å‘½ä»¤ï¼š
	  embed <text>
	  gen <prompt>
	  ir <json>
	  encode <text>
	  retrieve <query>
	  summarize <focus>
	  help | quit | exit
	å¯é€‰ï¼špython manage.py repl [--mode mock|ollama|openai|auto] [--db path]
	"""
	import argparse
	parser = argparse.ArgumentParser(prog="manage.py repl", add_help=False)
	parser.add_argument("--mode", choices=["mock","ollama","openai","auto"], default=None)
	parser.add_argument("--db", dest="db_path", default=None)
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo("ç”¨æ³•: python manage.py repl [--mode mock|ollama|openai|auto] [--db path]"); sys.exit(2)

	service, engine = _build_engine_and_adapter(args.mode, args.db_path)
	echo(f"ğŸ§  æ¨¡å‹æœåŠ¡: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")
	echo("è¾“å…¥ 'help' æŸ¥çœ‹å‘½ä»¤ï¼Œ'quit' é€€å‡ºã€‚")
	while True:
		try:
			line = input("t2m> ").strip()
		except (EOFError, KeyboardInterrupt):
			echo("")
			break
		if not line:
			continue
		cmd, *rest = line.split(" ", 1)
		arg = rest[0] if rest else ""
		try:
			if cmd in ("quit","exit"):
				break
			elif cmd == "help":
				echo("å‘½ä»¤: embed|gen|ir|encode|retrieve|summarize|quit")
			elif cmd == "embed":
				res = service.encode_memory(arg)
				echo(f"dim={res.dimension} model={res.model}")
			elif cmd == "gen":
				res = service.generation_model.generate(arg)
				echo(res.text)
			elif cmd == "ir":
				ir = json.loads(arg)
				res = engine.execute(ir)
				echo(str(res.data)[:400])
			elif cmd == "encode":
				ir = {"stage":"ENC","op":"Encode","args":{"payload":{"text":arg},"use_embedding":True}}
				res = engine.execute(ir)
				row_id = (res.data or {}).get("inserted_id") or (res.data or {}).get("id")
				echo(f"ok id={row_id}")
			elif cmd == "retrieve":
				ir = {"stage":"RET","op":"Retrieve","args":{"query":arg,"k":5}}
				res = engine.execute(ir)
				rows = []
				if isinstance(res.data, list): rows = res.data
				elif isinstance(res.data, dict): rows = res.data.get("rows", []) or []
				echo(f"{len(rows)} rows")
			elif cmd == "summarize":
				ir = {"stage":"RET","op":"Summarize","args":{"focus":arg,"max_tokens":120}}
				res = engine.execute(ir)
				echo(str((res.data or {}).get("summary","")))
			else:
				echo("æœªçŸ¥å‘½ä»¤ï¼Œè¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
		except Exception as e:
			echo(f"âŒ é”™è¯¯: {e}")
	return 0


def cmd_session():
	"""æŒä¹…åŒ–ä¼šè¯æ¨¡å¼ï¼šå¯æŒ‡å®šæ•°æ®åº“/æ¨¡å¼ï¼ŒåŠ è½½è„šæœ¬å¹¶é€æ¡æ‰§è¡Œæˆ–äº¤äº’è¾“å…¥ã€‚
	ç”¨æ³•: python manage.py session [--mode mock|ollama|openai|auto] [--db path] [--script file]

	å¯ç”¨æŒ‡ä»¤:
	  help               æ˜¾ç¤ºå¸®åŠ©
	  list               åˆ—å‡ºè„šæœ¬è¡Œ
	  next / n           æ‰§è¡Œä¸‹ä¸€è¡Œè„šæœ¬
	  run <idx>          æ‰§è¡Œè„šæœ¬ç¬¬ idx è¡Œ (ä» 1 å¼€å§‹)
	  encode <text>      ç¼–ç ä¸€æ¡è®°å¿†
	  retrieve <query>   æ£€ç´¢
	  summarize <focus>  æ‘˜è¦
	  ir <json>          æ‰§è¡Œå•æ¡ IR JSON
	  switch-db <path>   åˆ‡æ¢æ•°æ®åº“ (é‡å»ºå¼•æ“)
	  db                 æ˜¾ç¤ºå½“å‰æ•°æ®åº“
	  history            æ˜¾ç¤ºå·²æ‰§è¡ŒæŒ‡ä»¤å†å²
	  save <path>        ä¿å­˜å†å²åˆ°æ–‡ä»¶
	  quit/exit          é€€å‡º
	"""
	parser = argparse.ArgumentParser(prog='manage.py session', add_help=False)
	parser.add_argument('--mode', choices=['mock','ollama','openai','auto'], default=None)
	parser.add_argument('--db', dest='db_path', default=None)
	parser.add_argument('--script', dest='script_path', default=None)
	parser.add_argument('--output', choices=['brief','full'], default='brief', help='è¾“å‡ºæ¨¡å¼ (brief|full)')
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo('ç”¨æ³•: python manage.py session [--mode mock|ollama|openai|auto] [--db path] [--script file]'); sys.exit(2)

	service, engine = _build_engine_and_adapter(args.mode, args.db_path)
	db_path = args.db_path or os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db'
	echo(f"ğŸ§  æ¨¡å‹æœåŠ¡: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")
	echo(f"ğŸ—„ï¸  æ•°æ®åº“: {db_path}")
	output_mode = args.output  # 'brief' or 'full'

	script_lines: list[str] = []
	if args.script_path:
		sp = Path(args.script_path)
		if not sp.exists():
			echo(f"âš ï¸ è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {sp}")
		else:
			script_lines = [ln.rstrip('\n') for ln in sp.read_text(encoding='utf-8').splitlines()]
			echo(f"ğŸ“„ å·²åŠ è½½è„šæœ¬ {sp} å…± {len(script_lines)} è¡Œ")
	script_ptr = 0  # next line index
	history: list[str] = []

	def rebuild_engine(new_db: str):
		nonlocal service, engine, db_path
		db_path = new_db
		service, engine = _build_engine_and_adapter(args.mode, db_path)
		echo(f"ğŸ” å·²åˆ‡æ¢æ•°æ®åº“å¹¶é‡å»ºå¼•æ“ -> {db_path}")

	def exec_ir(ir: dict):
		try:
			res = engine.execute(ir)
		except Exception as e:
			echo(f"âŒ IR æ‰§è¡Œå¼‚å¸¸: {e}")
			return
		if not getattr(res, 'success', False):
			echo(f"âŒ å¤±è´¥: {res.error}")
			if output_mode == 'full':
				try:
					echo(json.dumps({'error': getattr(res,'error',None)}, ensure_ascii=False))
				except Exception:
					pass
			return
		data = res.data or {}
		op = ir.get('op')
		if output_mode == 'full':
			# å®Œæ•´ JSON è¾“å‡º
			try:
				echo(json.dumps({'op': op, 'success': True, 'data': data}, ensure_ascii=False))
			except Exception:
				echo(str(data))
			return
		# brief æ¨¡å¼
		if op == 'Encode':
			rid = data.get('inserted_id') or data.get('id')
			echo(f"âœ… Encode id={rid} dim={data.get('embedding_dim')}")
			return
		if op == 'Retrieve':
			rows = data.get('rows') if isinstance(data, dict) else []
			echo(f"âœ… Retrieve rows={len(rows)}")
			return
		if op == 'Summarize':
			summary = str(data.get('summary',''))
			echo(f"âœ… Summarize -> {summary[:160]}{'â€¦' if len(summary)>160 else ''}")
			return
		affected = data.get('affected_rows') or data.get('updated_rows')
		if affected is not None:
			echo(f"âœ… {op} affected={affected}")
		else:
			echo(f"âœ… {op} å®Œæˆ")

	def run_script_line(idx: int):
		nonlocal script_ptr
		if idx < 1 or idx > len(script_lines):
			echo("âš ï¸ è¡Œå·è¶…å‡ºèŒƒå›´")
			return
		line = script_lines[idx-1].strip()
		script_ptr = idx  # set pointer to this
		if not line or line.startswith('#'):
			echo(f"(è·³è¿‡ç©º/æ³¨é‡Šè¡Œ {idx})")
			return
		echo(f"â–¶ï¸ [è„šæœ¬è¡Œ{idx}] {line}")
		process_command(line)

	def process_command(line: str):
		nonlocal script_ptr
		line = line.strip()
		if not line:
			return
		# è‹¥æ•´è¡Œæ˜¯ JSONï¼ˆIRï¼‰ç›´æ¥å°è¯•æ‰§è¡Œ
		if line[0] in '{[':
			try:
				obj = json.loads(line)
				if isinstance(obj, dict) and obj.get('op'):
					history.append(line)
					exec_ir(obj)
					return
			except Exception:
				pass  # ç»§ç»­æŒ‰æ™®é€šå‘½ä»¤è§£æ
		history.append(line)
		parts = line.split(' ', 1)
		cmd = parts[0]
		arg = parts[1] if len(parts) > 1 else ''
		if cmd in ('quit','exit'):
			raise SystemExit(0)
		if cmd == 'help':
			echo("å‘½ä»¤: help|list|next|n|run <i>|encode <t>|retrieve <q>|summarize <f>|ir <json>|switch-db <p>|db|history|save <p>|output (brief|full)|quit|<ç›´æ¥ç²˜è´´IR JSON>")
		elif cmd == 'list':
			if not script_lines:
				echo('â„¹ï¸ æœªåŠ è½½è„šæœ¬'); return
			for i,l in enumerate(script_lines, start=1):
				marker = '>>' if (i == script_ptr+1) else '  '
				echo(f"{marker} {i:03d}: {l}")
		elif cmd in ('next','n'):
			if not script_lines:
				echo('â„¹ï¸ æ²¡æœ‰è„šæœ¬'); return
			if script_ptr >= len(script_lines):
				echo('âš ï¸ å·²åˆ°è„šæœ¬æœ«å°¾'); return
			run_script_line(script_ptr+1)
		elif cmd == 'run':
			if not arg.isdigit():
				echo('ç”¨æ³•: run <è¡Œå·>'); return
			run_script_line(int(arg))
		elif cmd == 'encode':
			ir = {"stage":"ENC","op":"Encode","args":{"payload":{"text":arg},"use_embedding":True}}
			exec_ir(ir)
		elif cmd == 'retrieve':
			ir = {"stage":"RET","op":"Retrieve","args":{"query":arg,"k":5}}
			exec_ir(ir)
		elif cmd == 'summarize':
			ir = {"stage":"RET","op":"Summarize","args":{"focus":arg,"max_tokens":160}}
			exec_ir(ir)
		elif cmd == 'ir':
			try:
				ir = json.loads(arg)
			except Exception as e:
				echo(f"JSON è§£æå¤±è´¥: {e}"); return
			exec_ir(ir)
		elif cmd == 'switch-db':
			if not arg:
				echo('ç”¨æ³•: switch-db <è·¯å¾„>'); return
			rebuild_engine(arg)
		elif cmd == 'db':
			echo(f"å½“å‰æ•°æ®åº“: {db_path}")
		elif cmd == 'history':
			for i,h in enumerate(history, start=1):
				echo(f"{i:03d}: {h}")
		elif cmd == 'save':
			if not arg:
				echo('ç”¨æ³•: save <è·¯å¾„>'); return
			try:
				Path(arg).write_text('\n'.join(history), encoding='utf-8')
				echo(f"âœ… å·²ä¿å­˜å†å² -> {arg}")
			except Exception as e:
				echo(f"âŒ ä¿å­˜å¤±è´¥: {e}")
		elif cmd == 'output':
			if arg not in ('brief','full'):
				echo('ç”¨æ³•: output brief|full'); return
			output_mode = arg
			echo(f"ğŸ”§ è¾“å‡ºæ¨¡å¼å·²åˆ‡æ¢ä¸º: {output_mode}")
		else:
			echo('æœªçŸ¥å‘½ä»¤ï¼Œè¾“å…¥ help è·å–å¸®åŠ©')

	echo("è¿›å…¥ä¼šè¯æ¨¡å¼ï¼Œè¾“å…¥ help æŸ¥çœ‹å‘½ä»¤ï¼ŒCtrl+C é€€å‡ºã€‚")
	while True:
		try:
			line = input('session> ')
		except (EOFError, KeyboardInterrupt):
			echo('')
			break
		try:
			process_command(line)
		except SystemExit:
			break
		except Exception as e:
			echo(f"âŒ å¤„ç†å‘½ä»¤æ—¶é”™è¯¯: {e}")
	echo('ğŸ‘‹ é€€å‡º session')
	return 0


def cmd_run_demo():
	"""è¿è¡Œæ¼”ç¤º: é»˜è®¤ç®€å•(ç¼–ç /æ£€ç´¢/æ‘˜è¦)ï¼Œä½¿ç”¨ --full è¿è¡Œ 12 ç±»æ“ä½œã€‚
	ç”¨æ³•: python manage.py demo [--mode mock|ollama|openai|auto] [--db path] [--full]
	"""
	import argparse, json, time
	parser = argparse.ArgumentParser(prog="manage.py demo", add_help=False)
	parser.add_argument("--mode", choices=["mock","ollama","openai","auto"], default=None)
	parser.add_argument("--db", dest="db_path", default=None)
	parser.add_argument("--full", action="store_true", help="æ‰§è¡Œæ‰€æœ‰ 12 ç§æ“ä½œ")
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo("ç”¨æ³•: python manage.py demo [--mode mock|ollama|openai|auto] [--db path] [--full]")
		sys.exit(2)

	service, engine = _build_engine_and_adapter(args.mode, args.db_path)
	echo(f"ğŸ§  æ¨¡å‹æœåŠ¡: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")
	echo(f"ğŸ—„ï¸  æ•°æ®åº“: {args.db_path or os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db'}")

	def _run(ir: dict, title: str):
		"""ç»Ÿä¸€æ‰§è¡Œå¹¶æ‰“å°ç»“æœæ‘˜è¦"""
		start = time.time()
		res = engine.execute(ir)
		ok = getattr(res, 'success', False)
		data = res.data if ok else {}
		dur = (time.time() - start) * 1000
		if not ok:
			echo(f"âŒ {title} å¤±è´¥: {res.error}")
			return None
		op = ir.get("op")
		if op == "Encode":
			rid = data.get("inserted_id") or data.get("id")
			echo(f"âœ… {title} -> id={rid} dim={data.get('embedding_dim')} ({dur:.1f}ms)")
			return rid
		if op == "Retrieve":
			rows = data.get("rows") if isinstance(data, dict) else []
			echo(f"âœ… {title} -> {len(rows)} rows ({dur:.1f}ms)")
		elif op == "Summarize":
			summary = str(data.get("summary",""))
			echo(f"âœ… {title} -> summary {summary[:60]}{'â€¦' if len(summary)>60 else ''} ({dur:.1f}ms)")
		elif op in ("Update","Label","Promote","Demote","Delete","Lock","Expire"):
			affected = data.get("affected_rows") or data.get("updated_rows")
			if affected is not None:
				echo(f"âœ… {title} -> affected={affected} ({dur:.1f}ms)")
			else:
				echo(f"âœ… {title} ({dur:.1f}ms)")
		elif op == "Split":
			echo(f"âœ… {title} -> total_splits={data.get('total_splits')} ({dur:.1f}ms)")
		elif op == "Merge":
			echo(f"âœ… {title} -> merged={data.get('merged_count')} primary={data.get('primary_id')} ({dur:.1f}ms)")
		else:
			echo(f"âœ… {title} ({dur:.1f}ms)")
		return data

	# ç®€å•æ¨¡å¼
	if not args.full:
		echo("â¡ï¸ Encode")
		rid = _run({
			"stage":"ENC","op":"Encode","args":{"payload":{"text":"è¿™æ˜¯ä¸€æ¡æµ‹è¯•è®°å¿†ï¼Œç”¨äºéªŒè¯Text2Memç³»ç»Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œã€‚"},"tags":["æµ‹è¯•","æ¼”ç¤º"],"use_embedding":True}
		}, "Encode")
		echo("â¡ï¸ Retrieve")
		_run({"stage":"RET","op":"Retrieve","args":{"query":"æµ‹è¯•","k":5}}, "Retrieve")
		echo("â¡ï¸ Summarize")
		_run({"stage":"RET","op":"Summarize","args":{"focus":"æµ‹è¯•","max_tokens":120}}, "Summarize")
		return 0

	echo("ğŸš€ è¿è¡Œ FULL DEMO (12 ç±»æ“ä½œ)")
	ids = {}

	# 1) Encode ä¸»è®°å¿†
	ids['main'] = _run({
		"stage":"ENC","op":"Encode","args":{"payload":{"text":"é¡¹ç›®A ç¬¬ä¸€æ¬¡ä¼šè®®ï¼šè®¨è®ºèŒƒå›´ã€ç›®æ ‡ä¸ä¸‹ä¸€æ­¥è®¡åˆ’ã€‚"},"tags":["project","meeting"],"type":"note","use_embedding":True}
	}, "Encode main")

	# 2) Encode æ¬¡è®°å¿†ï¼ˆç”¨äº Mergeï¼‰
	ids['secondary'] = _run({
		"stage":"ENC","op":"Encode","args":{"payload":{"text":"é¡¹ç›®A ç¬¬äºŒæ¬¡ä¼šè®®ï¼šç¡®å®šä»»åŠ¡åˆ†å·¥ä¸é£é™©ã€‚"},"tags":["project","meeting","notes"],"type":"note","use_embedding":True}
	}, "Encode secondary")

	# 3) Encode é•¿æ–‡æœ¬ï¼ˆç”¨äº Splitï¼‰
	long_text = "# æ¦‚è§ˆ\né¡¹ç›®A è¯´æ˜æ–‡æ¡£ã€‚\n# ç›®æ ‡\næå‡åä½œæ•ˆç‡ã€‚\n# è®¡åˆ’\n1. å»ºç«‹çŸ¥è¯†åº“\n2. å‘¨ä¼šè®°å½•\n# é£é™©\nèµ„æºä¸è¶³ä¸å»¶æœŸé£é™©ã€‚"
	ids['long'] = _run({
		"stage":"ENC","op":"Encode","args":{"payload":{"text":long_text},"tags":["doc","long"],"type":"note","use_embedding":True}
	}, "Encode long")

	# 4) Encode temp è®°å¿†ï¼ˆç”¨äº Expireï¼‰
	ids['temp'] = _run({
		"stage":"ENC","op":"Encode","args":{"payload":{"text":"ä¸´æ—¶ç¬”è®°ï¼šæœ¬å‘¨ä¸´æ—¶ä»»åŠ¡è®°å½•"},"tags":["temp","note"],"type":"note","use_embedding":True}
	}, "Encode temp")

	# 5) Encode obsolete è®°å¿†ï¼ˆç”¨äº Deleteï¼‰
	ids['obsolete'] = _run({
		"stage":"ENC","op":"Encode","args":{"payload":{"text":"obsolete record: è¿‡æœŸçš„å‚è€ƒèµ„æ–™"},"tags":["cleanup"],"type":"note","use_embedding":True}
	}, "Encode obsolete")

	# Label ä¸»è®°å¿† (æ·»åŠ  sensitive æ ‡ç­¾)
	_run({
		"stage":"STO","op":"Label","target":{"by_id":str(ids['main']) if ids.get('main') else None},"args":{"tags":["project","meeting","sensitive"]}
	}, "Label main add sensitive")

	# Retrieve project
	_run({"stage":"RET","op":"Retrieve","args":{"query":"é¡¹ç›®A","k":10,"order_by":"time_desc"}}, "Retrieve project")

	# Summarize by tags
	_run({"stage":"RET","op":"Summarize","target":{"by_tags":["project","meeting"],"match":"all"},"args":{"focus":"é¡¹ç›®A ä¼šè®®è¿›å±•","max_tokens":200}}, "Summarize project meetings")

	# Promote main
	_run({"stage":"STO","op":"Promote","target":{"by_id":str(ids['main']) if ids.get('main') else None},"args":{"priority":"urgent"}}, "Promote main")

	# Demote secondary
	_run({"stage":"STO","op":"Demote","target":{"by_id":str(ids['secondary']) if ids.get('secondary') else None},"args":{"archive":True}}, "Demote secondary")

	# Update all project tagged
	_run({"stage":"STO","op":"Update","target":{"by_tags":["project"]},"args":{"set":{"priority":"high","text":"é¡¹ç›®A ä¼šè®®å†…å®¹å·²æ•´ç†"}}}, "Update project")

	# Split long
	_run({"stage":"STO","op":"Split","target":{"by_id":str(ids['long']) if ids.get('long') else None},"args":{"strategy":"headings","inherit":{"tags":True}}}, "Split long doc")

	# Merge meeting (main & secondary)
	_run({"stage":"STO","op":"Merge","target":{"by_tags":["meeting"],"match":"any"},"args":{"strategy":"fold_into_primary","primary_id":str(ids['main']),"soft_delete_children":True}}, "Merge meetings")

	# Lock sensitive
	_run({"stage":"STO","op":"Lock","target":{"by_tags":["sensitive"]},"args":{"mode":"read_only","reason":"ä¿æŠ¤æ•æ„Ÿä¼šè®®è®°å½•"}}, "Lock sensitive")

	# Expire temp
	_run({"stage":"STO","op":"Expire","target":{"by_tags":["temp"]},"args":{"ttl":"P7D","on_expire":"soft_delete"}}, "Expire temp")

	# Delete obsolete by query
	_run({"stage":"STO","op":"Delete","target":{"by_query":"obsolete"},"args":{"soft":True,"reason":"æ¸…ç†è¿‡æ—¶"}}, "Delete obsolete")

	echo("ğŸ‰ FULL DEMO å®Œæˆ (Encode/Label/Retrieve/Summarize/Promote/Demote/Update/Split/Merge/Lock/Expire/Delete)")
	return 0


def cmd_models_smoke():
	"""æœ€å°åŒ–æ¨¡å‹è°ƒç”¨æµ‹è¯•ï¼šåšä¸€æ¬¡ embed + ä¸€æ¬¡ generateã€‚
	ç”¨æ³•:
	  python manage.py models-smoke            # ä¾æ® .env / MODEL_SERVICE
	  python manage.py models-smoke openai     # å¼ºåˆ¶OpenAI
	  python manage.py models-smoke ollama     # å¼ºåˆ¶Ollama
	  python manage.py models-smoke mock       # æ¨¡æ‹Ÿ
	"""
	mode = None
	if len(sys.argv) >= 3:
		mode = sys.argv[2].lower()

	try:
		service = _build_models_service_from_env(mode)
		from text2mem.services.models_service import GenerationResult
		echo(f"ğŸ§ª æ­£åœ¨ä½¿ç”¨: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")

		# 1) æµ‹è¯•åµŒå…¥
		text = "ç”¨äºåµŒå…¥çš„æµ‹è¯•æ–‡æœ¬ã€‚Hello embeddings!"
		emb = service.encode_memory(text)
		echo(f"âœ… Embedding ç»´åº¦: {emb.dimension}, æ¨¡å‹: {emb.model}")

		# 2) æµ‹è¯•ç”Ÿæˆ
		prompt = "è¯·ç”¨ä¸€å¥è¯æ€»ç»“ï¼šText2Mem æ˜¯ä¸€ä¸ªæ–‡æœ¬è®°å¿†å¤„ç†ç³»ç»Ÿã€‚"
		gen = service.generation_model.generate(prompt, temperature=0.2, max_tokens=60)
		echo(f"âœ… Generation æ¨¡å‹: {gen.model}")
		echo(f"ğŸ“ è¾“å‡º: {gen.text[:200]}...")
	except Exception as e:
		echo(f"âŒ æ¨¡å‹å†’çƒŸæµ‹è¯•å¤±è´¥: {e}")
		sys.exit(1)
	sys.exit(0)

def cmd_run_workflow():
	"""è¿è¡Œä¸€ä¸ªå·¥ä½œæµJSONæ–‡ä»¶ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªIRæ­¥éª¤ã€‚
	ç”¨æ³•:
	  python manage.py workflow <path-to-workflow.json> [--mode mock|ollama|openai|auto] [--db <db_path>]
	"""
	import argparse, json
	from text2mem.core.engine import Text2MemEngine
	from text2mem.adapters.sqlite_adapter import SQLiteAdapter

	parser = argparse.ArgumentParser(prog="manage.py workflow", add_help=False)
	parser.add_argument("workflow", help="å·¥ä½œæµJSONæ–‡ä»¶è·¯å¾„")
	parser.add_argument("--mode", choices=["mock","ollama","openai","auto"], default=None)
	parser.add_argument("--db", dest="db_path", default=None, help="æ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤è¯»å– TEXT2MEM_DB_PATH æˆ– ./text2mem.dbï¼‰")
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo("ç”¨æ³•: python manage.py workflow <workflow.json> [--mode mock|ollama|openai|auto] [--db path]")
		sys.exit(2)

	wf_path = Path(args.workflow)
	if not wf_path.exists():
		echo(f"âŒ å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨: {wf_path}")
		sys.exit(2)

	# é€‰æ‹©æ•°æ®åº“
	db_path = args.db_path or os.environ.get("TEXT2MEM_DB_PATH") or "./text2mem.db"
	# æ„å»ºæ¨¡å‹æœåŠ¡
	service = _build_models_service_from_env(args.mode)

	# å¼•æ“ä¸é€‚é…å™¨
	adapter = SQLiteAdapter(db_path, models_service=service)
	engine = Text2MemEngine(adapter=adapter, models_service=service)

	# è¯»å–å·¥ä½œæµ
	data = json.loads(wf_path.read_text(encoding="utf-8"))
	steps = data.get("steps", [])
	echo(f"ğŸš€ è¿è¡Œå·¥ä½œæµ: {wf_path.name} | æ­¥éª¤æ•°: {len(steps)} | DB: {db_path}")
	echo(f"ğŸ§  æ¨¡å‹: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")

	success_count = 0
	for idx, step in enumerate(steps, start=1):
		title = step.get("name") or step.get("description") or f"Step {step.get('step', idx)}"
		ir = step.get("ir") or step  # å®¹é”™ï¼šè‹¥ç›´æ¥æ˜¯IR
		if not isinstance(ir, dict) or not ir.get("op"):
			echo(f"âš ï¸ è·³è¿‡æ— æ•ˆæ­¥éª¤[{idx}]: ç¼ºå°‘IR")
			continue
		echo(f"â¡ï¸ [{idx}/{len(steps)}] {title} -> {ir.get('op')}")
		try:
			result = engine.execute(ir)
		except Exception as e:
			echo(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
			sys.exit(1)

		if not getattr(result, "success", False):
			echo(f"âŒ æ­¥éª¤å¤±è´¥: {result.error}")
			sys.exit(1)

		# ç»“æœæ‘˜è¦è¾“å‡º
		data_out = result.data or {}
		op = ir.get("op")
		if op == "Encode":
			rid = data_out.get("inserted_id") or data_out.get("id")
			emb_dim = data_out.get("embedding_dim")
			emb_model = data_out.get("embedding_model")
			emb_provider = data_out.get("embedding_provider")
			echo(f"   âœ… å·²ç¼–ç ï¼ŒID={rid}")
			if emb_model or emb_dim or emb_provider:
				echo(f"      ğŸ§© å‘é‡: dim={emb_dim} model={emb_model} provider={emb_provider}")
		elif op == "Retrieve":
			rows = []
			if isinstance(data_out, list):
				rows = data_out
			elif isinstance(data_out, dict):
				rows = data_out.get("rows", []) or []
			note = data_out.get("note")
			echo(f"   âœ… æ£€ç´¢åˆ° {len(rows)} æ¡" + (f" | {note}" if note else ""))
			if rows:
				# æ‰“å°ä¸€æ¡ç®€çŸ­é¢„è§ˆ
				import json as _json
				try:
					pv = _json.dumps(rows[0], ensure_ascii=False)[:200]
				except Exception:
					pv = str(rows[0])[:200]
				echo(f"      ğŸ“‹ ç¤ºä¾‹: {pv}â€¦")
		elif op == "Summarize":
			summary = str(data_out.get("summary", ""))
			model = data_out.get("model")
			usage = data_out.get("tokens") or {}
			echo(f"   ğŸ“ æ‘˜è¦: {summary[:200]}{'â€¦' if len(summary)>200 else ''}")
			if model:
				echo(f"      ğŸ” æ¨¡å‹: {model} | tokens: {usage}")
		else:
			# é€šç”¨åé¦ˆ
			affected = data_out.get("affected_rows") or data_out.get("updated_rows")
			if affected is not None:
				echo(f"   âœ… å®Œæˆ | å—å½±å“è¡Œ: {affected}")
			else:
				echo("   âœ… å®Œæˆ")
		success_count += 1

	echo(f"ğŸ‰ å·¥ä½œæµå®Œæˆ: {success_count}/{len(steps)} æ­¥æˆåŠŸ")
	sys.exit(0)

def cmd_set_env():
	"""è®¾ç½®ç¯å¢ƒå˜é‡"""
	if len(sys.argv) < 4:
		echo("ç”¨æ³•: manage.py set-env KEY VALUE")
		echo("ä¾‹å¦‚: manage.py set-env TEXT2MEM_LOG_LEVEL DEBUG")
		return 1
	
	key = sys.argv[2]
	value = sys.argv[3]
	
	env_path = ROOT / ".env"
	
	# è¯»å–ç°æœ‰çš„ç¯å¢ƒå˜é‡
	existing_vars = {}
	if env_path.exists():
		existing_vars = load_env_file(env_path)
	
	# æ›´æ–°æˆ–æ·»åŠ ç¯å¢ƒå˜é‡
	existing_vars[key] = value
	
	# é‡æ–°æ„å»º.envæ–‡ä»¶
	env_content = "# Text2Mem ç¯å¢ƒé…ç½®\n"
	provider = existing_vars.get("MODEL_SERVICE", "æœªæŒ‡å®š")
	env_content += f"# æä¾›å•†: {provider}\n\n"
	
	# æ·»åŠ é…ç½®åˆ†ç»„
	sections = {
		"æ•°æ®åº“è®¾ç½®": ["DATABASE_PATH", "TEXT2MEM_DB_PATH", "TEXT2MEM_DB_WAL", "TEXT2MEM_DB_TIMEOUT"],
		"åµŒå…¥æ¨¡å‹è®¾ç½®": ["TEXT2MEM_EMBEDDING_PROVIDER", "TEXT2MEM_EMBEDDING_MODEL", "TEXT2MEM_EMBEDDING_BASE_URL"],
		"ç”Ÿæˆæ¨¡å‹è®¾ç½®": ["TEXT2MEM_GENERATION_PROVIDER", "TEXT2MEM_GENERATION_MODEL", "TEXT2MEM_GENERATION_BASE_URL",
					"TEXT2MEM_TEMPERATURE", "TEXT2MEM_MAX_TOKENS", "TEXT2MEM_TOP_P"],
		"OpenAIè®¾ç½®": ["OPENAI_API_KEY", "OPENAI_MODEL", "OPENAI_API_BASE", "OPENAI_ORGANIZATION"],
		"Ollamaè®¾ç½®": ["OLLAMA_BASE_URL", "OLLAMA_MODEL"],
		"å…¶ä»–è®¾ç½®": ["MODEL_SERVICE", "TEXT2MEM_LOG_LEVEL"]
	}
	
	# æ‰¾åˆ°é”®æ‰€å±çš„éƒ¨åˆ†
	key_section = "å…¶ä»–è®¾ç½®"
	for section, keys in sections.items():
		if key in keys:
			key_section = section
			break
	
	# æŒ‰åˆ†ç»„å†™å…¥é…ç½®
	processed_keys = set()
	for section, keys in sections.items():
		# æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å±äºæ­¤éƒ¨åˆ†çš„é…ç½®
		section_keys = [k for k in keys if k in existing_vars]
		if section_keys:
			env_content += f"\n# {section}\n"
			for k in section_keys:
				env_content += f"{k}={existing_vars[k]}\n"
				processed_keys.add(k)
	
	# æ·»åŠ ä»»ä½•æœªåˆ†ç±»çš„é”®
	unprocessed_keys = [k for k in existing_vars if k not in processed_keys]
	if unprocessed_keys:
		env_content += "\n# å…¶ä»–è‡ªå®šä¹‰è®¾ç½®\n"
		for k in unprocessed_keys:
			env_content += f"{k}={existing_vars[k]}\n"
	
	# å†™å…¥æ–‡ä»¶
	env_path.write_text(env_content, encoding="utf-8")
	
	echo(f"âœ… å·²è®¾ç½®ç¯å¢ƒå˜é‡: {key}={value}")
	return 0

def main():
	if len(sys.argv) < 2:
		echo("Usage: manage.py <command> [options]")
		echo("")
		echo("[æ ¸å¿ƒ / ç¯å¢ƒ]")
		echo("  status                      ç¯å¢ƒçŠ¶æ€ (ä¾èµ– / .env / æœåŠ¡æ¢æµ‹)")
		echo("  models-info                 å½“å‰æ¨¡å‹è§£æé…ç½®")
		echo("  config --provider <p>       ç”Ÿæˆ/æ›´æ–° .env (mock|ollama|openai)")
		echo("  set-env KEY VALUE           å¿«é€Ÿå†™å…¥å•ä¸ªç¯å¢ƒå˜é‡å¹¶é‡å†™åˆ†ç»„")
		echo("")
		echo("[åŠŸèƒ½æ¼”ç¤º / å…¸å‹æµç¨‹]")
		echo("  demo [--mode --db --full --json --perf]  åŠŸèƒ½æ¼”ç¤º (--full å«12æ“ä½œ)")
		echo("  features [--mode --db]      Encode -> Retrieve -> Summarize å¿«é€Ÿé“¾è·¯")
		echo("  ir [--mode (--file|--inline) --db]  æ‰§è¡Œå•æ¡ IR JSON")
		echo("")
		echo("[å·¥ä½œæµ]")
		echo("  workflow <json> [--mode --db]  è¿è¡Œå·¥ä½œæµæ–‡ä»¶ steps")
		echo("  list-workflows               åˆ—å‡ºå†…ç½®å·¥ä½œæµç¤ºä¾‹")
		echo("")
		echo("[äº¤äº’ / ä¼šè¯]")
		echo("  repl [--mode --db]           ç®€å•äº¤äº’ (embed/gen/ir/...)")
		echo("  session [--mode --db --script file --output full|brief]  æŒä¹…ä¼šè¯")
		echo("")
		echo("[æ¨¡å‹å¿«é€ŸéªŒè¯]")
		echo("  models-smoke [mode]          æœ€å° embed+generate å†’çƒŸ")
		echo("")
		echo("[è¿ç»´ / æµ‹è¯• / ä¾èµ–]")
		echo("  test                         è¿è¡Œæµ‹è¯•å¥—ä»¶ (ä¼˜å…ˆ pytest)")
		echo("  setup-ollama                 å‡†å¤‡/æ‹‰å– Ollama æ¨¡å‹ (å ä½)")
		echo("  setup-openai                 ç”Ÿæˆ OpenAI ç”¨ .env (å ä½)")
		echo("")
		echo("ç¤ºä¾‹:")
		echo("  python manage.py demo --mode mock")
		echo('  python manage.py ir --mode mock --inline "{\"stage\":\"RET\",\"op\":\"Retrieve\",\"args\":{\"query\":\"æµ‹è¯•\",\"k\":2}}"')
		echo("  python manage.py session --mode mock --output full")
		return 1
	cmd = sys.argv[1]
	if cmd == "status":
		cmd_status()
		return 0
	if cmd == "config":
		cmd_config()
		return 0
	if cmd == "set-env":
		return cmd_set_env()
	if cmd == "setup-ollama":
		cmd_setup_ollama()
		return 0
	if cmd == "setup-openai":
		cmd_setup_openai()
		return 0
	if cmd == "test":
		cmd_test()
		return 0
	if cmd == "demo":
		cmd_run_demo()
		return 0
	if cmd == "models-smoke":
		cmd_models_smoke()
		return 0
	if cmd == "models-info":
		cmd_models_info()
		return 0
	if cmd == "features":
		cmd_features()
		return 0
	if cmd == "ir":
		cmd_ir()
		return 0
	if cmd == "list-workflows":
		cmd_list_workflows()
		return 0
	if cmd == "repl":
		cmd_repl()
		return 0
	if cmd == "session":
		cmd_session()
		return 0
	if cmd == "workflow":
		cmd_run_workflow()
		return 0
	echo(f"Unknown command: {cmd}")
	return 2


if __name__ == "__main__":
	sys.exit(main())

