#!/usr/bin/env python3
"""
Text2Mem Project Management Utility

Provides a unified entry point for environment setup, demos, testing, 
and interactive features.

Quick Start:
  python manage.py status                     # Check environment status
  python manage.py config --provider ollama   # Configure environment
  python manage.py demo                       # Run demo
  python manage.py session                    # Enter interactive mode

Detailed Help:
  python manage.py help [command]             # View command help
"""
import os
import sys
import subprocess
import json
import argparse
import textwrap
from dataclasses import dataclass
from typing import Any, Callable, Dict, Optional, Tuple, List
from pathlib import Path

# Import core utilities
from scripts.cli_core import (
    echo, load_env_file, ENV_PATH as CORE_ENV_PATH,
    build_models_service_from_env as _build_models_service_from_env,
    build_engine_and_adapter as _build_engine_and_adapter,
)
from scripts.config_helpers import generate_grouped_env
from scripts.env_utils import which

ROOT = Path(__file__).parent
ENV_PATH = CORE_ENV_PATH

# Load environment variables on startup
ENV_VARS = load_env_file(ENV_PATH) if ENV_PATH.exists() else {}


@dataclass(frozen=True)
class CommandInfo:
    """Metadata for a CLI command."""
    name: str
    handler: Callable[[], Optional[int]]
    summary: str
    group: str
    aliases: Tuple[str, ...] = ()
    description: Optional[str] = None

    def matches(self, candidate: str) -> bool:
        """Check whether a command name or alias matches."""
        return candidate == self.name or candidate in self.aliases


# Command group display order
COMMAND_GROUPS: Tuple[Tuple[str, str], ...] = (
    ("core", "ğŸ”§ Core Configuration"),
    ("demos", "ğŸ¯ Demonstrations"),
    ("workflows", "ğŸ“‹ Workflow Execution"),
    ("interaction", "ğŸ’¬ Interactive Session"),
    ("models", "ğŸ¤– Model Management"),
    ("ops", "âš™ï¸  Operations & Utilities"),
)

# ============================================================================
# Environment & Configuration Commands
# ============================================================================

def cmd_status():
    """Display environment and dependency status."""
    from text2mem.core.config import ModelConfig
    
    env_exists = ENV_PATH.exists()
    cfg = ModelConfig.from_env()
    db_path = os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db'
    
    echo("=" * 60)
    echo("ğŸ“Š Text2Mem Environment Status / Text2Mem ç¯å¢ƒçŠ¶æ€")
    echo("=" * 60)
    
    echo("\n[Environment File / ç¯å¢ƒæ–‡ä»¶]")
    if env_exists:
        echo(f"  âœ… .env configured -> {ENV_PATH} / å·²é…ç½®")
    else:
        echo(f"  âš ï¸  .env not found -> {ENV_PATH} / æœªæ‰¾åˆ°")
        echo(f"  ğŸ’¡ Run: python manage.py config --provider ollama / è¿è¡Œæ­¤å‘½ä»¤ç”Ÿæˆé…ç½®")
    
    echo("\n[Model Configuration / æ¨¡å‹é…ç½®]")
    echo(f"  Provider: {cfg.provider}")
    echo(f"  Embedding Model: {cfg.embedding_provider}:{cfg.embedding_model}")
    echo(f"  Generation Model: {cfg.generation_provider}:{cfg.generation_model}")
    
    if cfg.embedding_provider == 'ollama' or cfg.generation_provider == 'ollama':
        ollama_url = os.environ.get('TEXT2MEM_OLLAMA_BASE_URL') or \
                     os.environ.get('OLLAMA_BASE_URL') or \
                     cfg.ollama_base_url
        echo(f"  Ollama URL: {ollama_url}")
    
    if 'openai' in (cfg.provider, cfg.embedding_provider, cfg.generation_provider):
        api_key_set = bool(os.environ.get('OPENAI_API_KEY'))
        echo(f"  OpenAI API Key: {'âœ… Set / å·²è®¾ç½®' if api_key_set else 'âŒ Not Set / æœªè®¾ç½®'}")
    
    echo("\n[Database / æ•°æ®åº“]")
    db_exists = Path(db_path).exists()
    echo(f"  Path: {db_path}")
    echo(f"  Status: {'âœ… Exists / å·²å­˜åœ¨' if db_exists else 'âš ï¸  Not Created (auto-created on first use) / æœªåˆ›å»ºï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨åˆ›å»ºï¼‰'}")
    
    echo("\n[Dependencies / ä¾èµ–å·¥å…·]")
    echo(f"  ollama: {'âœ… Available / å¯ç”¨' if which('ollama') else 'âŒ Not Installed / æœªå®‰è£…'}")
    echo(f"  pytest: {'âœ… Available / å¯ç”¨' if which('pytest') else 'âš ï¸  Not Installed / æœªå®‰è£…'}")
    
    echo("")
    return 0


def cmd_config():
    """Generate or update .env file."""
    parser = argparse.ArgumentParser(prog='manage.py config', add_help=False)
    parser.add_argument('--provider', choices=['mock','ollama','openai'], required=True)
    parser.add_argument('--openai-key', default=None)
    parser.add_argument('--ollama-base-url', default='http://localhost:11434')
    parser.add_argument('--embed-model', default=None)
    parser.add_argument('--gen-model', default=None)
    parser.add_argument('--db-path', default='./text2mem.db', help='Database path / æ•°æ®åº“è·¯å¾„')
    try:
        args = parser.parse_args(sys.argv[2:])
    except SystemExit:
        echo('Usage / ç”¨æ³•: manage.py config --provider [mock|ollama|openai] [--openai-key ...] [--db-path ...]')
        return 2

    existing = dict(ENV_VARS)
    provider = args.provider
    existing['MODEL_SERVICE'] = provider
    existing['TEXT2MEM_PROVIDER'] = provider
    existing['TEXT2MEM_EMBEDDING_PROVIDER'] = 'openai' if provider=='openai' else ('ollama' if provider=='ollama' else provider)
    existing['TEXT2MEM_GENERATION_PROVIDER'] = existing['TEXT2MEM_EMBEDDING_PROVIDER']
    existing['TEXT2MEM_DB_PATH'] = args.db_path

    if provider == 'mock':
        existing.setdefault('TEXT2MEM_EMBEDDING_MODEL', 'dummy-embedding')
        existing.setdefault('TEXT2MEM_GENERATION_MODEL', 'dummy-llm')
    elif provider == 'ollama':
        existing['TEXT2MEM_OLLAMA_BASE_URL'] = args.ollama_base_url
        existing['OLLAMA_BASE_URL'] = args.ollama_base_url
        existing['TEXT2MEM_EMBEDDING_MODEL'] = args.embed_model or 'nomic-embed-text'
        existing['TEXT2MEM_GENERATION_MODEL'] = args.gen_model or 'qwen2.5:0.5b'
    else:  # openai
        if args.openai_key:
            existing['OPENAI_API_KEY'] = args.openai_key
        existing['TEXT2MEM_EMBEDDING_MODEL'] = args.embed_model or 'text-embedding-3-small'
        existing['TEXT2MEM_GENERATION_MODEL'] = args.gen_model or 'gpt-4o-mini'

    content = generate_grouped_env(existing, provider)
    ENV_PATH.write_text(content, encoding='utf-8')
    echo(f"âœ… .env written successfully -> {ENV_PATH} / å·²å†™å…¥ .env æ–‡ä»¶")
    echo(f"ğŸ’¡ Tip: Run 'python manage.py status' to verify configuration / æç¤ºï¼šå¯è¿è¡Œå‘½ä»¤éªŒè¯é…ç½®")
    return 0


def cmd_setup_ollama():
    """Download commonly used Ollama models."""
    exe = which('ollama')
    if not exe:
        echo('âŒ Ollama executable not found, please install first / æœªæ‰¾åˆ° Ollama å¯æ‰§è¡Œæ–‡ä»¶ï¼Œè¯·å…ˆå®‰è£… https://ollama.ai')
        echo('ğŸ’¡ Installation guide: https://github.com/ollama/ollama#readme')
        return 1
    
    from text2mem.core.config import ModelConfig
    cfg = ModelConfig.for_ollama()
    emb = os.environ.get('TEXT2MEM_EMBEDDING_MODEL') or cfg.embedding_model
    gen = os.environ.get('TEXT2MEM_GENERATION_MODEL') or cfg.generation_model
    
    echo("ğŸš€ Starting Ollama model downloads... / å¼€å§‹æ‹‰å– Ollama æ¨¡å‹...")
    echo(f"â¬‡ï¸  Embedding Model: {emb} / åµŒå…¥æ¨¡å‹")
    try:
        subprocess.run([exe, 'pull', emb], check=True)
        echo(f"âœ… {emb} download complete / ä¸‹è½½å®Œæˆ")
    except Exception as e:
        echo(f"âŒ Failed to download {emb}: {e} / æ‹‰å–å¤±è´¥")
        return 1
    
    echo(f"â¬‡ï¸  Generation Model: {gen} / ç”Ÿæˆæ¨¡å‹")
    try:
        subprocess.run([exe, 'pull', gen], check=True)
        echo(f"âœ… {gen} download complete / ä¸‹è½½å®Œæˆ")
    except Exception as e:
        echo(f"âŒ Failed to download {gen}: {e} / æ‹‰å–å¤±è´¥")
        return 1
    
    echo('ğŸ‰ All models downloaded successfully! / æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼')
    echo('ğŸ’¡ Run python manage.py models-smoke to test / è¿è¡Œå‘½ä»¤æµ‹è¯•æ¨¡å‹')
    return 0


def cmd_setup_openai():
    """Initialize OpenAI configuration into .env."""
    parser = argparse.ArgumentParser(prog='manage.py setup-openai', add_help=False)
    parser.add_argument('--api-key', dest='api_key', default=None)
    try:
        args = parser.parse_args(sys.argv[2:])
    except SystemExit:
        echo('Usage / ç”¨æ³•: manage.py setup-openai [--api-key sk-...]'); return 2
    existing = dict(ENV_VARS)
    existing['MODEL_SERVICE'] = 'openai'
    existing['TEXT2MEM_PROVIDER'] = 'openai'
    existing['TEXT2MEM_EMBEDDING_PROVIDER'] = 'openai'
    existing['TEXT2MEM_GENERATION_PROVIDER'] = 'openai'
    if args.api_key:
        existing['OPENAI_API_KEY'] = args.api_key
    existing.setdefault('TEXT2MEM_EMBEDDING_MODEL', 'text-embedding-3-small')
    existing.setdefault('TEXT2MEM_GENERATION_MODEL', 'gpt-3.5-turbo')
    content = generate_grouped_env(existing, 'openai')
    ENV_PATH.write_text(content, encoding='utf-8')
    echo(f"âœ… .env updated successfully -> {ENV_PATH} / å·²æ›´æ–° .env æ–‡ä»¶")
    return 0


def cmd_test():
    """Run tests (pytest preferred, otherwise minimal smoke test)."""
    parser = argparse.ArgumentParser(prog='manage.py test', add_help=False)
    parser.add_argument('-v', '--verbose', action='store_true', help='Verbose output')
    parser.add_argument('-k', '--keyword', default=None, help='Run tests matching keyword')
    parser.add_argument('--smoke', action='store_true', help='Run only smoke test')
    try:
        args = parser.parse_args(sys.argv[2:])
    except SystemExit:
        args = argparse.Namespace(verbose=False, keyword=None, smoke=False)
    
    if args.smoke:
        echo('ğŸ§ª Running minimal smoke test... / è¿è¡Œæœ€å°å†’çƒŸæµ‹è¯•...')
        try:
            service = _build_models_service_from_env(None)
            emb = service.encode_memory('hello embeddings')
            echo(f"âœ… Embedding ok, dim={emb.dimension}, model={emb.model}")
            gen = service.generation_model.generate('Summarize in one sentence: What is Text2Mem? / ä¸€å¥è¯æ€»ç»“ï¼šText2Mem æ˜¯ä»€ä¹ˆï¼Ÿ')
            echo(f"âœ… Generation ok, model={gen.model}")
            echo(f"ğŸ“ Output: {gen.text[:100]}...")
            return 0
        except Exception as e:
            echo(f"âŒ Smoke test failed: {e} / å†’çƒŸæµ‹è¯•å¤±è´¥")
            return 1
    
    try:
        cmd = [sys.executable, '-m', 'pytest']
        if args.verbose:
            cmd.append('-v')
        else:
            cmd.append('-q')
        if args.keyword:
            cmd.extend(['-k', args.keyword])
        
        echo(f"ğŸ§ª Running tests: {' '.join(cmd)} / è¿è¡Œæµ‹è¯•")
        r = subprocess.run(cmd, cwd=str(ROOT))
        return r.returncode
    except Exception as e:
        echo(f'âš ï¸ Unable to run pytest: {e} / æ— æ³•è¿è¡Œ pytest')
        echo('ğŸ’¡ Install pytest: pip install pytest / å¯é€šè¿‡æ­¤å‘½ä»¤å®‰è£… pytest')
        return 1


def cmd_models_info():
    """Display current model configuration."""
    from text2mem.core.config import ModelConfig
    cfg = ModelConfig.from_env()
    
    echo("=" * 60)
    echo("ğŸ¤– Model Configuration Details / æ¨¡å‹é…ç½®è¯¦æƒ…")
    echo("=" * 60)
    echo(f"\n[General / æ€»ä½“é…ç½®]")
    echo(f"  Provider: {cfg.provider}")
    
    echo(f"\n[Embedding Model / åµŒå…¥æ¨¡å‹]")
    echo(f"  Provider: {cfg.embedding_provider}")
    echo(f"  Model: {cfg.embedding_model}")
    
    echo(f"\n[Generation Model / ç”Ÿæˆæ¨¡å‹]")
    echo(f"  Provider: {cfg.generation_provider}")
    echo(f"  Model: {cfg.generation_model}")
    
    if cfg.embedding_provider == 'ollama' or cfg.generation_provider == 'ollama':
        echo(f"\n[Ollama Configuration / Ollama é…ç½®]")
        echo(f"  Base URL: {cfg.ollama_base_url}")
    
    if cfg.embedding_provider == 'openai' or cfg.generation_provider == 'openai':
        echo(f"\n[OpenAI Configuration / OpenAI é…ç½®]")
        api_key = os.environ.get('OPENAI_API_KEY', '')
        echo(f"  API Key: {'âœ… Set (' + api_key[:8] + '...) / å·²è®¾ç½®' if api_key else 'âŒ Not Set / æœªè®¾ç½®'}")
        if os.environ.get('OPENAI_API_BASE'):
            echo(f"  API Base: {os.environ.get('OPENAI_API_BASE')}")
    
    echo("")
    return 0

def cmd_ir():
    """Execute a single IR JSON command."""
    parser = argparse.ArgumentParser(prog='manage.py ir', add_help=False)
    parser.add_argument('--mode', choices=['mock','ollama','openai','auto'], default=None)
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--file', dest='file_path')
    group.add_argument('--inline', dest='inline_json')
    parser.add_argument('--db', dest='db_path', default=None)
    try:
        args = parser.parse_args(sys.argv[2:])
    except SystemExit:
        echo("Usage / ç”¨æ³•: manage.py ir [--mode mock|ollama|openai|auto] (--file path.json | --inline '{...}') [--db path]"); 
        return 2

    service, engine = _build_engine_and_adapter(args.mode, args.db_path)
    if args.file_path:
        ir = json.loads(Path(args.file_path).read_text(encoding='utf-8'))
    else:
        ir = json.loads(args.inline_json)
    res = engine.execute(ir)
    if not getattr(res, 'success', False):
        echo(f"âŒ Execution failed: {res.error} / æ‰§è¡Œå¤±è´¥"); 
        return 1
    data = res.data or {}
    try:
        preview = json.dumps(data, ensure_ascii=False)[:400]
    except Exception:
        preview = str(data)[:400]
    echo(f"âœ… Execution successful | {preview}{'â€¦' if len(preview)>=400 else ''} / æ‰§è¡ŒæˆåŠŸ")
    return 0


def cmd_run_demo():
    """Run demonstration: batch execution of predefined workflows or single IR samples.
    
    Usage / ç”¨æ³•:
      python manage.py demo [--mode mock|ollama|openai|auto] [--db path] [--set workflows|individual|scenarios]

    - workflows: Run multi-step operation workflows under examples/op_workflows
    - individual: Execute individual IR examples under examples/ir_operations
    - scenarios: Run realistic scenario workflows under examples/real_world_scenarios
    """
    parser = argparse.ArgumentParser(prog='manage.py demo', add_help=False)
    parser.add_argument('--mode', choices=['mock','ollama','openai','auto'], default=None)
    parser.add_argument('--db', dest='db_path', default=None)
    parser.add_argument('--set', choices=['workflows','individual','scenarios'], default='workflows')
    parser.add_argument('--verbose', action='store_true', help='Verbose output')
    try:
        args = parser.parse_args(sys.argv[2:])
    except SystemExit:
        echo('Usage / ç”¨æ³•: python manage.py demo [--mode mock|ollama|openai|auto] [--db path] [--set workflows|individual|scenarios] [--verbose]')
        return 2

    service, engine = _build_engine_and_adapter(args.mode, args.db_path)
    db_path_display = args.db_path or os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db'
    
    echo("=" * 60)
    echo("ğŸ¯ Text2Mem Demo Mode / Text2Mem æ¼”ç¤ºæ¨¡å¼")
    echo("=" * 60)
    echo(f"ğŸ§  Model Service: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")
    echo(f"ğŸ—„ï¸  Database: {db_path_display} / æ•°æ®åº“")
    echo(f"ğŸ“¦ Demo Set: {args.set} / æ¼”ç¤ºé›†")
    echo("=" * 60)
    echo("")

    from text2mem.core.engine import Text2MemEngine
    from text2mem.adapters.sqlite_adapter import SQLiteAdapter
    adapter = SQLiteAdapter(args.db_path or os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db', models_service=service)
    engine = Text2MemEngine(adapter=adapter, models_service=service)

    import json as _json

    def _echo_ir_result(ir_obj, out, verbose=False):
        op = ir_obj.get('op') if isinstance(ir_obj, dict) else None
        if verbose:
            try:
                echo(f"   ğŸ“„ Full Output: {_json.dumps(out, ensure_ascii=False)[:300]}... / å®Œæ•´è¾“å‡º")
            except Exception:
                pass
        
        if op == 'Encode':
            rid = None
            if isinstance(out, dict):
                rid = out.get('inserted_id') or out.get('id')
            echo(f"   âœ… Encode | id={rid} dim={out.get('embedding_dim') if isinstance(out, dict) else 'n/a'} / ç¼–ç æˆåŠŸ")
        elif op == 'Retrieve':
            if isinstance(out, list):
                rows = out
            elif isinstance(out, dict):
                rows = out.get('rows') or out.get('matches') or []
            else:
                rows = []
            echo(f"   âœ… Retrieve | {len(rows)} records retrieved / æ£€ç´¢åˆ° {len(rows)} æ¡è®°å½•")
            if verbose and rows:
                for idx, row in enumerate(rows[:2], 1):
                    echo(f"      [{idx}] {str(row)[:80]}...")
        elif op == 'Summarize':
            summary = ''
            if isinstance(out, dict):
                summary = str(out.get('summary',''))
            echo(f"   âœ… Summarize | {summary[:100]}{'â€¦' if len(summary)>100 else ''} / æ‘˜è¦ç”Ÿæˆ")
        else:
            affected = None
            if isinstance(out, dict):
                affected = out.get('affected_rows') or out.get('updated_rows') or out.get('success_count')
            if affected is not None:
                echo(f"   âœ… {op} | affected rows: {affected} / å—å½±å“è¡Œæ•°")
            else:
                echo(f"   âœ… {op} | Completed / å®Œæˆ")

    ran = 0
    failed = 0
    
    # --- Individual IR examples ---
    if args.set == 'individual':
        ir_dir = ROOT / 'examples' / 'ir_operations'
        if not ir_dir.exists():
            echo(f'â„¹ï¸  Directory not found: {ir_dir} / ç›®å½•ä¸å­˜åœ¨')
            return 0
        files = sorted(ir_dir.glob('*.json'))
        if not files:
            echo('â„¹ï¸  No examples found in examples/ir_operations / æœªæ‰¾åˆ°ç¤ºä¾‹æ–‡ä»¶')
            return 0
        for path in files:
            ir = _json.loads(path.read_text(encoding='utf-8'))
            echo(f"ğŸš€ Executing {path.name} -> {ir.get('op')} ({ir.get('stage')}) / æ‰§è¡Œç¤ºä¾‹")
            try:
                res = engine.execute(ir)
            except Exception as e:
                echo(f"âŒ Execution error: {e} / æ‰§è¡Œå¼‚å¸¸")
                failed += 1
                continue
            if not getattr(res, 'success', False):
                echo(f"âŒ Failed: {res.error} / æ‰§è¡Œå¤±è´¥")
                failed += 1
                continue
            out = res.data or {}
            _echo_ir_result(ir, out, args.verbose)
            ran += 1
        echo(f"\n{'='*60}")
        echo(f"ğŸ‰ Demo Complete | Success: {ran} | Failed: {failed} / æ¼”ç¤ºå®Œæˆ")
        return 0 if failed == 0 else 1

    # --- Scenario workflows ---
    if args.set == 'scenarios':
        wf_dir = ROOT / 'examples' / 'real_world_scenarios'
        if not wf_dir.exists():
            echo(f'â„¹ï¸  Directory not found: {wf_dir} / ç›®å½•ä¸å­˜åœ¨')
            return 0
        files = sorted(wf_dir.glob('*.json'))
        if not files:
            echo('â„¹ï¸  No workflows found in examples/real_world_scenarios / æœªæ‰¾åˆ°å·¥ä½œæµæ–‡ä»¶')
            return 0
        for path in files:
            data = _json.loads(path.read_text(encoding='utf-8'))
            steps = data.get('steps', [])
            echo(f"ğŸš€ Running Scenario: {path.name} | {len(steps)} steps / è¿è¡Œåœºæ™¯å·¥ä½œæµ")
            for i, step in enumerate(steps, start=1):
                ir = step.get('ir') or step
                title = step.get('name') or step.get('description') or f'step {i}'
                echo(f"â¡ï¸  [{i}/{len(steps)}] {title} -> {ir.get('op')} / æ‰§è¡Œæ­¥éª¤")
                try:
                    res = engine.execute(ir)
                except Exception as e:
                    echo(f"âŒ Execution error: {e} / æ‰§è¡Œå¼‚å¸¸")
                    failed += 1
                    continue
                if not getattr(res, 'success', False):
                    echo(f"âŒ Failed: {res.error} / å¤±è´¥")
                    failed += 1
                    continue
                out = res.data or {}
                _echo_ir_result(ir, out, args.verbose)
                ran += 1
        echo(f"\n{'='*60}")
        echo(f"ğŸ‰ Demo Complete | Success: {ran} | Failed: {failed} / æ¼”ç¤ºå®Œæˆ")
        return 0 if failed == 0 else 1

    # --- Operation workflows (default) ---
    wf_dir = ROOT / 'examples' / 'op_workflows'
    if not wf_dir.exists():
        echo(f'â„¹ï¸  Directory not found: {wf_dir} / ç›®å½•ä¸å­˜åœ¨')
        return 0
    
    files = [
        'op_encode.json', 'op_label.json', 'op_label_search.json', 'op_label_via_search.json',
        'op_promote.json', 'op_promote_search.json', 'op_promote_remind.json',
        'op_demote.json', 'op_update.json', 'op_delete_search.json',
        'op_update_via_search.json', 'op_delete.json', 'op_lock.json',
        'op_expire.json', 'op_split.json', 'op_split_custom.json', 'op_merge.json',
        'op_retrieve.json', 'op_summarize.json',
    ]
    for name in files:
        path = wf_dir / name
        if not path.exists():
            continue
        data = _json.loads(path.read_text(encoding='utf-8'))
        steps = data.get('steps', [])
        echo(f"ğŸš€ Running Workflow: {name} | {len(steps)} steps / è¿è¡Œå·¥ä½œæµ")
        for i, step in enumerate(steps, start=1):
            ir = step.get('ir') or step
            title = step.get('name') or f'step {i}'
            echo(f"â¡ï¸  [{i}/{len(steps)}] {title} -> {ir.get('op')} / æ‰§è¡Œæ­¥éª¤")
            try:
                res = engine.execute(ir)
            except Exception as e:
                echo(f"âŒ Execution error: {e} / æ‰§è¡Œå¼‚å¸¸")
                failed += 1
                continue
            if not getattr(res, 'success', False):
                echo(f"âŒ Failed: {res.error} / å¤±è´¥")
                failed += 1
                continue
            out = res.data or {}
            _echo_ir_result(ir, out, args.verbose)
            ran += 1
    echo(f"\n{'='*60}")
    echo(f"ğŸ‰ Demo Complete | Success: {ran} | Failed: {failed} / æ¼”ç¤ºå®Œæˆ")
    return 0 if failed == 0 else 1


def cmd_list_workflows():
    """List built-in workflow JSON files."""
    candidates = [
        ROOT / "examples" / "real_world_scenarios", 
        ROOT / "examples" / "op_workflows", 
        ROOT / "text2mem" / "examples"
    ]
    files = []
    for d in candidates:
        if d.exists():
            files += [p for p in d.glob("*.json")]
    if not files:
        echo("â„¹ï¸ No workflow files found / æœªæ‰¾åˆ°ä»»ä½•å·¥ä½œæµæ–‡ä»¶"); 
        return 0
    echo("ğŸ“š Available Workflow Files / å¯ç”¨å·¥ä½œæµæ–‡ä»¶ï¼š")
    for p in sorted(files):
        echo(f"  - {p.relative_to(ROOT)}")
    return 0

def cmd_session():
	"""Persistent interactive session mode â€” allows specifying database, mode, 
	and loading script files to execute commands or enter interactively.

	Usage / ç”¨æ³•:
	  python manage.py session [--mode mock|ollama|openai|auto] [--db path] [--script file]

	Available commands:
	  help                Show help / æ˜¾ç¤ºå¸®åŠ©
	  list                List script lines / åˆ—å‡ºè„šæœ¬è¡Œ
	  next / n            Execute next script line / æ‰§è¡Œä¸‹ä¸€è¡Œè„šæœ¬
	  run <idx>           Execute script line <idx> (1-based) / æ‰§è¡Œç¬¬ idx è¡Œè„šæœ¬
	  
	  # 12 IR operation shortcuts:
	  encode <text>       Encode/create memory (Encode) / ç¼–ç æˆ–åˆ›å»ºè®°å¿†
	  retrieve <query>    Retrieve memory (Retrieve) / æ£€ç´¢è®°å¿†
	  label <id> <tags>   Add tags to record (Label) / ç»™è®°å½•æ·»åŠ æ ‡ç­¾
	  update <id> <text>  Update record content (Update) / æ›´æ–°è®°å½•å†…å®¹
	  delete <id>         Delete record (Delete) / åˆ é™¤è®°å½•
	  promote <id>        Promote record (Promote) / æå‡è®°å½•ä¼˜å…ˆçº§
	  demote <id>         Demote record (Demote) / é™ä½è®°å½•ä¼˜å…ˆçº§
	  lock <id>           Lock record (Lock) / é”å®šè®°å½•
	  merge <ids>         Merge multiple records, e.g. merge 2,3 into 1 / åˆå¹¶å¤šä¸ªè®°å½•
	  split <id>          Split record (Split) / æ‹†åˆ†è®°å½•
	  expire <id> <ttl>   Set record expiration (Expire) / è®¾ç½®è¿‡æœŸæ—¶é—´
	  summarize <ids>     Generate summary for multiple records (Summarize) / ç”Ÿæˆæ‘˜è¦
	  
	  ir <json>           Execute raw IR JSON / æ‰§è¡Œå•æ¡ IR JSON
	  switch-db <path>    Switch database (rebuild engine) / åˆ‡æ¢æ•°æ®åº“å¹¶é‡å»ºå¼•æ“
	  db                  Show current database / æ˜¾ç¤ºå½“å‰æ•°æ®åº“
	  history             Show executed command history / æ˜¾ç¤ºå†å²
	  save <path>         Save history to file / ä¿å­˜å†å²
	  output brief|full   Switch output mode / åˆ‡æ¢è¾“å‡ºæ¨¡å¼
	  quit / exit         Exit / é€€å‡º

	Also supports:
	  â€¢ Directly pasting IR JSON, IR lists, or workflows with steps
	  â€¢ Script files with JSON lines will be auto-recognized and executed
	"""
	parser = argparse.ArgumentParser(prog='manage.py session', add_help=False)
	parser.add_argument('--mode', choices=['mock','ollama','openai','auto'], default=None)
	parser.add_argument('--db', dest='db_path', default=None)
	parser.add_argument('--script', dest='script_path', default=None)
	parser.add_argument('--output', choices=['brief','full'], default='brief', help='Output mode (brief|full) / è¾“å‡ºæ¨¡å¼')
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo('Usage / ç”¨æ³•: python manage.py session [--mode mock|ollama|openai|auto] [--db path] [--script file]')
		sys.exit(2)

	service, engine = _build_engine_and_adapter(args.mode, args.db_path)
	db_path = args.db_path or os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db'
	echo(f"ğŸ§  Model Service: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__} / æ¨¡å‹æœåŠ¡")
	echo(f"ğŸ—„ï¸  Database: {db_path} / æ•°æ®åº“è·¯å¾„")
	output_mode = args.output  # 'brief' or 'full'

	# Load script file if provided
	script_lines: list[str] = []
	if args.script_path:
		sp = Path(args.script_path)
		if not sp.exists():
			echo(f"âš ï¸  Script file not found: {sp} / è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨")
		else:
			script_lines = [ln.rstrip('\n') for ln in sp.read_text(encoding='utf-8').splitlines()]
			echo(f"ğŸ“„ Script loaded: {sp}, total {len(script_lines)} lines / å·²åŠ è½½è„šæœ¬")
	script_ptr = 0  # next line index pointer
	history: list[str] = []

	def rebuild_engine(new_db: str):
		"""Rebuild engine when switching database."""
		nonlocal service, engine, db_path
		db_path = new_db
		service, engine = _build_engine_and_adapter(args.mode, db_path)
		echo(f"ğŸ” Database switched and engine rebuilt -> {db_path} / å·²åˆ‡æ¢æ•°æ®åº“å¹¶é‡å»ºå¼•æ“")

	def exec_ir(ir: dict):
		"""Execute one IR object and show formatted output."""
		try:
			res = engine.execute(ir)
		except Exception as e:
			echo(f"âŒ IR execution error: {e} / æ‰§è¡Œå¼‚å¸¸")
			return
		if not getattr(res, 'success', False):
			echo(f"âŒ Failed: {res.error} / æ‰§è¡Œå¤±è´¥")
			if output_mode == 'full':
				try:
					echo(json.dumps({'error': getattr(res,'error',None)}, ensure_ascii=False))
				except Exception:
					pass
			return
		data = res.data or {}
		op = ir.get('op')

		if output_mode == 'full':
			# Print full JSON output
			try:
				echo(json.dumps({'op': op, 'success': True, 'data': data}, ensure_ascii=False))
			except Exception:
				echo(str(data))
			return
		
		# --- brief mode summary output ---
		if op == 'Encode':
			rid = data.get('inserted_id') or data.get('id')
			echo(f"âœ… Encode | id={rid}, dim={data.get('embedding_dim')} / ç¼–ç æˆåŠŸ")
			return
		if op == 'Retrieve':
			rows = data.get('rows') if isinstance(data, dict) else (data if isinstance(data, list) else [])
			echo(f"âœ… Retrieve | {len(rows)} rows retrieved / æ£€ç´¢åˆ° {len(rows)} æ¡è®°å½•")
			for idx, row in enumerate(rows[:3], 1):
				text_preview = (row.get('text') or '')[:60]
				echo(f"   [{idx}] id={row.get('id')} {text_preview}{'...' if len(text_preview)>=60 else ''}")
			return
		if op == 'Summarize':
			summary = str(data.get('summary',''))
			echo(f"âœ… Summarize | {summary[:160]}{'â€¦' if len(summary)>160 else ''} / æ‘˜è¦ç”Ÿæˆ")
			return
		affected = data.get('affected_rows') or data.get('updated_rows') or data.get('success_count')
		if affected is not None:
			echo(f"âœ… {op} | affected={affected} / å—å½±å“è®°å½•")
		else:
			echo(f"âœ… {op} completed / æ“ä½œå®Œæˆ")

	def run_inline_workflow(payload: dict) -> bool:
		"""Execute inline workflow object containing multiple IR steps."""
		steps = payload.get('steps')
		if not isinstance(steps, list):
			return False
		name = payload.get('name') or payload.get('title') or 'workflow'
		echo(f"ğŸ§¾ Executing inline workflow: {name} | {len(steps)} steps / æ‰§è¡Œå†…è”å·¥ä½œæµ")
		executed = False
		for idx, step in enumerate(steps, start=1):
			if not isinstance(step, dict):
				echo(f"âš ï¸  Skipping invalid step {idx}: type={type(step).__name__} / æ— æ•ˆæ­¥éª¤ï¼Œå·²è·³è¿‡")
				continue
			ir = step.get('ir') or step
			if not isinstance(ir, dict) or not ir.get('op'):
				echo(f"âš ï¸  Step {idx} missing valid IR, skipped / ç¼ºå°‘åˆæ³• IRï¼Œè·³è¿‡")
				continue
			title = step.get('name') or ir.get('name') or f'step {idx}'
			echo(f"â¡ï¸  [{idx}/{len(steps)}] {title} -> {ir.get('op')} / æ‰§è¡Œæ­¥éª¤")
			exec_ir(ir)
			executed = True
		return executed

	def execute_json_payload(obj: Any) -> bool:
		"""Handle execution of JSON payloads (IR object, list, or workflow)."""
		if isinstance(obj, dict):
			if obj.get('op'):
				exec_ir(obj)
				return True
			if run_inline_workflow(obj):
				return True
			echo('âš ï¸  JSON object missing executable content (op or steps) / ç¼ºå°‘å¯æ‰§è¡Œå­—æ®µ')
			return False
		if isinstance(obj, list):
			executed_any = False
			for idx, item in enumerate(obj, start=1):
				echo(f"ğŸ“¦ Processing list item {idx}/{len(obj)} / å¤„ç†åˆ—è¡¨å…ƒç´ ")
				executed_any |= execute_json_payload(item)
			return executed_any
		echo('âš ï¸  Unsupported JSON type â€” expected object or list / ä¸æ”¯æŒçš„ JSON ç±»å‹')
		return False
	def run_script_line(idx: int):
		"""Run a specific line from the loaded script by index."""
		nonlocal script_ptr
		if idx < 1 or idx > len(script_lines):
			echo("âš ï¸  Line number out of range / è¡Œå·è¶…å‡ºèŒƒå›´")
			return
		line = script_lines[idx-1].strip()
		script_ptr = idx  # set current pointer
		if not line or line.startswith('#'):
			echo(f"(Skipping blank/comment line {idx}) / è·³è¿‡ç©ºè¡Œæˆ–æ³¨é‡Šè¡Œ {idx}")
			return
		echo(f"â–¶ï¸  [Script line {idx}] {line} / æ‰§è¡Œè„šæœ¬è¡Œ")
		process_command(line)

	def process_command(line: str):
		"""Parse and execute a single session command line."""
		nonlocal script_ptr, output_mode
		line = line.strip()
		if not line:
			return
		# Try executing directly if line is JSON
		if line[0] in '{[':
			try:
				obj = json.loads(line)
			except Exception as e:
				echo(f"JSON parse error: {e} / JSON è§£æå¤±è´¥")
				return
			history.append(line)
			if execute_json_payload(obj):
				return
			else:
				return
		history.append(line)
		parts = line.split(' ', 1)
		cmd = parts[0]
		arg = parts[1] if len(parts) > 1 else ''
		
		# === Built-in commands ===
		if cmd in ('quit', 'exit'):
			raise SystemExit(0)
		if cmd == 'help':
			echo("""Commands / å‘½ä»¤:
  Basics / åŸºç¡€: help | list | next | n | run <i> | db | history | save <p> | output (brief|full) | quit
  12 IR operation shortcuts / 12ç§æ“ä½œå¿«æ·æ–¹å¼:
    encode <text>           - Encode/create memory / ç¼–ç æˆ–åˆ›å»ºè®°å¿†
    retrieve <query>        - Retrieve memory / æ£€ç´¢è®°å¿†
    label <id> <tags>       - Add tags (comma-separated) / æ‰“æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼‰
    update <id> <text>      - Update record text / æ›´æ–°å†…å®¹
    delete <id>             - Delete record / åˆ é™¤è®°å½•
    promote <id>            - Promote priority / æå‡ä¼˜å…ˆçº§
    demote <id>             - Demote priority / é™ä½ä¼˜å…ˆçº§
    lock <id>               - Lock record / é”å®šè®°å½•
    merge <ids>             - Merge records (e.g. merge 2,3 into 1) / åˆå¹¶è®°å½•
    split <id>              - Split record / æ‹†åˆ†è®°å½•
    expire <id> <ttl>       - Set expiration (e.g. P7D = 7 days) / è®¾ç½®è¿‡æœŸæ—¶é—´
    summarize <ids>         - Summarize multiple records / ç”Ÿæˆæ‘˜è¦
  Advanced / é«˜çº§: ir <json> | switch-db <p> | (paste IR/workflow JSON)""")
		
		elif cmd == 'list':
			if not script_lines:
				echo('â„¹ï¸  No script loaded / æœªåŠ è½½è„šæœ¬'); 
				return
			for i, l in enumerate(script_lines, start=1):
				marker = '>>' if (i == script_ptr+1) else '  '
				echo(f"{marker} {i:03d}: {l}")
		elif cmd in ('next','n'):
			if not script_lines:
				echo('â„¹ï¸  No script / æ²¡æœ‰è„šæœ¬'); 
				return
			if script_ptr >= len(script_lines):
				echo('âš ï¸  End of script reached / å·²åˆ°è„šæœ¬æœ«å°¾'); 
				return
			run_script_line(script_ptr+1)
		elif cmd == 'run':
			if not arg.isdigit():
				echo('Usage / ç”¨æ³•: run <line_number>'); 
				return
			run_script_line(int(arg))
		
		# === IR operation shortcuts ===
		elif cmd == 'encode':
			if not arg:
				echo('Usage / ç”¨æ³•: encode <text>'); 
				return
			ir = {"stage":"ENC","op":"Encode","args":{"payload":{"text":arg}}}
			exec_ir(ir)
		elif cmd == 'retrieve':
			if not arg:
				echo('Usage / ç”¨æ³•: retrieve <query>'); 
				return
			ir = {"stage":"RET","op":"Retrieve","target":{"search":{"intent":{"query":arg},"overrides":{"k":5}}},"args":{}}
			exec_ir(ir)
		elif cmd == 'label':
			parts = arg.split(' ', 1)
			if len(parts) < 2:
				echo('Usage / ç”¨æ³•: label <id> <tags> (comma-separated)'); 
				return
			record_id, tags_str = parts
			tags = [t.strip() for t in tags_str.split(',')]
			ir = {"stage":"STO","op":"Label","target":{"ids":[record_id]},"args":{"tags":tags,"mode":"add"}}
			exec_ir(ir)
		elif cmd == 'update':
			parts = arg.split(' ', 1)
			if len(parts) < 2:
				echo('Usage / ç”¨æ³•: update <id> <new_text>'); 
				return
			record_id, new_text = parts
			ir = {"stage":"STO","op":"Update","target":{"ids":[record_id]},"args":{"set":{"text":new_text}}}
			exec_ir(ir)
		elif cmd == 'delete':
			if not arg:
				echo('Usage / ç”¨æ³•: delete <id>'); 
				return
			ir = {"stage":"STO","op":"Delete","target":{"ids":[arg]},"args":{"soft":True}}
			exec_ir(ir)
		elif cmd == 'promote':
			if not arg:
				echo('Usage / ç”¨æ³•: promote <id>'); 
				return
			ir = {"stage":"STO","op":"Promote","target":{"ids":[arg]},"args":{"weight_delta":0.2}}
			exec_ir(ir)
		elif cmd == 'demote':
			if not arg:
				echo('Usage / ç”¨æ³•: demote <id>'); 
				return
			ir = {"stage":"STO","op":"Demote","target":{"ids":[arg]},"args":{"archive":True}}
			exec_ir(ir)
		elif cmd == 'lock':
			if not arg:
				echo('Usage / ç”¨æ³•: lock <id>'); 
				return
			ir = {"stage":"STO","op":"Lock","target":{"ids":[arg]},"args":{"mode":"read_only"}}
			exec_ir(ir)
		elif cmd == 'merge':
			# Format: merge 2,3 into 1 (merge 2,3 into 1) or merge 2,3,4 (2 is primary)
			if not arg:
				echo('Usage / ç”¨æ³•: merge <child_ids> into <primary_id> or merge <primary_id>,<child_ids>'); 
				return
			if ' into ' in arg:
				parts = arg.split(' into ')
				child_ids_str = parts[0].strip()
				primary_id = parts[1].strip()
				child_ids = [i.strip() for i in child_ids_str.split(',')]
			else:
				ids_str = arg.split(',')
				if len(ids_str) < 2:
					echo('âš ï¸  At least two IDs required to merge / éœ€è¦è‡³å°‘ä¸¤ä¸ªIDè¿›è¡Œåˆå¹¶'); 
					return
				primary_id = ids_str[0].strip()
				child_ids = [i.strip() for i in ids_str[1:]]
			ir = {"stage":"STO","op":"Merge","target":{"ids":child_ids},"args":{"strategy":"merge_into_primary","primary_id":primary_id}}
			exec_ir(ir)
		elif cmd == 'split':
			if not arg:
				echo('Usage / ç”¨æ³•: split <id>'); 
				return
			ir = {"stage":"STO","op":"Split","target":{"ids":[arg]},"args":{"strategy":"by_sentences","params":{"by_sentences":{"lang":"zh","max_sentences":3}}}}
			exec_ir(ir)
		elif cmd == 'expire':
			parts = arg.split(' ', 1)
			if len(parts) < 2:
				echo('Usage / ç”¨æ³•: expire <id> <ttl> (e.g. P7D means 7 days)'); 
				return
			record_id, ttl = parts
			ir = {"stage":"STO","op":"Expire","target":{"ids":[record_id]},"args":{"ttl":ttl,"on_expire":"soft_delete"}}
			exec_ir(ir)
		elif cmd == 'summarize':
			if not arg:
				echo('Usage / ç”¨æ³•: summarize <ids> [focus]'); 
				return
			parts = arg.split(' ', 1)
			ids_or_all = parts[0]
			focus = parts[1] if len(parts) > 1 else "Overall summary / æ€»ä½“æ¦‚è¿°"
			if ids_or_all.lower() == 'all':
				ir = {"stage":"RET","op":"Summarize","target":{"all":True},"args":{"focus":focus,"max_tokens":256},"meta":{"confirmation":True}}
			else:
				ids = [i.strip() for i in ids_or_all.split(',')]
				ir = {"stage":"RET","op":"Summarize","target":{"ids":ids},"args":{"focus":focus,"max_tokens":256}}
			exec_ir(ir)
		
		# === Utility commands ===
		elif cmd == 'ir':
			try:
				ir = json.loads(arg)
			except Exception as e:
				echo(f"JSON parse error: {e} / JSON è§£æå¤±è´¥"); 
				return
			exec_ir(ir)
		elif cmd == 'switch-db':
			if not arg:
				echo('Usage / ç”¨æ³•: switch-db <path>'); 
				return
			rebuild_engine(arg)
		elif cmd == 'db':
			echo(f"Current database: {db_path} / å½“å‰æ•°æ®åº“")
		elif cmd == 'history':
			for i, h in enumerate(history, start=1):
				echo(f"{i:03d}: {h}")
		elif cmd == 'save':
			if not arg:
				echo('Usage / ç”¨æ³•: save <path>'); 
				return
			try:
				Path(arg).write_text('\n'.join(history), encoding='utf-8')
				echo(f"âœ… History saved -> {arg} / å·²ä¿å­˜å†å²")
			except Exception as e:
				echo(f"âŒ Save failed: {e} / ä¿å­˜å¤±è´¥")
		elif cmd == 'output':
			if arg not in ('brief','full'):
				echo('Usage / ç”¨æ³•: output brief|full'); 
				return
			output_mode = arg
			echo(f"ğŸ”§ Output mode switched to: {output_mode} / è¾“å‡ºæ¨¡å¼å·²åˆ‡æ¢")
		else:
			echo('Unknown command, type help for list / æœªçŸ¥å‘½ä»¤ï¼Œè¯·è¾“å…¥ help')

	echo("Entering session mode, type help for commands, Ctrl+C to exit / è¿›å…¥ä¼šè¯æ¨¡å¼ï¼ŒCtrl+C é€€å‡ºã€‚")
	while True:
		try:
			line = input('session> ')
		except (EOFError, KeyboardInterrupt):
			echo('')
			break
		try:
			process_command(line)
		except SystemExit:
			break
		except Exception as e:
			echo(f"âŒ Error while processing command: {e} / å¤„ç†å‘½ä»¤æ—¶å‡ºé”™")
	echo('ğŸ‘‹ Exiting session / é€€å‡ºä¼šè¯')
	return 0
def cmd_models_smoke():
	"""Minimal model smoke test â€” perform one embedding and one generation call.
	æœ€å°åŒ–æ¨¡å‹å†’çƒŸæµ‹è¯•ï¼šåšä¸€æ¬¡ embedding + ä¸€æ¬¡ generationã€‚

	Usage / ç”¨æ³•:
	  python manage.py models-smoke            # use .env / MODEL_SERVICE
	  python manage.py models-smoke openai     # force OpenAI
	  python manage.py models-smoke ollama     # force Ollama
	  python manage.py models-smoke mock       # mock mode
	"""
	mode = None
	if len(sys.argv) >= 3:
		mode = sys.argv[2].lower()

	echo("=" * 60)
	echo("ğŸ§ª Model Smoke Test / æ¨¡å‹å†’çƒŸæµ‹è¯•")
	echo("=" * 60)
	
	try:
		service = _build_models_service_from_env(mode)
		from text2mem.services.models_service import GenerationResult
		echo(f"ğŸ”§ Using models / ä½¿ç”¨æ¨¡å‹:")
		echo(f"   Embedding: {service.embedding_model.__class__.__name__}")
		echo(f"   Generation: {service.generation_model.__class__.__name__}")
		echo("")

		# 1ï¸âƒ£ Test embedding
		echo("ğŸ“ Test 1/2: Embedding model / æµ‹è¯•åµŒå…¥æ¨¡å‹...")
		text = "ç”¨äºåµŒå…¥çš„æµ‹è¯•æ–‡æœ¬ã€‚Hello embeddings!"
		emb = service.encode_memory(text)
		echo(f"âœ… Embedding succeeded / åµŒå…¥æˆåŠŸ")
		echo(f"   Dimension: {emb.dimension} | Model: {emb.model}")
		echo("")

		# 2ï¸âƒ£ Test generation
		echo("ğŸ“ Test 2/2: Generation model / æµ‹è¯•ç”Ÿæˆæ¨¡å‹...")
		prompt = "è¯·ç”¨ä¸€å¥è¯æ€»ç»“ï¼šText2Mem æ˜¯ä¸€ä¸ªæ–‡æœ¬è®°å¿†å¤„ç†ç³»ç»Ÿã€‚"
		gen = service.generation_model.generate(prompt, temperature=0.2, max_tokens=60)
		echo(f"âœ… Generation succeeded / ç”ŸæˆæˆåŠŸ")
		echo(f"   Model: {gen.model}")
		echo(f"   Output / è¾“å‡º: {gen.text[:150]}{'...' if len(gen.text) > 150 else ''}")
		echo("")
		
		echo("=" * 60)
		echo("ğŸ‰ All tests passed! / æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
		echo("=" * 60)
	except Exception as e:
		echo("")
		echo("=" * 60)
		echo("âŒ Model smoke test failed / æ¨¡å‹å†’çƒŸæµ‹è¯•å¤±è´¥")
		echo("=" * 60)
		echo(f"Error / é”™è¯¯: {e}")
		echo("")
		echo("ğŸ’¡ Troubleshooting / æ•…éšœæ’æŸ¥:")
		echo("   1. Check .env config: python manage.py status / æ£€æŸ¥ .env é…ç½®")
		echo("   2. Verify model config: python manage.py models-info / éªŒè¯æ¨¡å‹é…ç½®")
		echo("   3. For Ollama: ensure 'ollama serve' is running / Ollama è¯·ç¡®ä¿æœåŠ¡å·²å¯åŠ¨")
		echo("   4. For OpenAI: verify API key / OpenAI è¯·æ£€æŸ¥ API Key")
		sys.exit(1)
	sys.exit(0)


def cmd_run_workflow():
	"""Run a workflow JSON file â€” executes IR steps in order.
	è¿è¡Œä¸€ä¸ªå·¥ä½œæµ JSON æ–‡ä»¶ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ª IR æ­¥éª¤ã€‚

	Usage / ç”¨æ³•:
	  python manage.py workflow <workflow.json> [--mode mock|ollama|openai|auto] [--db <db_path>] [--verbose]
	"""
	import argparse, json
	from text2mem.core.engine import Text2MemEngine
	from text2mem.adapters.sqlite_adapter import SQLiteAdapter

	parser = argparse.ArgumentParser(prog="manage.py workflow", add_help=False)
	parser.add_argument("workflow", help="Path to workflow JSON / å·¥ä½œæµ JSON æ–‡ä»¶è·¯å¾„")
	parser.add_argument("--mode", choices=["mock","ollama","openai","auto"], default=None)
	parser.add_argument("--db", dest="db_path", default=None, help="Database path (default: TEXT2MEM_DB_PATH or ./text2mem.db)")
	parser.add_argument("--verbose", action="store_true", help="Verbose output / è¯¦ç»†è¾“å‡º")
	try:
		args = parser.parse_args(sys.argv[2:])
	except SystemExit:
		echo("Usage / ç”¨æ³•: python manage.py workflow <workflow.json> [--mode mock|ollama|openai|auto] [--db path] [--verbose]")
		sys.exit(2)

	wf_path = Path(args.workflow)
	if not wf_path.exists():
		echo(f"âŒ Workflow file not found: {wf_path} / å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨")
		sys.exit(2)

	db_path = args.db_path or os.environ.get("TEXT2MEM_DB_PATH") or "./text2mem.db"
	service = _build_models_service_from_env(args.mode)
	adapter = SQLiteAdapter(db_path, models_service=service)
	engine = Text2MemEngine(adapter=adapter, models_service=service)

	data = json.loads(wf_path.read_text(encoding="utf-8"))
	workflow_name = data.get("name") or data.get("title") or wf_path.name
	steps = data.get("steps", [])
	
	echo("=" * 60)
	echo(f"ğŸš€ Running Workflow: {workflow_name} / è¿è¡Œå·¥ä½œæµ")
	echo("=" * 60)
	echo(f"ğŸ“„ File: {wf_path}")
	echo(f"ğŸ“¦ Steps: {len(steps)}")
	echo(f"ğŸ§  Models: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")
	echo(f"ğŸ—„ï¸  Database: {db_path}")
	echo("=" * 60)
	echo("")

	success_count = 0
	failed_count = 0
	
	for idx, step in enumerate(steps, start=1):
		title = step.get("name") or step.get("description") or f"Step {step.get('step', idx)}"
		ir = step.get("ir") or step
		if not isinstance(ir, dict) or not ir.get("op"):
			echo(f"âš ï¸  [{idx}/{len(steps)}] Skipping invalid step: {title} / æ— æ•ˆæ­¥éª¤ï¼Œå·²è·³è¿‡")
			continue
		
		echo(f"â¡ï¸  [{idx}/{len(steps)}] {title}")
		echo(f"    Operation: {ir.get('op')} | Stage: {ir.get('stage', 'N/A')} / æ“ä½œä¿¡æ¯")

		try:
			result = engine.execute(ir)
		except Exception as e:
			echo(f"âŒ Exception: {e} / æ‰§è¡Œå¼‚å¸¸")
			if args.verbose:
				import traceback
				traceback.print_exc()
			failed_count += 1
			continue

		if not getattr(result, "success", False):
			echo(f"âŒ Step failed: {result.error} / æ­¥éª¤å¤±è´¥")
			failed_count += 1
			continue

		data_out = result.data or {}
		op = ir.get("op")
		
		if op == "Encode":
			rid = data_out.get("inserted_id") or data_out.get("id")
			emb_dim = data_out.get("embedding_dim")
			echo(f"    âœ… Encoded | ID={rid}, dim={emb_dim} / ç¼–ç æˆåŠŸ")
		elif op == "Retrieve":
			rows = []
			if isinstance(data_out, list):
				rows = data_out
			elif isinstance(data_out, dict):
				rows = data_out.get("rows", []) or []
			echo(f"    âœ… Retrieved {len(rows)} records / æ£€ç´¢åˆ° {len(rows)} æ¡è®°å½•")
			if args.verbose and rows:
				echo(f"       Example / ç¤ºä¾‹: {str(rows[0])[:120]}...")
		elif op == "Summarize":
			summary = str(data_out.get("summary", ""))
			echo(f"    âœ… Summary: {summary[:120]}{'...' if len(summary) > 120 else ''} / æ‘˜è¦ç”Ÿæˆ")
		else:
			affected = data_out.get("affected_rows") or data_out.get("updated_rows")
			if affected is not None:
				echo(f"    âœ… Done | affected={affected} / å®Œæˆï¼Œå—å½±å“è®°å½•: {affected}")
			else:
				echo(f"    âœ… Done / å®Œæˆ")
		
		success_count += 1
		echo("")

	echo("=" * 60)
	echo(f"ğŸ‰ Workflow Completed / å·¥ä½œæµå®Œæˆ")
	echo("=" * 60)
	echo(f"âœ… Success: {success_count}/{len(steps)}")
	if failed_count > 0:
		echo(f"âŒ Failed: {failed_count}/{len(steps)}")
	echo("=" * 60)
	
	sys.exit(0 if failed_count == 0 else 1)


def cmd_set_env():
	"""Set or update environment variables in .env file.
	è®¾ç½®æˆ–æ›´æ–° .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ã€‚
	"""
	if len(sys.argv) < 4:
		echo("Usage / ç”¨æ³•: manage.py set-env KEY VALUE")
		echo("Example / ç¤ºä¾‹: manage.py set-env TEXT2MEM_LOG_LEVEL DEBUG")
		return 1
	
	key = sys.argv[2]
	value = sys.argv[3]
	env_path = ROOT / ".env"
	
	# Read existing .env variables
	existing_vars = {}
	if env_path.exists():
		existing_vars = load_env_file(env_path)
	
	existing_vars[key] = value  # update or add

	env_content = "# Text2Mem Environment Configuration / ç¯å¢ƒé…ç½®\n"
	provider = existing_vars.get("MODEL_SERVICE", "æœªæŒ‡å®š / unspecified")
	env_content += f"# Provider: {provider}\n\n"

	sections = {
		"Database Settings / æ•°æ®åº“è®¾ç½®": ["DATABASE_PATH", "TEXT2MEM_DB_PATH", "TEXT2MEM_DB_WAL", "TEXT2MEM_DB_TIMEOUT"],
		"Embedding Model / åµŒå…¥æ¨¡å‹è®¾ç½®": ["TEXT2MEM_EMBEDDING_PROVIDER", "TEXT2MEM_EMBEDDING_MODEL", "TEXT2MEM_EMBEDDING_BASE_URL"],
		"Generation Model / ç”Ÿæˆæ¨¡å‹è®¾ç½®": ["TEXT2MEM_GENERATION_PROVIDER", "TEXT2MEM_GENERATION_MODEL", "TEXT2MEM_GENERATION_BASE_URL",
					"TEXT2MEM_TEMPERATURE", "TEXT2MEM_MAX_TOKENS", "TEXT2MEM_TOP_P"],
		"OpenAI Settings / OpenAI è®¾ç½®": ["OPENAI_API_KEY", "OPENAI_MODEL", "OPENAI_API_BASE", "OPENAI_ORGANIZATION"],
		"Ollama Settings / Ollama è®¾ç½®": ["OLLAMA_BASE_URL", "OLLAMA_MODEL"],
		"Other / å…¶ä»–è®¾ç½®": ["MODEL_SERVICE", "TEXT2MEM_LOG_LEVEL"]
	}
	
	key_section = "Other / å…¶ä»–è®¾ç½®"
	for section, keys in sections.items():
		if key in keys:
			key_section = section
			break
	
	processed_keys = set()
	for section, keys in sections.items():
		section_keys = [k for k in keys if k in existing_vars]
		if section_keys:
			env_content += f"\n# {section}\n"
			for k in section_keys:
				env_content += f"{k}={existing_vars[k]}\n"
				processed_keys.add(k)
	
	unprocessed_keys = [k for k in existing_vars if k not in processed_keys]
	if unprocessed_keys:
		env_content += "\n# Custom / è‡ªå®šä¹‰è®¾ç½®\n"
		for k in unprocessed_keys:
			env_content += f"{k}={existing_vars[k]}\n"
	
	env_path.write_text(env_content, encoding="utf-8")
	echo(f"âœ… Environment variable set: {key}={value} / å·²å†™å…¥ .env æ–‡ä»¶")
	return 0


def _normalize_docstring(text: Optional[str]) -> str:
    if not text:
        return ""
    return textwrap.dedent(text.expandtabs()).strip()


COMMAND_DEFINITIONS: Tuple[CommandInfo, ...] = (
    CommandInfo("status", cmd_status, "Environment status (dependencies / .env / service detection) | ç¯å¢ƒçŠ¶æ€ï¼ˆä¾èµ– / .env / æœåŠ¡æ¢æµ‹ï¼‰", "core"),
    CommandInfo("config", cmd_config, "Generate or update .env (--provider ...) | ç”Ÿæˆæˆ–æ›´æ–° .env (--provider ...)", "core"),
    CommandInfo("set-env", cmd_set_env, "Quickly write a single environment variable | å¿«é€Ÿå†™å…¥å•ä¸ªç¯å¢ƒå˜é‡", "core", aliases=("set_env",)),
    CommandInfo("models-info", cmd_models_info, "Show parsed model configuration | æ˜¾ç¤ºè§£æåçš„æ¨¡å‹é…ç½®", "core"),
    CommandInfo("demo", cmd_run_demo, "Execute preset IR or workflow demos in batch | æ‰¹é‡æ‰§è¡Œé¢„ç½® IR / å·¥ä½œæµç¤ºä¾‹", "demos"),
    CommandInfo("ir", cmd_ir, "Execute a single IR JSON (--file | --inline) | æ‰§è¡Œå•æ¡ IR JSON (--file | --inline)", "demos"),
    CommandInfo("workflow", cmd_run_workflow, "Run a workflow file step-by-step | æŒ‰æ­¥éª¤é¡ºåºè¿è¡Œå·¥ä½œæµæ–‡ä»¶", "workflows"),
    CommandInfo("list-workflows", cmd_list_workflows, "List example workflow JSON files | åˆ—å‡ºç¤ºä¾‹å·¥ä½œæµ JSON æ–‡ä»¶", "workflows", aliases=("list_workflows",)),
    CommandInfo("session", cmd_session, "Enhanced persistent session (supports 12 shortcut operations) | å¢å¼ºå‹æŒä¹…ä¼šè¯ï¼ˆæ”¯æŒ12ç§æ“ä½œå¿«æ·æ–¹å¼ï¼‰", "interaction"),
    CommandInfo("models-smoke", cmd_models_smoke, "Minimal model smoke test (embed + generate) | æœ€å°æ¨¡å‹å†’çƒŸæµ‹è¯•ï¼ˆåµŒå…¥ + ç”Ÿæˆï¼‰", "models", aliases=("models_smoke",)),
    CommandInfo("setup-ollama", cmd_setup_ollama, "Pull default Ollama models | æ‹‰å–é»˜è®¤çš„ Ollama æ¨¡å‹", "ops"),
    CommandInfo("setup-openai", cmd_setup_openai, "Generate .env for OpenAI usage | ç”Ÿæˆ OpenAI ä½¿ç”¨çš„ .env æ–‡ä»¶", "ops"),
    CommandInfo("test", cmd_test, "Run pytest or minimal smoke test | è¿è¡Œ pytest æˆ–æœ€å°å†’çƒŸæµ‹è¯•", "ops"),
)

COMMAND_LOOKUP: Dict[str, CommandInfo] = {}
for info in COMMAND_DEFINITIONS:
    COMMAND_LOOKUP[info.name] = info
    for alias in info.aliases:
        COMMAND_LOOKUP[alias] = info


def _command_names(info: CommandInfo) -> str:
    names = [info.name, *info.aliases]
    return ", ".join(names)


def print_usage() -> None:
    echo("Usage ç”¨æ³•: python manage.py <command> [options]")
    echo("")
    for key, label in COMMAND_GROUPS:
        group_items = [info for info in COMMAND_DEFINITIONS if info.group == key]
        if not group_items:
            continue
        echo(f"[{label}]")
        for info in group_items:
            names = _command_names(info)
            echo(f"  {names:<28} {info.summary}")
        echo("")
    echo("Use 'python manage.py help <command>' for detailed instructions.")
    echo("ä½¿ç”¨ 'python manage.py help <command>' æŸ¥çœ‹è¯¦ç»†è¯´æ˜ã€‚")
    echo("")
    echo("Examples ç¤ºä¾‹:")
    echo("  python manage.py demo --mode mock")
    echo("  python manage.py ir --mode mock --inline '{\"stage\":\"RET\",\"op\":...}'")
    echo("  python manage.py session --mode mock --output full")


def print_command_help(name: str) -> int:
    info = COMMAND_LOOKUP.get(name)
    if not info:
        echo(f"Unknown command: {name} | æœªçŸ¥å‘½ä»¤: {name}")
        echo("Use 'python manage.py help' to see available commands.")
        echo("ä½¿ç”¨ 'python manage.py help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤ã€‚")
        return 1
    label = next((lbl for key, lbl in COMMAND_GROUPS if key == info.group), info.group)
    echo(f"Command å‘½ä»¤: {_command_names(info)}")
    echo(f"Group åˆ†ç»„: {label}")
    echo(f"Summary æ¦‚è¦: {info.summary}")
    details = _normalize_docstring(info.description or info.handler.__doc__)
    if details:
        echo("")
        for line in details.splitlines():
            echo(line)
    return 0


def main():
    if len(sys.argv) < 2:
        print_usage()
        return 1

    cmd = sys.argv[1]
    if cmd in ("help", "-h", "--help"):
        target = sys.argv[2] if len(sys.argv) > 2 else None
        if not target:
            print_usage()
            return 0
        return print_command_help(target)

    info = COMMAND_LOOKUP.get(cmd)
    if not info:
        echo(f"Unknown command: {cmd} | æœªçŸ¥å‘½ä»¤: {cmd}")
        echo("Use 'python manage.py help' to view available commands.")
        echo("ä½¿ç”¨ 'python manage.py help' æŸ¥çœ‹å‘½ä»¤åˆ—è¡¨ã€‚")
        return 2

    result = info.handler()
    return result if isinstance(result, int) else 0


if __name__ == "__main__":
    sys.exit(main())
