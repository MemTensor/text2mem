#!/usr/bin/env python3
"""Standalone full demo runner using manage.py internal logic.
Usage:
  python scripts/full_demo.py [--mode mock|ollama|openai|auto] [--db path]

This mirrors `python manage.py demo --full` but keeps logic isolated
so it can be imported or extended (e.g., for benchmarking).
"""
from __future__ import annotations
import argparse, os, sys, time, json
from pathlib import Path

# Allow relative imports of project modules when run directly
ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT))

from manage import _build_engine_and_adapter, echo  # type: ignore

def run_full(mode: str | None, db_path: str | None):
    service, engine = _build_engine_and_adapter(mode, db_path)
    echo(f"ğŸ§  æ¨¡å‹æœåŠ¡: embed={service.embedding_model.__class__.__name__}, gen={service.generation_model.__class__.__name__}")
    echo(f"ğŸ—„ï¸  æ•°æ®åº“: {db_path or os.environ.get('TEXT2MEM_DB_PATH') or './text2mem.db'}")

    def _run(ir: dict, title: str):
        start = time.time()
        res = engine.execute(ir)
        ok = getattr(res, 'success', False)
        data = res.data if ok else {}
        dur = (time.time() - start) * 1000
        if not ok:
            echo(f"âŒ {title} å¤±è´¥: {res.error}")
            return None
        op = ir.get("op")
        if op == "Encode":
            rid = data.get("inserted_id") or data.get("id")
            echo(f"âœ… {title} -> id={rid} dim={data.get('embedding_dim')} ({dur:.1f}ms)")
            return rid
        if op == "Retrieve":
            rows = data.get("rows") if isinstance(data, dict) else []
            echo(f"âœ… {title} -> {len(rows)} rows ({dur:.1f}ms)")
        elif op == "Summarize":
            summary = str(data.get("summary",""))
            echo(f"âœ… {title} -> summary {summary[:60]}{'â€¦' if len(summary)>60 else ''} ({dur:.1f}ms)")
        elif op in ("Update","Label","Promote","Demote","Delete","Lock","Expire"):
            affected = data.get("affected_rows") or data.get("updated_rows")
            if affected is not None:
                echo(f"âœ… {title} -> affected={affected} ({dur:.1f}ms)")
            else:
                echo(f"âœ… {title} ({dur:.1f}ms)")
        elif op == "Split":
            echo(f"âœ… {title} -> total_splits={data.get('total_splits')} ({dur:.1f}ms)")
        elif op == "Merge":
            echo(f"âœ… {title} -> merged={data.get('merged_count')} primary={data.get('primary_id')} ({dur:.1f}ms)")
        else:
            echo(f"âœ… {title} ({dur:.1f}ms)")
        return data

    echo("ğŸš€ è¿è¡Œ FULL DEMO (12 ç±»æ“ä½œ)")
    ids = {}

    ids['main'] = _run({
        "stage":"ENC","op":"Encode","args":{"payload":{"text":"é¡¹ç›®A ç¬¬ä¸€æ¬¡ä¼šè®®ï¼šè®¨è®ºèŒƒå›´ã€ç›®æ ‡ä¸ä¸‹ä¸€æ­¥è®¡åˆ’ã€‚"},"tags":["project","meeting"],"type":"note","use_embedding":True}
    }, "Encode main")

    ids['secondary'] = _run({
        "stage":"ENC","op":"Encode","args":{"payload":{"text":"é¡¹ç›®A ç¬¬äºŒæ¬¡ä¼šè®®ï¼šç¡®å®šä»»åŠ¡åˆ†å·¥ä¸é£é™©ã€‚"},"tags":["project","meeting","notes"],"type":"note","use_embedding":True}
    }, "Encode secondary")

    long_text = "# æ¦‚è§ˆ\né¡¹ç›®A è¯´æ˜æ–‡æ¡£ã€‚\n# ç›®æ ‡\næå‡åä½œæ•ˆç‡ã€‚\n# è®¡åˆ’\n1. å»ºç«‹çŸ¥è¯†åº“\n2. å‘¨ä¼šè®°å½•\n# é£é™©\nèµ„æºä¸è¶³ä¸å»¶æœŸé£é™©ã€‚"
    ids['long'] = _run({
        "stage":"ENC","op":"Encode","args":{"payload":{"text":long_text},"tags":["doc","long"],"type":"note","use_embedding":True}
    }, "Encode long")

    ids['temp'] = _run({
        "stage":"ENC","op":"Encode","args":{"payload":{"text":"ä¸´æ—¶ç¬”è®°ï¼šæœ¬å‘¨ä¸´æ—¶ä»»åŠ¡è®°å½•"},"tags":["temp","note"],"type":"note","use_embedding":True}
    }, "Encode temp")

    ids['obsolete'] = _run({
        "stage":"ENC","op":"Encode","args":{"payload":{"text":"obsolete record: è¿‡æœŸçš„å‚è€ƒèµ„æ–™"},"tags":["cleanup"],"type":"note","use_embedding":True}
    }, "Encode obsolete")

    _run({"stage":"STO","op":"Label","target":{"by_id":str(ids['main']) if ids.get('main') else None},"args":{"tags":["project","meeting","sensitive"]}}, "Label main add sensitive")

    _run({"stage":"RET","op":"Retrieve","args":{"query":"é¡¹ç›®A","k":10,"order_by":"time_desc"}}, "Retrieve project")

    _run({"stage":"RET","op":"Summarize","target":{"by_tags":["project","meeting"],"match":"all"},"args":{"focus":"é¡¹ç›®A ä¼šè®®è¿›å±•","max_tokens":200}}, "Summarize project meetings")

    _run({"stage":"STO","op":"Promote","target":{"by_id":str(ids['main']) if ids.get('main') else None},"args":{"priority":"urgent"}}, "Promote main")

    _run({"stage":"STO","op":"Demote","target":{"by_id":str(ids['secondary']) if ids.get('secondary') else None},"args":{"archive":True}}, "Demote secondary")

    _run({"stage":"STO","op":"Update","target":{"by_tags":["project"]},"args":{"set":{"priority":"high","text":"é¡¹ç›®A ä¼šè®®å†…å®¹å·²æ•´ç†"}}}, "Update project")

    _run({"stage":"STO","op":"Split","target":{"by_id":str(ids['long']) if ids.get('long') else None},"args":{"strategy":"headings","inherit":{"tags":True}}}, "Split long doc")

    _run({"stage":"STO","op":"Merge","target":{"by_tags":["meeting"],"match":"any"},"args":{"strategy":"fold_into_primary","primary_id":str(ids['main']),"soft_delete_children":True}}, "Merge meetings")

    _run({"stage":"STO","op":"Lock","target":{"by_tags":["sensitive"]},"args":{"mode":"read_only","reason":"ä¿æŠ¤æ•æ„Ÿä¼šè®®è®°å½•"}}, "Lock sensitive")

    _run({"stage":"STO","op":"Expire","target":{"by_tags":["temp"]},"args":{"ttl":"P7D","on_expire":"soft_delete"}}, "Expire temp")

    _run({"stage":"STO","op":"Delete","target":{"by_query":"obsolete"},"args":{"soft":True,"reason":"æ¸…ç†è¿‡æ—¶"}}, "Delete obsolete")

    echo("ğŸ‰ FULL DEMO å®Œæˆ")


def main():
    p = argparse.ArgumentParser(add_help=True)
    p.add_argument("--mode", choices=["mock","ollama","openai","auto"], default=None)
    p.add_argument("--db", dest="db_path", default=None)
    args = p.parse_args()
    run_full(args.mode, args.db_path)

if __name__ == "__main__":
    main()
