# Small-scale test generation plan – 5 samples

plan:
  name: "test_5_samples"
  description: "Small-scale generation for testing – only 5 samples"
  version: "1.0"
  
  total_samples: 5
  batch_size: 5
  
  min_context_length: 100
  max_context_length: 200
  
  resume_from_checkpoint: false
  checkpoint_file: "bench/generate/output/.checkpoint_test_5_samples.json"

# Scenario proportions
scenario_proportions:
  incident_postmortem: 0.4
  meeting_notes: 0.3
  project_tracking: 0.3

# Operation proportions
operation_proportions:
  encode: 0.40
  retrieve: 0.30
  summarize: 0.20
  label: 0.10

# Operation definitions
operations:
  encode:
    enabled: true
    description: "Encode / Write memory"
  retrieve:
    enabled: true
    description: "Semantic retrieval"
  summarize:
    enabled: true
    description: "Generate summary"
  label:
    enabled: true
    description: "Add label"

# Scenario definitions
scenarios:
  incident_postmortem:
    name: "Incident Postmortem"
    name_en: "Incident Postmortem"
    enabled: true
  meeting_notes:
    name: "Meeting Notes"
    name_en: "Meeting Notes"
    enabled: true
  project_tracking:
    name: "Project Tracking"
    name_en: "Project Tracking"
    enabled: true

# Sample characteristics
characteristics:
  instruction_style:
    direct: 100%
    indirect: 0%
  
  structure:
    single: 100%
    workflow: 0%
  
  lang:
    zh: 50%
    en: 50%

# LLM configuration
llm:
  provider: "openai"
  model: "gpt-4o-mini"
  api_key_env: "OPENAI_API_KEY"
  base_url: ""
  temperature: 0.7
  max_tokens: 2000
  timeout: 120

# Three-stage pipeline configuration
stages:
  stage1_nl_generation:
    enabled: true
    temperature: 0.7
    max_tokens: 2000
    batch_size: 5
  
  stage2_ir_generation:
    enabled: true
    temperature: 0.5
    max_tokens: 2000
    batch_size: 1
  
  stage3_expected_generation:
    enabled: true
    temperature: 0.5
    max_tokens: 2000
    batch_size: 1

# Output configuration
output:
  base_dir: "bench/data/raw"
  format: "jsonl"
  keep_intermediate: true

# Logging configuration
logging:
  level: "INFO"
  console: true
