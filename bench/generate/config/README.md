<div align="center">

# Configuration File Guide | é…ç½®æ–‡ä»¶è¯´æ˜

**Guide for benchmark generation configuration files**  
**åŸºå‡†ç”Ÿæˆé…ç½®æ–‡ä»¶æŒ‡å—**

</div>

---

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

---

# English

## ğŸ“ File List

| File | Purpose | Status |
|------|---------|--------|
| `generation_plan.yaml` | Main configuration file | âœ… Active |
| `generation_plan_examples.yaml` | Configuration examples | ğŸ“– Reference |
| `config.yaml` | Legacy config (compatibility) | âš ï¸ Kept |

## ğŸ”‘ API Key and Base URL Configuration

### Three Configuration Methods

#### 1. Use Environment Variables (Recommended) â­

**Pros**: Secure, simple, won't expose to Git

```bash
# Set environment variables
export OPENAI_API_KEY=sk-your-key
export OPENAI_API_BASE=https://api.openai.com/v1  # Optional
```

```yaml
# Don't set in config file
llm:
  provider: openai
  model: gpt-4-turbo-preview
  # api_key and base_url auto-read from environment
```

#### 2. Use Environment Variable Placeholders (Team Collaboration) â­

**Pros**: Config file can be committed to Git without exposing real keys

```yaml
llm:
  provider: openai
  model: gpt-4-turbo-preview
  api_key: "${OPENAI_API_KEY}"        # Placeholder
  base_url: "${OPENAI_API_BASE}"      # Placeholder
```

Team members set their own environment variables:
```bash
export OPENAI_API_KEY=sk-their-own-key
```

#### 3. Direct Configuration (Not Recommended) âš ï¸

**Cons**: Exposes keys, not secure

```yaml
llm:
  provider: openai
  model: gpt-4-turbo-preview
  api_key: "sk-your-actual-key"       # âš ï¸ Will expose
  base_url: "https://api.openai.com/v1"
```

## ğŸ“Š Configuration Priority

### API Key Reading Order

1. **Direct config setting**: `api_key: 'sk-xxx'`
2. **Config placeholder**: `api_key: '${OPENAI_API_KEY}'`
3. **System environment variable**: 
   - OpenAI: `OPENAI_API_KEY`
   - Anthropic: `ANTHROPIC_API_KEY`

### Base URL Reading Order

1. **Direct config setting**: `base_url: 'https://...'`
2. **Config placeholder**: `base_url: '${OPENAI_API_BASE}'`
3. **System environment variable**:
   - OpenAI: `OPENAI_API_BASE` or `OPENAI_BASE_URL`
   - Ollama: `OLLAMA_HOST` or `OLLAMA_BASE_URL`
4. **Use default**:
   - OpenAI: `https://api.openai.com/v1`
   - Ollama: `http://localhost:11434`
   - Anthropic: `https://api.anthropic.com`

## ğŸŒ Different Provider Configurations

### OpenAI

```bash
# Set environment variables
export OPENAI_API_KEY=sk-your-key

# Optional: use proxy
export OPENAI_API_BASE=https://your-proxy.com/v1
```

```yaml
llm:
  provider: openai
  model: gpt-4-turbo-preview
  # Or use gpt-3.5-turbo (cheaper)
```

### Ollama (Local/Remote)

```bash
# Local (default)
ollama serve

# Or use remote Ollama
export OLLAMA_HOST=http://192.168.1.100:11434
```

```yaml
llm:
  provider: ollama
  model: qwen2:7b
  # base_url: http://localhost:11434  # Optional, default value
  timeout: 120  # Ollama may need more time
```

### Anthropic

```bash
export ANTHROPIC_API_KEY=sk-ant-your-key
```

```yaml
llm:
  provider: anthropic
  model: claude-3-opus-20240229
```

## ğŸ“ Common Configuration Scenarios

### Scenario 1: Development Testing

```yaml
plan:
  total_samples: 10
  batch_size: 2

llm:
  provider: openai
  model: gpt-3.5-turbo  # Cheaper
  temperature: 0.7
  max_tokens: 1000      # Reduce cost
```

### Scenario 2: Production

```yaml
plan:
  total_samples: 100
  batch_size: 10

llm:
  provider: openai
  model: gpt-4-turbo-preview
  temperature: 0.7
  max_tokens: 4000
```

### Scenario 3: Using Proxy

```yaml
llm:
  provider: openai
  model: gpt-4-turbo-preview
  base_url: "https://your-openai-proxy.com/v1"
```

### Scenario 4: Local Ollama (Free)

```yaml
llm:
  provider: ollama
  model: qwen2:7b
  base_url: http://localhost:11434
  timeout: 120
```

## ğŸ§ª Test Configuration

Verify configuration is correct:

```bash
# Run config test
python bench/generate/tests/test_llm_config.py

# Run system test
python bench/generate/tests/test_system.py
```

## ğŸ’¡ Best Practices

1. âœ… **Use environment variables** - Don't write API keys in config files
2. âœ… **Use placeholders** - Use `${VAR_NAME}` in team configs
3. âœ… **Configure .gitignore** - Ensure files with real keys won't be committed
4. âœ… **Test first** - Test with small samples first
5. âœ… **Document** - Explain which environment variables need to be set

## âš ï¸ Security Tips

- âŒ **Don't** write API keys directly in config files
- âŒ **Don't** commit config files with real keys to Git
- âŒ **Don't** share config files publicly
- âœ… **Use** environment variables or key management systems
- âœ… **Rotate** API keys regularly

## ğŸ“š Related Documentation

- [QUICKSTART.md](../docs/QUICKSTART.md) - Quick setup guide
- [EXAMPLES.md](../docs/EXAMPLES.md) - Usage examples
- [generation_plan_examples.yaml](generation_plan_examples.yaml) - 8 config examples

---

# ä¸­æ–‡

## ğŸ“ æ–‡ä»¶åˆ—è¡¨

| æ–‡ä»¶ | ç”¨é€” | çŠ¶æ€ |
|------|------|------|
| `generation_plan.yaml` | ä¸»é…ç½®æ–‡ä»¶ | âœ… ä½¿ç”¨ä¸­ |
| `generation_plan_examples.yaml` | é…ç½®ç¤ºä¾‹é›†åˆ | ğŸ“– å‚è€ƒ |
| `config.yaml` | æ—§ç‰ˆé…ç½®ï¼ˆå…¼å®¹ï¼‰ | âš ï¸ ä¿ç•™ |

## ğŸ”‘ API Key å’Œ Base URL é…ç½®

### ä¸‰ç§é…ç½®æ–¹å¼

#### 1. ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰â­

**ä¼˜ç‚¹**: å®‰å…¨ã€ç®€å•ã€ä¸ä¼šæš´éœ²åˆ° Git

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY=sk-your-key
export OPENAI_API_BASE=https://api.openai.com/v1  # å¯é€‰
```

```yaml
# é…ç½®æ–‡ä»¶ä¸­ä¸è®¾ç½®
llm:
  provider: openai
  model: gpt-4-turbo-preview
  # api_key å’Œ base_url ä¸é…ç½®ï¼Œè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡è¯»å–
```

#### 2. ä½¿ç”¨ç¯å¢ƒå˜é‡å ä½ç¬¦ï¼ˆå›¢é˜Ÿåä½œæ¨èï¼‰â­

**ä¼˜ç‚¹**: é…ç½®æ–‡ä»¶å¯ä»¥æäº¤åˆ° Gitï¼Œä½†ä¸ä¼šæš´éœ²çœŸå® key

```yaml
llm:
  provider: openai
  model: gpt-4-turbo-preview
  api_key: "${OPENAI_API_KEY}"        # å ä½ç¬¦
  base_url: "${OPENAI_API_BASE}"      # å ä½ç¬¦
```

å›¢é˜Ÿæˆå‘˜å„è‡ªè®¾ç½®ç¯å¢ƒå˜é‡ï¼š
```bash
export OPENAI_API_KEY=sk-their-own-key
```

#### 3. ç›´æ¥é…ç½®ï¼ˆä¸æ¨èï¼‰âš ï¸

**ç¼ºç‚¹**: ä¼šæš´éœ² keyï¼Œä¸å®‰å…¨

```yaml
llm:
  provider: openai
  model: gpt-4-turbo-preview
  api_key: "sk-your-actual-key"       # âš ï¸ ä¼šæš´éœ²
  base_url: "https://api.openai.com/v1"
```

## ğŸ“Š é…ç½®ä¼˜å…ˆçº§

### API Key è¯»å–é¡ºåº

1. **é…ç½®æ–‡ä»¶ç›´æ¥è®¾ç½®**: `api_key: 'sk-xxx'`
2. **é…ç½®æ–‡ä»¶ç¯å¢ƒå˜é‡å ä½ç¬¦**: `api_key: '${OPENAI_API_KEY}'`
3. **ç³»ç»Ÿç¯å¢ƒå˜é‡**: 
   - OpenAI: `OPENAI_API_KEY`
   - Anthropic: `ANTHROPIC_API_KEY`

### Base URL è¯»å–é¡ºåº

1. **é…ç½®æ–‡ä»¶ç›´æ¥è®¾ç½®**: `base_url: 'https://...'`
2. **é…ç½®æ–‡ä»¶ç¯å¢ƒå˜é‡å ä½ç¬¦**: `base_url: '${OPENAI_API_BASE}'`
3. **ç³»ç»Ÿç¯å¢ƒå˜é‡**:
   - OpenAI: `OPENAI_API_BASE` æˆ– `OPENAI_BASE_URL`
   - Ollama: `OLLAMA_HOST` æˆ– `OLLAMA_BASE_URL`
4. **ä½¿ç”¨é»˜è®¤å€¼**:
   - OpenAI: `https://api.openai.com/v1`
   - Ollama: `http://localhost:11434`
   - Anthropic: `https://api.anthropic.com`

## ğŸŒ ä¸åŒæä¾›å•†çš„é…ç½®

### OpenAI

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY=sk-your-key

# å¯é€‰ï¼šä½¿ç”¨ä»£ç†
export OPENAI_API_BASE=https://your-proxy.com/v1
```

```yaml
llm:
  provider: openai
  model: gpt-4-turbo-preview
  # æˆ–ä½¿ç”¨ gpt-3.5-turboï¼ˆæ›´ä¾¿å®œï¼‰
```

### Ollamaï¼ˆæœ¬åœ°/è¿œç¨‹ï¼‰

```bash
# æœ¬åœ°ï¼ˆé»˜è®¤ï¼‰
ollama serve

# æˆ–ä½¿ç”¨è¿œç¨‹ Ollama
export OLLAMA_HOST=http://192.168.1.100:11434
```

```yaml
llm:
  provider: ollama
  model: qwen2:7b
  # base_url: http://localhost:11434  # å¯é€‰ï¼Œé»˜è®¤å€¼
  timeout: 120  # Ollama å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
```

### Anthropic

```bash
export ANTHROPIC_API_KEY=sk-ant-your-key
```

```yaml
llm:
  provider: anthropic
  model: claude-3-opus-20240229
```

## ğŸ“ å¸¸è§é…ç½®åœºæ™¯

### åœºæ™¯1: å¼€å‘æµ‹è¯•

```yaml
plan:
  total_samples: 10
  batch_size: 2

llm:
  provider: openai
  model: gpt-3.5-turbo  # ä¾¿å®œ
  temperature: 0.7
  max_tokens: 1000      # å‡å°‘æ¶ˆè€—
```

### åœºæ™¯2: ç”Ÿäº§ç¯å¢ƒ

```yaml
plan:
  total_samples: 100
  batch_size: 10

llm:
  provider: openai
  model: gpt-4-turbo-preview
  temperature: 0.7
  max_tokens: 4000
```

### åœºæ™¯3: ä½¿ç”¨ä»£ç†

```yaml
llm:
  provider: openai
  model: gpt-4-turbo-preview
  base_url: "https://your-openai-proxy.com/v1"
```

### åœºæ™¯4: æœ¬åœ° Ollamaï¼ˆå…è´¹ï¼‰

```yaml
llm:
  provider: ollama
  model: qwen2:7b
  base_url: http://localhost:11434
  timeout: 120
```

## ğŸ§ª æµ‹è¯•é…ç½®

éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®ï¼š

```bash
# è¿è¡Œé…ç½®æµ‹è¯•
python bench/generate/tests/test_llm_config.py

# è¿è¡Œç³»ç»Ÿæµ‹è¯•
python bench/generate/tests/test_system.py
```

## ğŸ’¡ æœ€ä½³å®è·µ

1. âœ… **ä½¿ç”¨ç¯å¢ƒå˜é‡** - ä¸è¦åœ¨é…ç½®æ–‡ä»¶ä¸­å†™ API key
2. âœ… **ä½¿ç”¨å ä½ç¬¦** - å›¢é˜Ÿåä½œæ—¶åœ¨é…ç½®ä¸­ä½¿ç”¨ `${VAR_NAME}`
3. âœ… **é…ç½® .gitignore** - ç¡®ä¿ä¸ä¼šæäº¤å«æœ‰çœŸå® key çš„æ–‡ä»¶
4. âœ… **æµ‹è¯•ä¼˜å…ˆ** - å…ˆç”¨å°æ ·æœ¬æµ‹è¯•é…ç½®
5. âœ… **æ–‡æ¡£åŒ–** - åœ¨å›¢é˜Ÿä¸­è¯´æ˜éœ€è¦è®¾ç½®å“ªäº›ç¯å¢ƒå˜é‡

## âš ï¸ å®‰å…¨æç¤º

- âŒ **ä¸è¦**åœ¨é…ç½®æ–‡ä»¶ä¸­ç›´æ¥å†™ API key
- âŒ **ä¸è¦**å°†å«æœ‰çœŸå® key çš„é…ç½®æ–‡ä»¶æäº¤åˆ° Git
- âŒ **ä¸è¦**åœ¨å…¬å¼€çš„åœ°æ–¹åˆ†äº«é…ç½®æ–‡ä»¶
- âœ… **ä½¿ç”¨**ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†ç³»ç»Ÿ
- âœ… **å®šæœŸè½®æ¢** API key

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [QUICKSTART.md](../docs/QUICKSTART.md) - å¿«é€Ÿé…ç½®æŒ‡å—
- [EXAMPLES.md](../docs/EXAMPLES.md) - ä½¿ç”¨ç¤ºä¾‹
- [generation_plan_examples.yaml](generation_plan_examples.yaml) - 8ä¸ªé…ç½®ç¤ºä¾‹

---

<div align="center">

**Last Updated | æœ€åæ›´æ–°**: 2026-01-07  
**Version | ç‰ˆæœ¬**: v3.0

[â¬† Back to top | è¿”å›é¡¶éƒ¨](#configuration-file-guide--é…ç½®æ–‡ä»¶è¯´æ˜)

</div>
