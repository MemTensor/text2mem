#!/usr/bin/env python3
"""
dataæ¸…æ´—å·¥å…·

Features:
1. fromstage3å’Œtestresultä¸­ç­›é€‰sample
2. åº”ç”¨è¿‡æ»¤è§„åˆ™
3. generateæ¸…æ´—åçš„data

Usage:
    # æ¸…æ´—latestrun
    python -m bench.tools.clean --run latest
    
    # æ¸…æ´—specifiedrun
    python -m bench.tools.clean --run 20251015_131147
    
    # ä¸è¿‡æ»¤unknown
    python -m bench.tools.clean --run latest --no-filter-unknown
"""

import argparse
import json
import logging
from collections import Counter
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set

from bench.tools.run_manager import RunManager

logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DataCleaner:
    """dataæ¸…æ´—å™¨"""
    
    # defaultè¿‡æ»¤è§„åˆ™
    ALLOWED_INSTRUCTION_TYPES = {'direct', 'indirect'}
    ALLOWED_STRUCTURES = {'single', 'workflow'}
    ALLOWED_OPERATIONS = {
        'Encode', 'Retrieve', 'Update', 'Delete', 'Summarize', 'Label',
        'Promote', 'Demote', 'Expire', 'Lock', 'Merge', 'Split',
    }
    
    def __init__(
        self,
        run_id: str,
        filter_unknown: bool = True,
        filter_failed: bool = True,
    ):
        """
        Args:
            run_id: Run ID
            filter_unknown: whetherè¿‡æ»¤includeunknownçš„sample
            filter_failed: whetherè¿‡æ»¤testfailedçš„sample
        """
        self.run_id = run_id
        self.filter_unknown = filter_unknown
        self.filter_failed = filter_failed
        
        self.run_manager = RunManager()
        self.run_dir = self.run_manager.get_run_dir(run_id)
        self.cleaned_dir = self.run_manager.get_cleaned_dir(run_id)
        
        self.samples: List[Dict[str, Any]] = []
        self.passed_sample_ids: Set[str] = set()
        
        self.stats = {
            'total_loaded': 0,
            'total_passed_tests': 0,
            'total_filtered': 0,
            'total_final': 0,
            'filter_reasons': {
                'failed_test': 0,
                'unknown_fields': 0,
                'invalid_instruction_type': 0,
                'invalid_structure': 0,
                'invalid_operation': 0,
            }
        }
        
        logger.info(f"ğŸ“‚ Rundirectory: {self.run_dir}")
        logger.info(f"ğŸ“‚ æ¸…æ´—è¾“å‡º: {self.cleaned_dir}")
    
    def load_test_results(self):
        """loadtestresult"""
        if not self.filter_failed:
            logger.info("âš ï¸  ä¸è¿‡æ»¤testfailedçš„sample")
            return
        
        has_tests = self.run_manager.has_tests(self.run_id)
        if not has_tests:
            logger.warning("âš ï¸  æ²¡æœ‰testresultï¼Œwillä¸è¿‡æ»¤failedsample")
            self.filter_failed = False
            return
        
        tests_dir = self.run_manager.get_tests_dir(self.run_id)
        
        # ä¼˜å…ˆUsepassed.jsonlï¼Œifä¸existåˆ™Usedetails.jsonl
        passed_file = tests_dir / 'passed.jsonl'
        details_file = tests_dir / 'details.jsonl'
        
        passed_count = 0
        if passed_file.exists():
            logger.info(f"ğŸ“‚ loadtestresult: {passed_file}")
            with passed_file.open('r', encoding='utf-8') as f:
                for line in f:
                    if not line.strip():
                        continue
                    result = json.loads(line)
                    self.passed_sample_ids.add(result['sample_id'])
                    passed_count += 1
        elif details_file.exists():
            logger.info(f"ğŸ“‚ fromè¯¦ç»†resultä¸­loadviaçš„sample: {details_file}")
            with details_file.open('r', encoding='utf-8') as f:
                for line in f:
                    if not line.strip():
                        continue
                    result = json.loads(line)
                    # åªæ·»åŠ passed=Trueçš„sample
                    if result.get('passed', False):
                        self.passed_sample_ids.add(result['sample_id'])
                        passed_count += 1
        else:
            logger.warning(f"âš ï¸  notfoundtestresultfile")
            self.filter_failed = False
            return
        
        # ifæœ‰é‡å¤IDï¼Œè¾“å‡ºè­¦å‘Š
        unique_ids = len(self.passed_sample_ids)
        if passed_count > unique_ids:
            logger.warning(f"âš ï¸  å‘ç° {passed_count - unique_ids} ä¸ªé‡å¤çš„sample_idåœ¨testresultä¸­")
            logger.warning(f"   è¿™mayæ˜¯becausegenerateçš„dataæœ‰é‡å¤IDï¼Œå»ºè®®checkgenerateé€»è¾‘")
        
        logger.info(f"âœ… load {unique_ids} ä¸ªå”¯ä¸€çš„viatestçš„sampleID (total {passed_count} æ¡viarecord)")
        self.stats['total_passed_tests'] = unique_ids
        self.stats['total_passed_records'] = passed_count
    
    def load_samples(self):
        """loadåŸå§‹sample countæ®"""
        # gettoæºraw
        raw_id = self.run_manager.get_source_raw(self.run_id)
        if not raw_id:
            raise FileNotFoundError(f"unable toç¡®å®šrun {self.run_id} çš„toæºraw")
        
        stage3_file = self.run_manager.get_stage_file_from_raw(raw_id, 3)
        
        if not stage3_file.exists():
            raise FileNotFoundError(f"Stage3fileä¸exist: {stage3_file}")
        
        logger.info(f"ğŸ“‚ loadsample countæ®: {stage3_file}")
        
        count = 0
        with stage3_file.open('r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                try:
                    sample = json.loads(line)
                    self.samples.append(sample)
                    count += 1
                except json.JSONDecodeError as e:
                    logger.warning(f"âš ï¸  è¡Œ {line_num} è§£æfailed: {e}")
        
        logger.info(f"âœ… load {count} ä¸ªsample")
        self.stats['total_loaded'] = count
    
    def filter_samples(self) -> List[Dict[str, Any]]:
        """è¿‡æ»¤sample"""
        logger.info("ğŸ§¹ startè¿‡æ»¤sample...")
        logger.info(f"   filter_failed={self.filter_failed}, passed_ids count={len(self.passed_sample_ids)}")
        
        filtered_samples = []
        
        for sample in self.samples:
            sample_id = sample.get('id', '')
            class_info = sample.get('class', {})
            
            # è§„åˆ™1: è¿‡æ»¤testfailedçš„sample
            if self.filter_failed and sample_id not in self.passed_sample_ids:
                self.stats['filter_reasons']['failed_test'] += 1
                self.stats['total_filtered'] += 1
                continue
            
            # æå–å­—æ®µ
            lang = class_info.get('lang', 'unknown')
            instruction_type = class_info.get('instruction_type', 'unknown')
            structure = class_info.get('structure', 'unknown')
            
            # æå–æ“ä½œ
            schema_list = sample.get('schema_list', [])
            if not schema_list:
                self.stats['filter_reasons']['invalid_operation'] += 1
                self.stats['total_filtered'] += 1
                continue
            
            operation = schema_list[0].get('op', 'unknown')
            
            # è§„åˆ™2: è¿‡æ»¤includeunknownçš„sample
            if self.filter_unknown and 'unknown' in [lang, instruction_type, structure, operation]:
                self.stats['filter_reasons']['unknown_fields'] += 1
                self.stats['total_filtered'] += 1
                continue
            
            # è§„åˆ™3: checkæŒ‡ä»¤type
            if instruction_type not in self.ALLOWED_INSTRUCTION_TYPES:
                self.stats['filter_reasons']['invalid_instruction_type'] += 1
                self.stats['total_filtered'] += 1
                continue
            
            # è§„åˆ™4: checkç»“æ„
            if structure not in self.ALLOWED_STRUCTURES:
                self.stats['filter_reasons']['invalid_structure'] += 1
                self.stats['total_filtered'] += 1
                continue
            
            # è§„åˆ™5: checkæ“ä½œ
            if operation not in self.ALLOWED_OPERATIONS:
                self.stats['filter_reasons']['invalid_operation'] += 1
                self.stats['total_filtered'] += 1
                continue
            
            # viaallè¿‡æ»¤
            filtered_samples.append(sample)
        
        self.stats['total_final'] = len(filtered_samples)
        logger.info(f"âœ… è¿‡æ»¤complete: {len(filtered_samples)} ä¸ªsampleä¿ç•™")
        logger.info(f"   è¿‡æ»¤æ‰: {self.stats['total_filtered']} ä¸ªsample")
        
        return filtered_samples
    
    def save_cleaned_data(self, samples: List[Dict[str, Any]]):
        """saveæ¸…æ´—åçš„data"""
        logger.info("ğŸ’¾ saveæ¸…æ´—åçš„data...")
        
        # 1. saveæ¸…æ´—åçš„sample
        cleaned_file = self.cleaned_dir / 'cleaned.jsonl'
        with cleaned_file.open('w', encoding='utf-8') as f:
            for sample in samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        logger.info(f"  âœ… æ¸…æ´—data: {cleaned_file}")
        
        # 2. generatemetadata
        # gettoæºraw
        raw_id = self.run_manager.get_source_raw(self.run_id)
        
        metadata = {
            'run_id': self.run_id,
            'created_at': datetime.now().isoformat(),
            'source_raw': raw_id,
            'source_stage3': str(self.run_manager.get_stage_file_from_raw(raw_id, 3)) if raw_id else None,
            'total_samples': len(samples),
            'filtering': {
                'filter_unknown': self.filter_unknown,
                'filter_failed': self.filter_failed,
            },
            'stats': self.stats,
        }
        
        metadata_file = self.cleaned_dir / 'metadata.json'
        with metadata_file.open('w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        logger.info(f"  âœ… metadata: {metadata_file}")
        
        # 3. generatestatistics
        stats = self._generate_stats(samples)
        stats_file = self.cleaned_dir / 'stats.json'
        with stats_file.open('w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        logger.info(f"  âœ… statistics: {stats_file}")
        
        # 4. generateè¿‡æ»¤report
        filter_report = {
            'created_at': datetime.now().isoformat(),
            'total_loaded': self.stats['total_loaded'],
            'total_passed_tests': self.stats['total_passed_tests'],
            'total_passed_records': self.stats.get('total_passed_records', self.stats['total_passed_tests']),
            'total_filtered': self.stats['total_filtered'],
            'total_final': self.stats['total_final'],
            'retention_rate': self.stats['total_final'] / self.stats['total_loaded'] * 100 if self.stats['total_loaded'] > 0 else 0,
            'filter_reasons': self.stats['filter_reasons'],
        }
        
        report_file = self.cleaned_dir / 'filter_report.json'
        with report_file.open('w', encoding='utf-8') as f:
            json.dump(filter_report, f, ensure_ascii=False, indent=2)
        logger.info(f"  âœ… è¿‡æ»¤report: {report_file}")
        
        logger.info(f"ğŸ’¾ allfilealreadysaveto: {self.cleaned_dir}")
    
    def _generate_stats(self, samples: List[Dict[str, Any]]) -> Dict[str, Any]:
        """generatestatistics"""
        langs = Counter()
        operations = Counter()
        instruction_types = Counter()
        structures = Counter()
        
        for sample in samples:
            class_info = sample.get('class', {})
            
            langs[class_info.get('lang', 'unknown')] += 1
            instruction_types[class_info.get('instruction_type', 'unknown')] += 1
            structures[class_info.get('structure', 'unknown')] += 1
            
            schema_list = sample.get('schema_list', [])
            if schema_list:
                operations[schema_list[0].get('op', 'unknown')] += 1
        
        return {
            'total': len(samples),
            'distribution': {
                'languages': dict(langs.most_common()),
                'operations': dict(operations.most_common()),
                'instruction_types': dict(instruction_types.most_common()),
                'structures': dict(structures.most_common()),
            }
        }
    
    def print_summary(self):
        """æ‰“å°æ¸…æ´—æ‘˜è¦"""
        print("\n" + "="*80)
        print("ğŸ“Š æ¸…æ´—æ‘˜è¦")
        print("="*80)
        
        print(f"\nå¤„ç†ç»Ÿè®¡:")
        print(f"  loadsample count: {self.stats['total_loaded']}")
        if self.stats['total_passed_tests'] > 0:
            print(f"  viatest: {self.stats['total_passed_tests']}")
        print(f"  è¿‡æ»¤sample count: {self.stats['total_filtered']}")
        print(f"  æœ€ç»ˆsample count: {self.stats['total_final']}")
        print(f"  ä¿ç•™æ¯”ä¾‹: {self.stats['total_final']/self.stats['total_loaded']*100:.1f}%")
        
        if self.stats['total_filtered'] > 0:
            print(f"\nè¿‡æ»¤åŸå› :")
            for reason, count in self.stats['filter_reasons'].items():
                if count > 0:
                    print(f"  {reason}: {count} ä¸ª")
        
        print("\n" + "="*80)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="dataæ¸…æ´—å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
è¿‡æ»¤è§„åˆ™:
  1. è¿‡æ»¤testfailedçš„sampleï¼ˆifæœ‰testresultï¼‰
  2. è¿‡æ»¤include'unknown'çš„sample
  3. åªä¿ç•™'direct'å’Œ'indirect'æŒ‡ä»¤type
  4. åªä¿ç•™'single'å’Œ'workflow'ç»“æ„
  5. åªä¿ç•™12ç§æ ¸å¿ƒæ“ä½œ

example:
  # æ¸…æ´—latestrun
  python -m bench.tools.clean --run latest
  
  # æ¸…æ´—specifiedrun
  python -m bench.tools.clean --run 20251015_131147
  
  # ä¸è¿‡æ»¤unknownå­—æ®µ
  python -m bench.tools.clean --run latest --no-filter-unknown
  
  # ä¸è¿‡æ»¤failedsample
  python -m bench.tools.clean --run latest --no-filter-failed
        """
    )
    
    parser.add_argument(
        '--run', '-r',
        default='latest',
        help='Run ID (å¦‚ "20251015_131147" or "latest"ï¼Œdefault: latest)'
    )
    parser.add_argument(
        '--no-filter-unknown',
        action='store_true',
        help='ä¸è¿‡æ»¤includeunknownçš„sample'
    )
    parser.add_argument(
        '--no-filter-failed',
        action='store_true',
        help='ä¸è¿‡æ»¤testfailedçš„sample'
    )
    
    args = parser.parse_args()
    
    # createæ¸…æ´—å™¨
    try:
        cleaner = DataCleaner(
            run_id=args.run,
            filter_unknown=not args.no_filter_unknown,
            filter_failed=not args.no_filter_failed,
        )
    except FileNotFoundError as e:
        logger.error(f"âŒ {e}")
        return 1
    
    try:
        # 1. loadtestresult
        cleaner.load_test_results()
        
        # 2. loadsample
        cleaner.load_samples()
        
        # 3. è¿‡æ»¤sample
        filtered_samples = cleaner.filter_samples()
        
        if not filtered_samples:
            logger.error("âŒ æ²¡æœ‰sampleviaè¿‡æ»¤")
            return 1
        
        # 4. saveæ¸…æ´—åçš„data
        cleaner.save_cleaned_data(filtered_samples)
        
        # 5. æ‰“å°æ‘˜è¦
        cleaner.print_summary()
        
        print(f"\nâœ… æ¸…æ´—completeï¼")
        return 0
        
    except Exception as e:
        logger.error(f"âŒ æ¸…æ´—failed: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())
