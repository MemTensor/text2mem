#!/usr/bin/env python3
"""
Benchmarkå®Œæ•´æµç¨‹å·¥å…· v3.0

åŠŸèƒ½ï¼š
ä»rawæ•°æ®åˆ°æœ€ç»ˆbenchmarkçš„å®Œæ•´è‡ªåŠ¨åŒ–æµç¨‹ï¼š
1. æµ‹è¯•ï¼ˆåˆ›å»ºrunï¼‰
2. æ¸…æ´—å¹¶æ„å»ºbenchmarkï¼ˆåˆå¹¶æ­¥éª¤ï¼‰

ç”¨æ³•ï¼š
    # å¤„ç†æœ€æ–°raw
    python -m bench.tools.pipeline --raw latest --version v2
    
    # å¤„ç†æŒ‡å®šraw
    python -m bench.tools.pipeline --raw 20251015_131147 --version v2
    
    # è·³è¿‡æµ‹è¯•æ­¥éª¤
    python -m bench.tools.pipeline --raw latest --version v2 --skip-tests
"""

import argparse
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional

from bench.tools.run_manager import RunManager

logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class BenchmarkPipeline:
    """Benchmarkå®Œæ•´æµç¨‹"""
    
    def __init__(
        self,
        raw_id: str,
        version: Optional[str] = None,
        skip_tests: bool = False,
        verbose: bool = False,
    ):
        """
        Args:
            raw_id: Raw ID
            version: Benchmarkç‰ˆæœ¬å·ï¼ˆå¦‚v2, v3ç­‰ï¼‰
            skip_tests: è·³è¿‡æµ‹è¯•è¿è¡Œ
            verbose: è¯¦ç»†è¾“å‡º
        """
        self.raw_id = raw_id
        self.verbose = verbose
        self.skip_tests = skip_tests
        
        # ç¡®å®šè¾“å‡ºç‰ˆæœ¬
        if version:
            self.version = version
        else:
            # è‡ªåŠ¨ç”Ÿæˆç‰ˆæœ¬å·ï¼ˆåŸºäºraw_idï¼‰
            if raw_id == 'latest':
                run_manager = RunManager()
                actual_raw_id = run_manager.get_latest_raw()
            else:
                actual_raw_id = raw_id
            self.version = f"v_{actual_raw_id}"
        
        self.run_manager = RunManager()
        
        # è·å–rawç›®å½•
        try:
            self.raw_dir = self.run_manager.get_raw_dir(raw_id)
            if raw_id == 'latest':
                self.raw_id = self.run_manager.get_latest_raw()
        except FileNotFoundError as e:
            logger.error(f"âŒ {e}")
            raise
        
        logger.info(f"ğŸ“‹ Pipelineé…ç½®:")
        logger.info(f"  Raw ID: {self.raw_id}")
        logger.info(f"  Rawç›®å½•: {self.raw_dir}")
        logger.info(f"  Benchmarkç‰ˆæœ¬: {self.version}")
    
    def run(self) -> bool:
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        logger.info("\n" + "="*80)
        logger.info("ğŸš€ å¼€å§‹Benchmarkæ„å»ºæµç¨‹")
        logger.info("="*80)
        
        try:
            # Step 1: è¿è¡Œæµ‹è¯•ï¼ˆåˆ›å»ºrunï¼‰
            if not self.skip_tests:
                if not self._step1_tests():
                    return False
            else:
                logger.info("\nâ­ï¸  è·³è¿‡æµ‹è¯•è¿è¡Œ")
                # å¦‚æœè·³è¿‡æµ‹è¯•ï¼Œéœ€è¦ç¡®ä¿runå·²å­˜åœ¨
                runs = self.run_manager.list_runs()
                if self.raw_id not in runs:
                    logger.error(f"âŒ Runä¸å­˜åœ¨: {self.raw_id}")
                    logger.info("   æç¤ºï¼šä¸èƒ½è·³è¿‡æµ‹è¯•ï¼Œå› ä¸ºrunè¿˜æœªåˆ›å»º")
                    return False
            
            # ç¡®å®šrun_id
            self.run_id = self.raw_id
            
            # Step 2: æ¸…æ´—å¹¶æ„å»ºbenchmarkï¼ˆåˆå¹¶æ­¥éª¤ï¼‰
            if not self._step2_clean_and_build():
                return False
            
            logger.info("\n" + "="*80)
            logger.info("âœ… Pipelineå®Œæˆï¼")
            logger.info("="*80)
            
            return True
            
        except Exception as e:
            logger.error(f"\nâŒ Pipelineå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _step1_tests(self) -> bool:
        """Step 1: è¿è¡Œæµ‹è¯•ï¼ˆåˆ›å»ºrunï¼‰"""
        logger.info("\n" + "="*80)
        logger.info("ğŸ§ª Step 1: è¿è¡Œæµ‹è¯•ï¼ˆåˆ›å»ºrunï¼‰")
        logger.info("="*80)
        
        from bench.tools.test import TestRunner
        
        runner = TestRunner(raw_id=self.raw_id, verbose=self.verbose)
        runner.load_samples()
        runner.run_tests()
        runner.save_results()
        
        if self.verbose:
            runner.print_summary()
        
        # æ£€æŸ¥æµ‹è¯•ç»“æœ
        if runner.stats['failed'] > 0:
            logger.warning(f"âš ï¸  æœ‰ {runner.stats['failed']} ä¸ªæ ·æœ¬æµ‹è¯•å¤±è´¥")
            logger.warning(f"   è¿™äº›æ ·æœ¬å°†åœ¨æ¸…æ´—æ­¥éª¤ä¸­è¢«è¿‡æ»¤æ‰")
        
        self.run_id = runner.run_id
        logger.info(f"âœ… Step 1 å®Œæˆ: {runner.tests_dir}")
        return True
    
    def _step2_clean_and_build(self) -> bool:
        """Step 2: æ¸…æ´—å¹¶æ„å»ºbenchmarkï¼ˆåˆå¹¶æ­¥éª¤ï¼‰"""
        logger.info("\n" + "="*80)
        logger.info("ğŸ§¹ Step 2: æ¸…æ´—æ•°æ®å¹¶æ„å»ºBenchmark")
        logger.info("="*80)
        
        from bench.tools.clean import DataCleaner
        from bench.tools.build import BenchmarkBuilder
        
        # 2.1 æ¸…æ´—æ•°æ®
        logger.info("ğŸ“ 2.1 æ¸…æ´—æ•°æ®...")
        cleaner = DataCleaner(
            run_id=self.run_id,
            filter_unknown=True,
            filter_failed=(not self.skip_tests),
        )
        
        cleaner.load_test_results()
        cleaner.load_samples()
        filtered_samples = cleaner.filter_samples()
        
        if not filtered_samples:
            logger.error("âŒ æ²¡æœ‰æ ·æœ¬é€šè¿‡è¿‡æ»¤")
            return False
        
        cleaner.save_cleaned_data(filtered_samples)
        
        if self.verbose:
            cleaner.print_summary()
        
        logger.info(f"âœ… æ¸…æ´—å®Œæˆ: {self.run_manager.get_cleaned_dir(self.run_id)}")
        
        # 2.2 æ„å»ºbenchmark
        logger.info("\nğŸ“ 2.2 æ„å»ºBenchmark...")
        builder = BenchmarkBuilder(
            run_id=self.run_id,
            version=self.version,
            rebuild_ids=True,
        )
        
        builder.load_cleaned_data()
        builder.rebuild_sample_ids()
        builder.build()
        
        if self.verbose:
            builder.print_summary()
        
        logger.info(f"âœ… æ„å»ºå®Œæˆ: {self.run_manager.get_benchmark_dir(self.version)}")
        
        return True
    
    def print_summary(self):
        """æ‰“å°å®Œæ•´æ‘˜è¦"""
        print("\n" + "="*80)
        print("ğŸ“‹ Pipelineæ‘˜è¦")
        print("="*80)
        
        print(f"\nè¾“å…¥:")
        print(f"  Raw ID: {self.raw_id}")
        print(f"  Rawç›®å½•: {self.raw_dir}")
        
        print(f"\nè¾“å‡º:")
        print(f"  Run ID: {self.run_id}")
        print(f"  Runç›®å½•: {self.run_manager.get_run_dir(self.run_id)}")
        print(f"  Benchmarkç‰ˆæœ¬: {self.version}")
        print(f"  Benchmarkç›®å½•: {self.run_manager.get_benchmark_dir(self.version)}")
        
        print(f"\næ‰§è¡Œçš„æ­¥éª¤:")
        steps = []
        if not self.skip_tests:
            steps.append("âœ… è¿è¡Œæµ‹è¯•ï¼ˆåˆ›å»ºrunï¼‰")
        steps.append("âœ… æ¸…æ´—æ•°æ®å¹¶æ„å»ºBenchmark")
        
        for step in steps:
            print(f"  {step}")
        
        print(f"\nä¸‹ä¸€æ­¥:")
        print(f"  # éªŒè¯benchmark")
        print(f"  python -m bench run --split benchmark --verbose")
        
        print("\n" + "="*80)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Benchmarkå®Œæ•´æµç¨‹å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
å®Œæ•´æµç¨‹åŒ…æ‹¬:
  1. è¿è¡Œæµ‹è¯• - ä»rawåˆ›å»ºrunå¹¶æµ‹è¯•æ‰€æœ‰æ ·æœ¬
  2. æ¸…æ´—å¹¶æ„å»º - è¿‡æ»¤å¤±è´¥æ ·æœ¬ï¼Œåº”ç”¨è§„åˆ™ï¼Œé‡æ–°åˆ†é…IDï¼Œç”Ÿæˆæœ€ç»ˆbenchmark

ç¤ºä¾‹:
  # å¤„ç†æœ€æ–°raw
  python -m bench.tools.pipeline --raw latest --version v2
  
  # å¤„ç†æŒ‡å®šraw
  python -m bench.tools.pipeline --raw 20251015_131147 --version v2
  
  # è·³è¿‡æµ‹è¯•ï¼Œç›´æ¥æ¸…æ´—å¹¶æ„å»ºï¼ˆrunå¿…é¡»å·²å­˜åœ¨ï¼‰
  python -m bench.tools.pipeline --raw latest --version v2 --skip-tests
        """
    )
    
    parser.add_argument(
        '--raw',
        required=True,
        help='Raw ID (å¦‚ "20251015_131147" æˆ– "latest")'
    )
    parser.add_argument(
        '--version', '-v',
        help='Benchmarkç‰ˆæœ¬å· (å¦‚ "v2", "v3"ï¼Œé»˜è®¤ï¼šè‡ªåŠ¨ç”Ÿæˆ)'
    )
    parser.add_argument(
        '--skip-tests',
        action='store_true',
        help='è·³è¿‡æµ‹è¯•è¿è¡Œï¼ˆrunå¿…é¡»å·²å­˜åœ¨ï¼‰'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º'
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºpipeline
    try:
        pipeline = BenchmarkPipeline(
            raw_id=args.raw,
            version=args.version,
            skip_tests=args.skip_tests,
            verbose=args.verbose,
        )
    except FileNotFoundError:
        return 1
    
    # è¿è¡Œ
    success = pipeline.run()
    
    if success:
        pipeline.print_summary()
        return 0
    else:
        return 1


if __name__ == '__main__':
    sys.exit(main())
