#!/usr/bin/env python3
"""
æ¸…æ´— Benchmark æ•°æ®

è¿‡æ»¤è§„åˆ™:
1. åˆ é™¤æ‰€æœ‰åŒ…å« 'unknown' çš„æ ·æœ¬
2. æŒ‡ä»¤ç±»å‹ï¼šåªä¿ç•™ 'direct' å’Œ 'indirect'
3. ç»“æ„ï¼šåªä¿ç•™ 'single' å’Œ 'workflow'
4. æ“ä½œï¼šåªä¿ç•™ 12 ç§æ ¸å¿ƒæ“ä½œ

ç”¨æ³•:
    python clean_benchmark.py
    python clean_benchmark.py --input my_input.jsonl --output my_output.jsonl
"""

import argparse
import json
import logging
from pathlib import Path
from typing import Dict, Any, Set

logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class BenchmarkCleaner:
    """Benchmark æ•°æ®æ¸…æ´—å™¨"""
    
    # å…è®¸çš„å€¼
    ALLOWED_INSTRUCTION_TYPES = {'direct', 'indirect'}
    ALLOWED_STRUCTURES = {'single', 'workflow'}
    ALLOWED_OPERATIONS = {
        'Encode',      # ç¼–ç /ä¿å­˜
        'Retrieve',    # æ£€ç´¢
        'Update',      # æ›´æ–°
        'Delete',      # åˆ é™¤
        'Summarize',   # æ€»ç»“
        'Label',       # æ ‡ç­¾
        'Promote',     # æå‡
        'Demote',      # é™çº§
        'Expire',      # è¿‡æœŸ
        'Lock',        # é”å®š
        'Merge',       # åˆå¹¶
        'Split',       # æ‹†åˆ†
    }
    
    def __init__(self):
        self.samples = []
        self.stats = {
            'total': 0,
            'filtered': 0,
            'reasons': {
                'unknown_in_fields': 0,
                'invalid_instruction_type': 0,
                'invalid_structure': 0,
                'invalid_operation': 0,
            }
        }
    
    def load_samples(self, input_file: Path) -> int:
        """åŠ è½½æ ·æœ¬"""
        logger.info(f"ğŸ“‚ åŠ è½½æ ·æœ¬: {input_file}")
        
        count = 0
        with input_file.open('r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                try:
                    sample = json.loads(line)
                    self.samples.append(sample)
                    count += 1
                except json.JSONDecodeError as e:
                    logger.warning(f"âš ï¸  è¡Œ {line_num} è§£æå¤±è´¥: {e}")
        
        self.stats['total'] = count
        logger.info(f"âœ… åŠ è½½ {count} ä¸ªæ ·æœ¬")
        return count
    
    def check_sample(self, sample: Dict[str, Any]) -> tuple[bool, str]:
        """æ£€æŸ¥æ ·æœ¬æ˜¯å¦ç¬¦åˆè¦æ±‚
        
        Returns:
            (æ˜¯å¦ä¿ç•™, åŸå› )
        """
        class_info = sample.get('class', {})
        
        # æå–å­—æ®µ
        lang = class_info.get('lang', 'unknown')
        instruction_type = class_info.get('instruction_type', 'unknown')
        structure = class_info.get('structure', 'unknown')
        
        # æå–æ“ä½œ
        schema_list = sample.get('schema_list', [])
        if not schema_list:
            return False, 'invalid_operation'
        
        operation = schema_list[0].get('op', 'unknown')
        
        # æ£€æŸ¥ 1: æ˜¯å¦åŒ…å« unknown
        if 'unknown' in [lang, instruction_type, structure, operation]:
            return False, 'unknown_in_fields'
        
        # æ£€æŸ¥ 2: æŒ‡ä»¤ç±»å‹
        if instruction_type not in self.ALLOWED_INSTRUCTION_TYPES:
            return False, 'invalid_instruction_type'
        
        # æ£€æŸ¥ 3: ç»“æ„
        if structure not in self.ALLOWED_STRUCTURES:
            return False, 'invalid_structure'
        
        # æ£€æŸ¥ 4: æ“ä½œ
        if operation not in self.ALLOWED_OPERATIONS:
            return False, 'invalid_operation'
        
        return True, 'valid'
    
    def clean(self):
        """æ¸…æ´—æ•°æ®"""
        logger.info("ğŸ§¹ å¼€å§‹æ¸…æ´—æ•°æ®...")
        
        cleaned_samples = []
        
        for sample in self.samples:
            keep, reason = self.check_sample(sample)
            
            if keep:
                cleaned_samples.append(sample)
            else:
                self.stats['filtered'] += 1
                self.stats['reasons'][reason] += 1
        
        self.samples = cleaned_samples
        
        logger.info(f"âœ… æ¸…æ´—å®Œæˆ")
        logger.info(f"   ä¿ç•™: {len(self.samples)} ä¸ªæ ·æœ¬")
        logger.info(f"   è¿‡æ»¤: {self.stats['filtered']} ä¸ªæ ·æœ¬")
    
    def rebuild_ids(self):
        """é‡æ–°åˆ†é… IDï¼ˆæ¸…æ´—åï¼‰"""
        logger.info("ğŸ”§ é‡æ–°åˆ†é… ID...")
        
        # æŒ‰åˆ†ç±»åˆ†ç»„
        groups = {}
        for sample in self.samples:
            class_info = sample.get('class', {})
            
            # ä¿å­˜åŸå§‹ ID
            original_id = sample.get('id', '')
            
            # æå–åˆ†ç±»ä¿¡æ¯
            lang = class_info.get('lang', 'unknown')
            instruction_type = class_info.get('instruction_type', 'unknown')
            structure = class_info.get('structure', 'unknown')
            
            # æå–æ“ä½œç±»å‹
            schema_list = sample.get('schema_list', [])
            if schema_list:
                op = schema_list[0].get('op', 'unknown').lower()
            else:
                op = 'unknown'
            
            # æ„å»ºåˆ†ç»„é”®
            group_key = f"{lang}-{instruction_type}-{structure}-{op}"
            
            if group_key not in groups:
                groups[group_key] = []
            
            groups[group_key].append(sample)
        
        logger.info(f"   å‘ç° {len(groups)} ä¸ªåˆ†ç»„")
        
        # ä¸ºæ¯ä¸ªåˆ†ç»„é‡æ–°ç¼–å·
        new_samples = []
        
        for group_key, samples_list in sorted(groups.items()):
            for idx, sample in enumerate(samples_list, 1):
                # ç”Ÿæˆæ–° ID
                new_id = f"t2m-{group_key}-{idx:03d}"
                
                # ä¿å­˜æ—§çš„æ–° ID åˆ° _previous_id
                if sample.get('id') != sample.get('_original_id'):
                    sample['_previous_id'] = sample.get('id')
                
                # æ›´æ–° ID
                sample['id'] = new_id
                
                new_samples.append(sample)
            
            logger.info(f"   {group_key}: {len(samples_list)} ä¸ªæ ·æœ¬")
        
        self.samples = new_samples
        logger.info(f"âœ… é‡æ–°åˆ†é…äº† {len(self.samples)} ä¸ªæ ·æœ¬çš„ ID")
    
    def save(self, output_file: Path):
        """ä¿å­˜æ¸…æ´—åçš„æ•°æ®"""
        logger.info(f"ğŸ’¾ ä¿å­˜åˆ°: {output_file}")
        
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with output_file.open('w', encoding='utf-8') as f:
            for sample in self.samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        
        logger.info(f"âœ… å·²ä¿å­˜ {len(self.samples)} ä¸ªæ ·æœ¬")
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        from collections import Counter
        
        print("\n" + "="*60)
        print("ğŸ“Š æ¸…æ´—ç»Ÿè®¡")
        print("="*60)
        print(f"åŸå§‹æ ·æœ¬æ•°: {self.stats['total']}")
        print(f"ä¿ç•™æ ·æœ¬æ•°: {len(self.samples)}")
        print(f"è¿‡æ»¤æ ·æœ¬æ•°: {self.stats['filtered']}")
        print(f"ä¿ç•™æ¯”ä¾‹: {len(self.samples)/self.stats['total']*100:.1f}%")
        
        print(f"\nè¿‡æ»¤åŸå› :")
        for reason, count in self.stats['reasons'].items():
            if count > 0:
                print(f"  {reason}: {count} ä¸ª")
        
        # ç»Ÿè®¡ä¿ç•™çš„æ ·æœ¬
        langs = Counter()
        types = Counter()
        structures = Counter()
        operations = Counter()
        
        for sample in self.samples:
            class_info = sample.get('class', {})
            langs[class_info.get('lang', 'unknown')] += 1
            types[class_info.get('instruction_type', 'unknown')] += 1
            structures[class_info.get('structure', 'unknown')] += 1
            
            schema_list = sample.get('schema_list', [])
            if schema_list:
                op = schema_list[0].get('op', 'unknown')
                operations[op] += 1
        
        print(f"\nä¿ç•™çš„æ ·æœ¬ç»Ÿè®¡:")
        print(f"  è¯­è¨€: {dict(langs)}")
        print(f"  æŒ‡ä»¤ç±»å‹: {dict(types)}")
        print(f"  ç»“æ„: {dict(structures)}")
        print(f"  æ“ä½œ: {dict(operations)}")
        print("="*60)


def main():
    parser = argparse.ArgumentParser(
        description="æ¸…æ´— Benchmark æ•°æ®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
è¿‡æ»¤è§„åˆ™:
  1. åˆ é™¤æ‰€æœ‰åŒ…å« 'unknown' çš„æ ·æœ¬
  2. æŒ‡ä»¤ç±»å‹ï¼šåªä¿ç•™ 'direct' å’Œ 'indirect'
  3. ç»“æ„ï¼šåªä¿ç•™ 'single' å’Œ 'workflow'
  4. æ“ä½œï¼šåªä¿ç•™ 12 ç§æ ¸å¿ƒæ“ä½œ
     (Encode, Retrieve, Update, Delete, Summarize, Label,
      Promote, Demote, Expire, Lock, Merge, Split)

ç¤ºä¾‹:
  # åŸºç¡€ç”¨æ³•
  python clean_benchmark.py
  
  # æŒ‡å®šè¾“å…¥è¾“å‡º
  python clean_benchmark.py --input my_input.jsonl --output my_output.jsonl
        """
    )
    
    parser.add_argument(
        '--input',
        type=Path,
        default=Path('bench/data/test_data/test_data.jsonl'),
        help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šbench/data/test_data/test_data.jsonlï¼‰'
    )
    parser.add_argument(
        '--output',
        type=Path,
        default=Path('bench/data/benchmark/v1/benchmark.jsonl'),
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šbench/data/benchmark/v1/benchmark.jsonlï¼‰'
    )
    parser.add_argument(
        '--no-rebuild-id',
        action='store_true',
        help='ä¸é‡æ–°åˆ†é… ID'
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not args.input.exists():
        logger.error(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return 1
    
    # åˆ›å»ºæ¸…æ´—å™¨
    cleaner = BenchmarkCleaner()
    
    # 1. åŠ è½½
    cleaner.load_samples(args.input)
    
    # 2. æ¸…æ´—
    cleaner.clean()
    
    # 3. é‡æ–°åˆ†é… IDï¼ˆå¯é€‰ï¼‰
    if not args.no_rebuild_id:
        cleaner.rebuild_ids()
    
    # 4. ä¿å­˜
    cleaner.save(args.output)
    
    # 5. ç»Ÿè®¡
    cleaner.print_stats()
    
    print(f"\nğŸ“„ è¾“å‡ºæ–‡ä»¶: {args.output}")
    print(f"âœ… Benchmark æ¸…æ´—å®Œæˆï¼")
    
    return 0


if __name__ == '__main__':
    exit(main())
